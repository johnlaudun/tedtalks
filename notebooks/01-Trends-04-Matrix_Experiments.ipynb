{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Into the Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "* [Hedonometer](https://hedonometer.org/timeseries/en_all/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd, re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "dfAll = pd.read_csv('../output/TEDall.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `shape` below just to make sure the dataset loaded as expected and then `list()` to remind us of our columns: we are looking for the column that distinguishes between the main TED events and the various extra events. We are going to focus on the main events for the time being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1747, 30) ['Unnamed: 0', 'Set', 'Talk_ID', 'public_url', 'headline', 'description', 'event', 'duration', 'published', 'tags', 'views', 'text', 'speaker_1', 'speaker1_occupation', 'speaker1_introduction', 'speaker1_profile', 'speaker_2', 'speaker2_occupation', 'speaker2_introduction', 'speaker2_profile', 'speaker_3', 'speaker3_occupation', 'speaker3_introduction', 'speaker3_profile', 'speaker_4', 'speaker4_occupation', 'speaker4_introduction', 'speaker4_profile', 'presented', 'TEDevent']\n"
     ]
    }
   ],
   "source": [
    "print(dfAll.shape, list(dfAll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure we remember the terms used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plus', 'only'}\n"
     ]
    }
   ],
   "source": [
    "print(set(dfAll.Set.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to filter the dataset so that we only work with the main TED event:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(992, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main = dfAll[dfAll['Set']=='only']\n",
    "main.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the number of talks for each of the years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1984     1\n",
       "1990     1\n",
       "1994     1\n",
       "1998     6\n",
       "2001     3\n",
       "2002    28\n",
       "2003    34\n",
       "2004    31\n",
       "2005    36\n",
       "2006    43\n",
       "2007    68\n",
       "2008    56\n",
       "2009    81\n",
       "2010    68\n",
       "2011    70\n",
       "2012    65\n",
       "2013    76\n",
       "2014    84\n",
       "2015    75\n",
       "2016    75\n",
       "2017    90\n",
       "Name: presented, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main['presented'].value_counts().sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there's not much point in including the first five years on record: they total to 11, which is only half as many as the total of 28 for 2002. \n",
    "\n",
    "The easiest way to proceed is:\n",
    "\n",
    "1. Concatenate all the texts of the talks into one big pseudo-document for each year\n",
    "2. Drop the first five years\n",
    "\n",
    "We start there with concatenating all the texts of the talks into a pandas series with the years as index. In pandas you can [concatenate strings][] based on some other criteria: here we are *grouping by* the year a talk was given, which is `presented` in our dataset. (We use the `all_years` variable initially so that we can call the edited series simply `years`.)\n",
    "\n",
    "[concatenate strings]: https://stackoverflow.com/questions/27298178/concatenate-strings-from-several-rows-using-pandas-groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the texts of the talks into one big pseudo-document for each year\n",
    "all_years = main.groupby(['presented'])['text'].apply(lambda x: ','.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "presented\n",
       "2002      What I want to talk about is, as background,...\n",
       "2003      You know, one of the intense pleasures of tr...\n",
       "2004      (Music)    (Music ends)    (Applause)    Tha...\n",
       "2005      My name is Lovegrove. I only know nine Loveg...\n",
       "2006      Thank you so much, Chris. And it's truly a g...\n",
       "2007      I have all my life wondered what \"mind-boggl...\n",
       "2008      Roy Gould: Less than a year from now, the wo...\n",
       "2009      I wrote a letter last week talking about the...\n",
       "2010      Sadly, in the next 18 minutes when I do our ...\n",
       "2011      Ten years ago exactly, I was in Afghanistan....\n",
       "2012      Let me begin with four words that will provi...\n",
       "2013      What is going to be the future of learning? ...\n",
       "2014      Chris Anderson: The rights of citizens, the ...\n",
       "2015      We are built out of very small stuff, and we...\n",
       "2016      So a while ago, I tried an experiment. For o...\n",
       "2017      Gayle King: Have a seat, Serena Williams, or...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the first five years\n",
    "years = all_years.drop([1984, 1990, 1994, 1998, 2001])\n",
    "years.head(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`years.values` returns an array of all the values. `years.values[0]` gives you the first item in the array/list, and as you count up the index, you walk through the pseudo-document for each year. \n",
    "\n",
    "Not entirely intuitively, you can get the values without explicitly calling them in a `for` loop:\n",
    "\n",
    "```python\n",
    "for item in years:\n",
    "    print(item[0:20])\n",
    "```\n",
    "\n",
    "But this explicit version, which here also includes the index, is bit more clear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002:   What I want to tal\n",
      "2003:   You know, one of t\n",
      "2004:   (Music)    (Music \n",
      "2005:   My name is Lovegro\n",
      "2006:   Thank you so much,\n",
      "2007:   I have all my life\n",
      "2008:   Roy Gould: Less th\n",
      "2009:   I wrote a letter l\n",
      "2010:   Sadly, in the next\n",
      "2011:   Ten years ago exac\n",
      "2012:   Let me begin with \n",
      "2013:   What is going to b\n",
      "2014:   Chris Anderson: Th\n",
      "2015:   We are built out o\n",
      "2016:   So a while ago, I \n",
      "2017:   Gayle King: Have a\n"
     ]
    }
   ],
   "source": [
    "for index, value in years.iteritems():\n",
    "    print(f'{index}: {value[0:20]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Year Pseudo-Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a test case for later work, and without being terribly important for the current experiment, we are going to clean our texts using two functions: one to remove speakers and one to remove parentheticals.\n",
    "\n",
    "In the cell below we create our two lists, speakers and parentheticals, and then create two separate functions and then a function to combine them. \n",
    "\n",
    "Our first step is to create the two lists of strings we want removed:\n",
    "\n",
    "* `parentheticals` is from previous experiments\n",
    "* `speakers` is probably unpythonic in its expression but it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parentheticals = [ \"\\(laughter\\)\", \"\\(applause\\)\", \"\\(music\\)\", \"\\(video\\)\", \n",
    "                  \"\\(laughs\\)\", \"\\(applause ends\\)\", \"\\(audio\\)\", \"\\(singing\\)\", \n",
    "                  \"\\(music ends\\)\", \"\\(cheers\\)\", \"\\(cheering\\)\", \"\\(recording\\)\", \n",
    "                  \"\\(beatboxing\\)\", \"\\(audience\\)\", \"\\(guitar strum\\)\", \n",
    "                  \"\\(clicks metronome\\)\", \"\\(sighs\\)\", \"\\(guitar\\)\", \"\\(marimba sounds\\)\", \n",
    "                  \"\\(drum sounds\\)\" ]\n",
    "len(parentheticals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Al Gore', 'David Pogue', 'Majora Carter', 'Ken Robinson', 'Hans Rosling', 'Tony Robbins', 'Joshua Prince-Ramus', 'Julia Sweeney', 'Rick Warren', 'Dan Dennett']\n"
     ]
    }
   ],
   "source": [
    "speakers = dfAll.speaker_1.tolist() + dfAll.speaker_2.tolist() + dfAll.speaker_3.tolist() + dfAll.speaker_4.tolist()\n",
    "print(speakers[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_parens(text):\n",
    "    new_text = text\n",
    "    for rgx_match in parentheticals:\n",
    "        new_text = re.sub(rgx_match, ' ', new_text.lower(), flags=re.IGNORECASE)\n",
    "    return new_text\n",
    "\n",
    "def remove_speaker_names(text):\n",
    "    temp_text = text\n",
    "    for rgx_match in speakers:\n",
    "        temp_text = re.sub(rgx_match, ' ', temp_text)\n",
    "    return temp_text\n",
    "\n",
    "def clean_text(text):\n",
    "    the_text = text\n",
    "    cleaned = remove_parens(remove_speaker_names(the_text))\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`remove_speaker_names` keeps throwing a `TypeError`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Quick Word Count for Each Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go any further, let's just get a quick word count for each of our years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presented</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>What I want to talk about is, as background,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>You know, one of the intense pleasures of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>(Music)    (Music ends)    (Applause)    Tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>My name is Lovegrove. I only know nine Loveg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>Thank you so much, Chris. And it's truly a g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text\n",
       "presented                                                   \n",
       "2002         What I want to talk about is, as background,...\n",
       "2003         You know, one of the intense pleasures of tr...\n",
       "2004         (Music)    (Music ends)    (Applause)    Tha...\n",
       "2005         My name is Lovegrove. I only know nine Loveg...\n",
       "2006         Thank you so much, Chris. And it's truly a g..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfYears = years.to_frame()\n",
    "dfYears.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfYears = dfYears.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfYears = dfYears.replace('[^\\w\\s\\+]', '', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfYears['word_count'] = dfYears.text.apply(lambda x: len(str(x).split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presented</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>what i want to talk about is as background i...</td>\n",
       "      <td>82116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>you know one of the intense pleasures of tra...</td>\n",
       "      <td>93898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>music    music ends    applause    thank you...</td>\n",
       "      <td>89746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>my name is lovegrove i only know nine lovegr...</td>\n",
       "      <td>110717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>thank you so much chris and its truly a grea...</td>\n",
       "      <td>118346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>i have all my life wondered what mindbogglin...</td>\n",
       "      <td>149144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>roy gould less than a year from now the worl...</td>\n",
       "      <td>125901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>i wrote a letter last week talking about the...</td>\n",
       "      <td>138005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>sadly in the next 18 minutes when i do our c...</td>\n",
       "      <td>136148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>ten years ago exactly i was in afghanistan i...</td>\n",
       "      <td>131579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>let me begin with four words that will provi...</td>\n",
       "      <td>110636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>what is going to be the future of learning  ...</td>\n",
       "      <td>139354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>chris anderson the rights of citizens the fu...</td>\n",
       "      <td>160202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>we are built out of very small stuff and we ...</td>\n",
       "      <td>151397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>so a while ago i tried an experiment for one...</td>\n",
       "      <td>145530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>gayle king have a seat serena williams or sh...</td>\n",
       "      <td>181809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text  word_count\n",
       "presented                                                               \n",
       "2002         what i want to talk about is as background i...       82116\n",
       "2003         you know one of the intense pleasures of tra...       93898\n",
       "2004         music    music ends    applause    thank you...       89746\n",
       "2005         my name is lovegrove i only know nine lovegr...      110717\n",
       "2006         thank you so much chris and its truly a grea...      118346\n",
       "2007         i have all my life wondered what mindbogglin...      149144\n",
       "2008         roy gould less than a year from now the worl...      125901\n",
       "2009         i wrote a letter last week talking about the...      138005\n",
       "2010         sadly in the next 18 minutes when i do our c...      136148\n",
       "2011         ten years ago exactly i was in afghanistan i...      131579\n",
       "2012         let me begin with four words that will provi...      110636\n",
       "2013         what is going to be the future of learning  ...      139354\n",
       "2014         chris anderson the rights of citizens the fu...      160202\n",
       "2015         we are built out of very small stuff and we ...      151397\n",
       "2016         so a while ago i tried an experiment for one...      145530\n",
       "2017         gayle king have a seat serena williams or sh...      181809"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfYears.head(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we instantiate our term frequency vectorizer and turn it loose on our pseudo-documents:\n",
    "\n",
    "1. In creating a list from the `years` series we are returning to the texts with punctuation, which we need for our `remove_parens` function to do its job. The difference almost a thousand words in the resulting matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16   What I want to talk about is, as background, is  [2002, 2003, 2004, 2005, 2006]\n"
     ]
    }
   ],
   "source": [
    "texts = [ value for index, value in years.iteritems() ]\n",
    "year_labels = [ index for index, value in years.iteritems() ]\n",
    "\n",
    "# This just checks our results\n",
    "print(len(texts), texts[0][0:50], year_labels[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 21723)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = CountVectorizer(preprocessor = remove_parens, min_df = 2)\n",
    "word_count_vector=vec.fit_transform(texts)\n",
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 21723)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = vec.fit_transform(texts)\n",
    "term_matrix = pd.DataFrame(X.todense(), columns=vec.get_feature_names())\n",
    "term_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_matrix['year'] = year_labels\n",
    "term_matrix.set_index('year', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>year</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>43</td>\n",
       "      <td>54</td>\n",
       "      <td>61</td>\n",
       "      <td>66</td>\n",
       "      <td>62</td>\n",
       "      <td>81</td>\n",
       "      <td>100</td>\n",
       "      <td>73</td>\n",
       "      <td>87</td>\n",
       "      <td>67</td>\n",
       "      <td>52</td>\n",
       "      <td>112</td>\n",
       "      <td>65</td>\n",
       "      <td>74</td>\n",
       "      <td>80</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000th</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "year   2002  2003  2004  2005  2006  2007  2008  2009  2010  2011  2012  2013  \\\n",
       "00        0     0     0     0     0     2     0     1     0     0     1     0   \n",
       "000      43    54    61    66    62    81   100    73    87    67    52   112   \n",
       "000th     0     0     0     1     0     1     0     0     0     0     0     2   \n",
       "01        0     0     0     0     0     0     1     0     0     1     0     1   \n",
       "02        0     0     0     0     0     0     0     1     0     0     0     0   \n",
       "\n",
       "year   2014  2015  2016  2017  \n",
       "00        0     0     0     0  \n",
       "000      65    74    80    99  \n",
       "000th     1     0     1     0  \n",
       "01        0     0     0     0  \n",
       "02        1     0     0     0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df = term_matrix.transpose()\n",
    "word_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": 2,
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
