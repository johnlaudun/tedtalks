{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Into the Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're just here for the term-year matrix, skip past the build section below and go straight to the [Analysis](#Analysis) section, where you can load the results of the build section from a CSV of ther results. \n",
    "\n",
    "See: [Hedonometer](https://hedonometer.org/timeseries/en_all/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first section we (1) filter out all but the TED main talks, (2) group those talks by year, and then (3) count terms for each year. The process is in the following subsections:\n",
    "\n",
    "1. In [Imports and Data](#Imports-and-data) we load the data, filter for the main TED talks, and then by way of inspection, count the number of talks available for each year. As it turns out, the first few years do not have many talks -- the first three years have only one talk each -- and so we drop those years subsequently.\n",
    "2. In [Create \"Texts\" for Each Year](#Create-texts-for-each-year), we deploy **pandas**' `groupby` method to create a series with each year as the index and all the texts for that year as the value.\n",
    "3. In [Clean the Texts](#Clean-the-texts), we attempt to remove a number of elements that do not belong in the texts proper but this currently is not complete. \n",
    "4. We then do [A Quick Word Count for Each Year](#A-quick-word-count-for-each-year) just to check what our numbers are looking like.\n",
    "5. Finally, we [Vectorize the Texts](#Vectorize-the-texts), creating a dataframe which has the years for rows and the terms for columns which is then transposed so that the words are the rows and the years columns, making it easier, we hope, to \"see\" trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd, re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the data, we use `.shape` and `list()` to make sure the dataset loaded as expected and then to remind us of our column headers -- we are looking for the column that distinguishes between the main TED events and the various extra events. We are going to focus on the main events for the time being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plus', 'only'}\n"
     ]
    }
   ],
   "source": [
    "# Load the Data\n",
    "dfAll = pd.read_csv('../output/TEDall.csv')\n",
    "\n",
    "# Remind ourselves what the terms are to distinguish\n",
    "# between TED main talks and all the other talks\n",
    "print(set(dfAll.Set.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1984     1\n",
       "1990     1\n",
       "1994     1\n",
       "1998     6\n",
       "2001     3\n",
       "2002    28\n",
       "2003    34\n",
       "2004    31\n",
       "2005    36\n",
       "2006    43\n",
       "2007    68\n",
       "2008    56\n",
       "2009    81\n",
       "2010    68\n",
       "2011    70\n",
       "2012    65\n",
       "2013    76\n",
       "2014    84\n",
       "2015    75\n",
       "2016    75\n",
       "2017    90\n",
       "Name: presented, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataframe to just the TED main talks:\n",
    "main = dfAll[dfAll['Set']=='only']\n",
    "# main.shape\n",
    "main['presented'].value_counts().sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create \"Texts\" for Each Year\n",
    "\n",
    "It looks like there's not much point in including the first five years on record: they total to 11, which is only half as many as the total of 28 for 2002. \n",
    "\n",
    "The easiest way to proceed is:\n",
    "\n",
    "1. Concatenate all the texts of the talks into one big pseudo-document for each year\n",
    "2. Drop the first five years\n",
    "\n",
    "We start there with concatenating all the texts of the talks into a pandas series with the years as index. In pandas you can [concatenate strings][] based on some other criteria: here we are *grouping by* the year a talk was given, which is `presented` in our dataset. (We use the `all_years` variable initially so that we can call the edited series simply `years`.)\n",
    "\n",
    "[concatenate strings]: https://stackoverflow.com/questions/27298178/concatenate-strings-from-several-rows-using-pandas-groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the texts of the talks into one big pseudo-document for each year\n",
    "all_years = main.groupby(['presented'])['text'].apply(lambda x: ','.join(x))\n",
    "\n",
    "# Drop the first five years\n",
    "years = all_years.drop([1984, 1990, 1994, 1998, 2001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002:   What I want to talk about is, as background, is the idea t\n",
      "2003:   You know, one of the intense pleasures of travel and one o\n",
      "2004:   (Music)    (Music ends)    (Applause)    Thank you!    (Ap\n",
      "2005:   My name is Lovegrove. I only know nine Lovegroves, two of \n",
      "2006:   Thank you so much, Chris. And it's truly a great honor to \n",
      "2007:   I have all my life wondered what \"mind-boggling\" meant. Af\n",
      "2008:   Roy Gould: Less than a year from now, the world is going t\n",
      "2009:   I wrote a letter last week talking about the work of the f\n",
      "2010:   Sadly, in the next 18 minutes when I do our chat, four Ame\n",
      "2011:   Ten years ago exactly, I was in Afghanistan. I was coverin\n",
      "2012:   Let me begin with four words that will provide the context\n",
      "2013:   What is going to be the future of learning?    I do have a\n",
      "2014:   Chris Anderson: The rights of citizens, the future of the \n",
      "2015:   We are built out of very small stuff, and we are embedded \n",
      "2016:   So a while ago, I tried an experiment. For one year, I wou\n",
      "2017:   Gayle King: Have a seat, Serena Williams, or should we say\n"
     ]
    }
   ],
   "source": [
    "for index, value in years.iteritems():\n",
    "    print(f'{index}: {value[0:60]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a test case for later work, and without being terribly important for the current experiment, we are going to clean our texts using two functions: one to remove speakers and one to remove parentheticals.\n",
    "\n",
    "In the cell below we create our two lists, speakers and parentheticals, and then create two separate functions and then a function to combine them. \n",
    "\n",
    "Our first step is to create the two lists of strings we want removed:\n",
    "\n",
    "* `parentheticals` is from previous experiments\n",
    "* `speakers` is probably unpythonic in its expression but it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parentheticals = [ \"\\(laughter\\)\", \"\\(applause\\)\", \"\\(music\\)\", \"\\(video\\)\", \n",
    "                  \"\\(laughs\\)\", \"\\(applause ends\\)\", \"\\(audio\\)\", \"\\(singing\\)\", \n",
    "                  \"\\(music ends\\)\", \"\\(cheers\\)\", \"\\(cheering\\)\", \"\\(recording\\)\", \n",
    "                  \"\\(beatboxing\\)\", \"\\(audience\\)\", \"\\(guitar strum\\)\", \n",
    "                  \"\\(clicks metronome\\)\", \"\\(sighs\\)\", \"\\(guitar\\)\", \"\\(marimba sounds\\)\", \n",
    "                  \"\\(drum sounds\\)\" ]\n",
    "len(parentheticals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Al Gore', 'David Pogue', 'Majora Carter', 'Ken Robinson', 'Hans Rosling', 'Tony Robbins', 'Joshua Prince-Ramus', 'Julia Sweeney', 'Rick Warren', 'Dan Dennett']\n"
     ]
    }
   ],
   "source": [
    "speakers = dfAll.speaker_1.tolist() + dfAll.speaker_2.tolist() + dfAll.speaker_3.tolist() + dfAll.speaker_4.tolist()\n",
    "print(speakers[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_parens(text):\n",
    "    new_text = text\n",
    "    for rgx_match in parentheticals:\n",
    "        new_text = re.sub(rgx_match, ' ', new_text.lower(), flags=re.IGNORECASE)\n",
    "    return new_text\n",
    "\n",
    "def remove_speaker_names(text):\n",
    "    temp_text = text\n",
    "    for rgx_match in speakers:\n",
    "        temp_text = re.sub(rgx_match, ' ', temp_text)\n",
    "    return temp_text\n",
    "\n",
    "def clean_text(text):\n",
    "    the_text = text\n",
    "    cleaned = remove_parens(remove_speaker_names(the_text))\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`remove_speaker_names` keeps throwing a `TypeError`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Quick Word Count for Each Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go any further, let's just get a quick word count for each of our years. In this section of cells, we do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presented</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>what i want to talk about is as background i...</td>\n",
       "      <td>82116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>you know one of the intense pleasures of tra...</td>\n",
       "      <td>93898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>music    music ends    applause    thank you...</td>\n",
       "      <td>89746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>my name is lovegrove i only know nine lovegr...</td>\n",
       "      <td>110717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>thank you so much chris and its truly a grea...</td>\n",
       "      <td>118346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>i have all my life wondered what mindbogglin...</td>\n",
       "      <td>149144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>roy gould less than a year from now the worl...</td>\n",
       "      <td>125901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>i wrote a letter last week talking about the...</td>\n",
       "      <td>138005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>sadly in the next 18 minutes when i do our c...</td>\n",
       "      <td>136148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>ten years ago exactly i was in afghanistan i...</td>\n",
       "      <td>131579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>let me begin with four words that will provi...</td>\n",
       "      <td>110636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>what is going to be the future of learning  ...</td>\n",
       "      <td>139354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>chris anderson the rights of citizens the fu...</td>\n",
       "      <td>160202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>we are built out of very small stuff and we ...</td>\n",
       "      <td>151397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>so a while ago i tried an experiment for one...</td>\n",
       "      <td>145530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>gayle king have a seat serena williams or sh...</td>\n",
       "      <td>181809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text  word_count\n",
       "presented                                                               \n",
       "2002         what i want to talk about is as background i...       82116\n",
       "2003         you know one of the intense pleasures of tra...       93898\n",
       "2004         music    music ends    applause    thank you...       89746\n",
       "2005         my name is lovegrove i only know nine lovegr...      110717\n",
       "2006         thank you so much chris and its truly a grea...      118346\n",
       "2007         i have all my life wondered what mindbogglin...      149144\n",
       "2008         roy gould less than a year from now the worl...      125901\n",
       "2009         i wrote a letter last week talking about the...      138005\n",
       "2010         sadly in the next 18 minutes when i do our c...      136148\n",
       "2011         ten years ago exactly i was in afghanistan i...      131579\n",
       "2012         let me begin with four words that will provi...      110636\n",
       "2013         what is going to be the future of learning  ...      139354\n",
       "2014         chris anderson the rights of citizens the fu...      160202\n",
       "2015         we are built out of very small stuff and we ...      151397\n",
       "2016         so a while ago i tried an experiment for one...      145530\n",
       "2017         gayle king have a seat serena williams or sh...      181809"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert our series to a dataframe to make it easier to work in place:\n",
    "dfYears = years.to_frame()\n",
    "\n",
    "# Lowercase our texts\n",
    "dfYears = dfYears.apply(lambda x: x.astype(str).str.lower())\n",
    "\n",
    "# Remove everything that isn't a word, or space\n",
    "dfYears = dfYears.replace('[^\\w\\s\\+]', '', regex = True)\n",
    "\n",
    "# Split on spaces and then count the length of the resulting list\n",
    "dfYears['word_count'] = dfYears.text.apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "# See the results\n",
    "dfYears.head(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the Pseudo-Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we instantiate our term frequency vectorizer and turn it loose on our pseudo-documents:\n",
    "\n",
    "1. In creating a list from the `years` series we are returning to the texts with punctuation, which we need for our `remove_parens` function to do its job. The difference almost a thousand words in the resulting matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16   What I want to talk about is, as background, is  [2002, 2003, 2004, 2005, 2006]\n"
     ]
    }
   ],
   "source": [
    "# Countvectorizer expects a list, so we create a list\n",
    "texts = [ value for index, value in years.iteritems() ]\n",
    "\n",
    "# We are going to bring our years back to the resulting term matrix below, \n",
    "# so while we are creating lists from our series, lets grab those years\n",
    "# (And yes you can create two lists from one list comprehension, but don't.)\n",
    "year_labels = [ index for index, value in years.iteritems() ]\n",
    "\n",
    "# This just checks our results\n",
    "print(len(texts), texts[0][0:50], year_labels[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 21723)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The usual incantation (minus the desired speaker removal for now):\n",
    "vec = CountVectorizer(preprocessor = remove_parens, min_df = 2)\n",
    "word_count_vector=vec.fit_transform(texts)\n",
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 21723)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from the resulting array\n",
    "X = vec.fit_transform(texts)\n",
    "term_matrix = pd.DataFrame(X.todense(), columns=vec.get_feature_names())\n",
    "term_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_matrix['year'] = year_labels\n",
    "term_matrix.set_index('year', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>year</th>\n",
       "      <th>term</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000</td>\n",
       "      <td>43</td>\n",
       "      <td>54</td>\n",
       "      <td>61</td>\n",
       "      <td>66</td>\n",
       "      <td>62</td>\n",
       "      <td>81</td>\n",
       "      <td>100</td>\n",
       "      <td>73</td>\n",
       "      <td>87</td>\n",
       "      <td>67</td>\n",
       "      <td>52</td>\n",
       "      <td>112</td>\n",
       "      <td>65</td>\n",
       "      <td>74</td>\n",
       "      <td>80</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000th</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "year   term  2002  2003  2004  2005  2006  2007  2008  2009  2010  2011  2012  \\\n",
       "0        00     0     0     0     0     0     2     0     1     0     0     1   \n",
       "1       000    43    54    61    66    62    81   100    73    87    67    52   \n",
       "2     000th     0     0     0     1     0     1     0     0     0     0     0   \n",
       "3        01     0     0     0     0     0     0     1     0     0     1     0   \n",
       "4        02     0     0     0     0     0     0     0     1     0     0     0   \n",
       "\n",
       "year  2013  2014  2015  2016  2017  \n",
       "0        0     0     0     0     0  \n",
       "1      112    65    74    80    99  \n",
       "2        2     1     0     1     0  \n",
       "3        1     0     0     0     0  \n",
       "4        0     1     0     0     0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df = term_matrix.transpose()\n",
    "word_df.reset_index(inplace=True)\n",
    "word_df = word_df.rename(columns={'index': 'term'})\n",
    "word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save this dataframe \n",
    "# ==> Commented out so re-running notebook doesn't result in new file\n",
    "# word_df.to_csv('../output/term_year_matrix.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all of the above done, we now have a matrix with every word in a row and every year a column such that we can read a word's usage from left to right moving forward in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21722, 17) ['term', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017']\n"
     ]
    }
   ],
   "source": [
    "# Load the Data\n",
    "df = pd.read_csv('../output/term_year_matrix.csv') # , index_col = 'term'\n",
    "\n",
    "# The 'Unnamed: 0' column is a vestigial index, let's drop it:\n",
    "# df.drop(columns = ['Unnamed: 0'], inplace=True)\n",
    "# df.set_index('term')\n",
    "\n",
    "# Check shape and list columns:\n",
    "print(df.shape, list(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13276</th>\n",
       "      <td>nuclear</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>73</td>\n",
       "      <td>9</td>\n",
       "      <td>78</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          term  2002  2003  2004  2005  2006  2007  2008  2009  2010  2011  \\\n",
       "13276  nuclear    10     1     0     4     3    11    73     9    78     7   \n",
       "\n",
       "       2012  2013  2014  2015  2016  2017  \n",
       "13276    14    22    12     8     4     2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One term:\n",
    "df[word_df['term']=='nuclear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3708</th>\n",
       "      <td>climate</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>37</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518</th>\n",
       "      <td>global</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "      <td>102</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13276</th>\n",
       "      <td>nuclear</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>73</td>\n",
       "      <td>9</td>\n",
       "      <td>78</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          term  2002  2003  2004  2005  2006  2007  2008  2009  2010  2011  \\\n",
       "3708   climate     1    10     1    14     9    19    17    26    17     4   \n",
       "8518    global    12    11     2    12    40    26    29    36    32    20   \n",
       "13276  nuclear    10     1     0     4     3    11    73     9    78     7   \n",
       "\n",
       "       2012  2013  2014  2015  2016  2017  \n",
       "3708     28    23    23    14    37    95  \n",
       "8518     26    16    33    39   102    41  \n",
       "13276    14    22    12     8     4     2  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple terms:\n",
    "terms = ['nuclear', 'global', 'climate']\n",
    "\n",
    "# And this is the pandas way\n",
    "df[word_df.term.isin(terms)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing by Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next series of cells, we first get the total number of words for each year, and then we get a list of our year columns so that we can then get a sum for each column and divide each term for a given year by the total number of words for that year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2002     73153\n",
       "2003     85039\n",
       "2004     79782\n",
       "2005     99193\n",
       "2006    105353\n",
       "2007    133227\n",
       "2008    114236\n",
       "2009    126229\n",
       "2010    122575\n",
       "2011    119465\n",
       "2012     99317\n",
       "2013    126976\n",
       "2014    145956\n",
       "2015    136625\n",
       "2016    128932\n",
       "2017    162345\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a quick check of the sums involved\n",
    "df.sum(axis = 0, skipna = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of our columns minus the first one which is where our terms are located:\n",
    "years = list(df)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide each cell in a column by the total for each column\n",
    "df[years] = df[years] / df[years].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3708</th>\n",
       "      <td>climate</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518</th>\n",
       "      <td>global</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.000253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13276</th>\n",
       "      <td>nuclear</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          term      2002      2003      2004      2005      2006      2007  \\\n",
       "3708   climate  0.000014  0.000118  0.000013  0.000141  0.000085  0.000143   \n",
       "8518    global  0.000164  0.000129  0.000025  0.000121  0.000380  0.000195   \n",
       "13276  nuclear  0.000137  0.000012  0.000000  0.000040  0.000028  0.000083   \n",
       "\n",
       "           2008      2009      2010      2011      2012      2013      2014  \\\n",
       "3708   0.000149  0.000206  0.000139  0.000033  0.000282  0.000181  0.000158   \n",
       "8518   0.000254  0.000285  0.000261  0.000167  0.000262  0.000126  0.000226   \n",
       "13276  0.000639  0.000071  0.000636  0.000059  0.000141  0.000173  0.000082   \n",
       "\n",
       "           2015      2016      2017  \n",
       "3708   0.000102  0.000287  0.000585  \n",
       "8518   0.000285  0.000791  0.000253  \n",
       "13276  0.000059  0.000031  0.000012  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and here's are three sample terms now with normalized frequency for a year\n",
    "df[word_df.term.isin(terms)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_df.to_csv('../output/term_year_matrix_normalized.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": 2,
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
