{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb2af92",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "In this notebook, we seek to find \"hedging\" bigrams by using the word2vec embeddings for unigrams that are part of hedging bigrams. Examples include:  \n",
    "\n",
    "* \"Sort\" coming from \"sort of\"\n",
    "* \"kind\" coming from \"kind of\"\n",
    "* \"Guess\" used in \"I guess\"\n",
    "\n",
    "Following the ideas from Ben Schmidt's [Rejecting the gender binary: a vector-space operation](http://bookworm.benschmidt.org/posts/2015-10-30-rejecting-the-gender-binary.html), we will build a vector for the collection of \"hedging\" unigrams and then use \"vector rejection\" to remove non-hedging uses of the hedging unigrams. For example: \n",
    "\n",
    "* \"Sort\" coming from \"sort of\" but not \"arrange, list, classify\" nor \"variety, category, type\"\n",
    "* \"kind\" coming from \"kind of\" but not \"friendly, nice, patience\" nor \"variety, category, type\"\n",
    "* \"Guess\" used in \"I guess\" but not \"predict, determine, explain\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e88dd06",
   "metadata": {},
   "source": [
    " Look here: https://stackabuse.com/implementing-word2vec-with-gensim-library-in-python/\n",
    " \n",
    " https://medium.com/swlh/word-embedding-word2vec-with-genism-nltk-and-t-sne-visualization-43eae8ab3e2e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cae2e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd, re, csv, nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# https://stackoverflow.com/questions/37101114/what-to-download-in-order-to-make-nltk-tokenize-word-tokenize-work\n",
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# for preprocessing the text\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import string\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0d5b7430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'c', 'd', 'e', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'll', 're', 've']\n"
     ]
    }
   ],
   "source": [
    "# Creating a stopword list of consonants and the \n",
    "\n",
    "stoplist = list(string.ascii_letters[:26])\n",
    "stoplist.pop(8) # Remove 'i'\n",
    "stoplist.pop(0) # Remove 'a'\n",
    "\n",
    "stoplist.append(\"ll\")\n",
    "stoplist.append(\"re\")\n",
    "stoplist.append(\"ve\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1a586734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building my own stopword remover to get rid of the non \"a\" and \"i\" consonants\n",
    "# Based on `remove_stopewords() in gensim\n",
    "#    https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/parsing/preprocessing.py\n",
    "\n",
    "def remove_stoplist(s):\n",
    "    return \" \".join(remove_consonants_tokens(s.split()))\n",
    "\n",
    "def remove_stoplist_tokens(tokens):\n",
    "    global stoplist\n",
    "    return [token for token in tokens if token not in stoplist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20ae2029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "# Load binary gendered talks \n",
    "talks_male = pd.read_csv('talks_male.csv', index_col='Talk_ID')\n",
    "talks_female = pd.read_csv('talks_female.csv', index_col='Talk_ID')\n",
    "\n",
    "# No one gender ==> NOG\n",
    "talks_nog = pd.read_csv('talks_nog.csv', index_col='Talk_ID')\n",
    "\n",
    "# Concatenate the data\n",
    "\n",
    "all_talks = pd.concat([talks_male,talks_female,talks_nog])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11eba21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioned_texts = all_talks.text.tolist()\n",
    "\n",
    "# From https://www.geeksforgeeks.org/python-string-join-method/\n",
    "#text_all = \" \".join(partitioned_texts)\n",
    "\n",
    "processed_texts = [text.lower() for text in partitioned_texts]\n",
    "processed_texts = [re.sub('[^a-zA-Z]', ' ', text) for text in processed_texts]\n",
    "processed_texts = [re.sub(r'\\s+', ' ', text) for text in processed_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d52ce3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"  Thank you so much, Chris. And it's truly a great\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitioned_texts[0][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1f5837ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_texts = [remove_stoplist(text) for text in processed_texts]\n",
    "doc_texts = [nltk.word_tokenize(text) for text in processed_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ef9a2a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5a0b2116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "992"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0b7acdb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thank',\n",
       " 'you',\n",
       " 'so',\n",
       " 'much',\n",
       " 'chris',\n",
       " 'and',\n",
       " 'it',\n",
       " 'truly',\n",
       " 'a',\n",
       " 'great',\n",
       " 'honor',\n",
       " 'to',\n",
       " 'have',\n",
       " 'the',\n",
       " 'opportunity',\n",
       " 'to',\n",
       " 'come',\n",
       " 'to',\n",
       " 'this',\n",
       " 'stage',\n",
       " 'twice',\n",
       " 'i',\n",
       " 'extremely',\n",
       " 'grateful',\n",
       " 'i',\n",
       " 'have',\n",
       " 'been',\n",
       " 'blown',\n",
       " 'away',\n",
       " 'by',\n",
       " 'this',\n",
       " 'conference',\n",
       " 'and',\n",
       " 'i',\n",
       " 'want',\n",
       " 'to',\n",
       " 'thank',\n",
       " 'all',\n",
       " 'of',\n",
       " 'you',\n",
       " 'for',\n",
       " 'the',\n",
       " 'many',\n",
       " 'nice',\n",
       " 'comments',\n",
       " 'about',\n",
       " 'what',\n",
       " 'i',\n",
       " 'had',\n",
       " 'to',\n",
       " 'say',\n",
       " 'the',\n",
       " 'other',\n",
       " 'night',\n",
       " 'and',\n",
       " 'i',\n",
       " 'say',\n",
       " 'that',\n",
       " 'sincerely',\n",
       " 'partly',\n",
       " 'because',\n",
       " 'mock',\n",
       " 'sob',\n",
       " 'i',\n",
       " 'need',\n",
       " 'that',\n",
       " 'laughter',\n",
       " 'put',\n",
       " 'yourselves',\n",
       " 'in',\n",
       " 'my',\n",
       " 'position',\n",
       " 'laughter',\n",
       " 'i',\n",
       " 'flew',\n",
       " 'on',\n",
       " 'air',\n",
       " 'force',\n",
       " 'two',\n",
       " 'for',\n",
       " 'eight',\n",
       " 'years',\n",
       " 'laughter',\n",
       " 'now',\n",
       " 'i',\n",
       " 'have',\n",
       " 'to',\n",
       " 'take',\n",
       " 'off',\n",
       " 'my',\n",
       " 'shoes',\n",
       " 'or',\n",
       " 'boots',\n",
       " 'to',\n",
       " 'get',\n",
       " 'on',\n",
       " 'an',\n",
       " 'airplane',\n",
       " 'laughter',\n",
       " 'applause',\n",
       " 'i',\n",
       " 'tell',\n",
       " 'you',\n",
       " 'one',\n",
       " 'quick',\n",
       " 'story',\n",
       " 'to',\n",
       " 'illustrate',\n",
       " 'what',\n",
       " 'that',\n",
       " 'been',\n",
       " 'like',\n",
       " 'for',\n",
       " 'me',\n",
       " 'laughter',\n",
       " 'it',\n",
       " 'a',\n",
       " 'true',\n",
       " 'story',\n",
       " 'every',\n",
       " 'bit',\n",
       " 'of',\n",
       " 'this',\n",
       " 'is',\n",
       " 'true',\n",
       " 'soon',\n",
       " 'after',\n",
       " 'tipper',\n",
       " 'and',\n",
       " 'i',\n",
       " 'left',\n",
       " 'the',\n",
       " 'mock',\n",
       " 'sob',\n",
       " 'white',\n",
       " 'house',\n",
       " 'laughter',\n",
       " 'we',\n",
       " 'were',\n",
       " 'driving',\n",
       " 'from',\n",
       " 'our',\n",
       " 'home',\n",
       " 'in',\n",
       " 'nashville',\n",
       " 'to',\n",
       " 'a',\n",
       " 'little',\n",
       " 'farm',\n",
       " 'we',\n",
       " 'have',\n",
       " 'miles',\n",
       " 'east',\n",
       " 'of',\n",
       " 'nashville',\n",
       " 'driving',\n",
       " 'ourselves',\n",
       " 'laughter',\n",
       " 'i',\n",
       " 'know',\n",
       " 'it',\n",
       " 'sounds',\n",
       " 'like',\n",
       " 'a',\n",
       " 'little',\n",
       " 'thing',\n",
       " 'to',\n",
       " 'you',\n",
       " 'but',\n",
       " 'laughter',\n",
       " 'i',\n",
       " 'looked',\n",
       " 'in',\n",
       " 'the',\n",
       " 'rear',\n",
       " 'view',\n",
       " 'mirror',\n",
       " 'and',\n",
       " 'all',\n",
       " 'of',\n",
       " 'a',\n",
       " 'sudden',\n",
       " 'it',\n",
       " 'just',\n",
       " 'hit',\n",
       " 'me',\n",
       " 'there',\n",
       " 'was',\n",
       " 'no',\n",
       " 'motorcade',\n",
       " 'back',\n",
       " 'there',\n",
       " 'laughter',\n",
       " 'you',\n",
       " 'heard',\n",
       " 'of',\n",
       " 'phantom',\n",
       " 'limb',\n",
       " 'pain',\n",
       " 'laughter',\n",
       " 'this',\n",
       " 'was',\n",
       " 'a',\n",
       " 'rented',\n",
       " 'ford',\n",
       " 'taurus',\n",
       " 'laughter',\n",
       " 'it',\n",
       " 'was',\n",
       " 'dinnertime',\n",
       " 'and',\n",
       " 'we',\n",
       " 'started',\n",
       " 'looking',\n",
       " 'for',\n",
       " 'a',\n",
       " 'place',\n",
       " 'to',\n",
       " 'eat',\n",
       " 'we',\n",
       " 'were',\n",
       " 'on',\n",
       " 'i',\n",
       " 'we',\n",
       " 'got',\n",
       " 'to',\n",
       " 'exit',\n",
       " 'lebanon',\n",
       " 'tennessee',\n",
       " 'we',\n",
       " 'got',\n",
       " 'off',\n",
       " 'the',\n",
       " 'exit',\n",
       " 'we',\n",
       " 'found',\n",
       " 'a',\n",
       " 'shoney',\n",
       " 'restaurant',\n",
       " 'low',\n",
       " 'cost',\n",
       " 'family',\n",
       " 'restaurant',\n",
       " 'chain',\n",
       " 'for',\n",
       " 'those',\n",
       " 'of',\n",
       " 'you',\n",
       " 'who',\n",
       " 'don',\n",
       " 'know',\n",
       " 'it',\n",
       " 'we',\n",
       " 'went',\n",
       " 'in',\n",
       " 'and',\n",
       " 'sat',\n",
       " 'down',\n",
       " 'at',\n",
       " 'the',\n",
       " 'booth',\n",
       " 'and',\n",
       " 'the',\n",
       " 'waitress',\n",
       " 'came',\n",
       " 'over',\n",
       " 'made',\n",
       " 'a',\n",
       " 'big',\n",
       " 'commotion',\n",
       " 'over',\n",
       " 'tipper',\n",
       " 'laughter',\n",
       " 'she',\n",
       " 'took',\n",
       " 'our',\n",
       " 'order',\n",
       " 'and',\n",
       " 'then',\n",
       " 'went',\n",
       " 'to',\n",
       " 'the',\n",
       " 'couple',\n",
       " 'in',\n",
       " 'the',\n",
       " 'booth',\n",
       " 'next',\n",
       " 'to',\n",
       " 'us',\n",
       " 'and',\n",
       " 'she',\n",
       " 'lowered',\n",
       " 'her',\n",
       " 'voice',\n",
       " 'so',\n",
       " 'much',\n",
       " 'i',\n",
       " 'had',\n",
       " 'to',\n",
       " 'really',\n",
       " 'strain',\n",
       " 'to',\n",
       " 'hear',\n",
       " 'what',\n",
       " 'she',\n",
       " 'was',\n",
       " 'saying',\n",
       " 'and',\n",
       " 'she',\n",
       " 'said',\n",
       " 'yes',\n",
       " 'that',\n",
       " 'former',\n",
       " 'vice',\n",
       " 'president',\n",
       " 'al',\n",
       " 'gore',\n",
       " 'and',\n",
       " 'his',\n",
       " 'wife',\n",
       " 'tipper',\n",
       " 'and',\n",
       " 'the',\n",
       " 'man',\n",
       " 'said',\n",
       " 'he',\n",
       " 'come',\n",
       " 'down',\n",
       " 'a',\n",
       " 'long',\n",
       " 'way',\n",
       " 'hasn',\n",
       " 'he',\n",
       " 'laughter',\n",
       " 'applause',\n",
       " 'there',\n",
       " 'been',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'a',\n",
       " 'series',\n",
       " 'of',\n",
       " 'epiphanies',\n",
       " 'laughter',\n",
       " 'the',\n",
       " 'very',\n",
       " 'next',\n",
       " 'day',\n",
       " 'continuing',\n",
       " 'the',\n",
       " 'totally',\n",
       " 'true',\n",
       " 'story',\n",
       " 'i',\n",
       " 'got',\n",
       " 'on',\n",
       " 'a',\n",
       " 'to',\n",
       " 'fly',\n",
       " 'to',\n",
       " 'africa',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'speech',\n",
       " 'in',\n",
       " 'nigeria',\n",
       " 'in',\n",
       " 'the',\n",
       " 'city',\n",
       " 'of',\n",
       " 'lagos',\n",
       " 'on',\n",
       " 'the',\n",
       " 'topic',\n",
       " 'of',\n",
       " 'energy',\n",
       " 'and',\n",
       " 'i',\n",
       " 'began',\n",
       " 'the',\n",
       " 'speech',\n",
       " 'by',\n",
       " 'telling',\n",
       " 'them',\n",
       " 'the',\n",
       " 'story',\n",
       " 'of',\n",
       " 'what',\n",
       " 'had',\n",
       " 'just',\n",
       " 'happened',\n",
       " 'the',\n",
       " 'day',\n",
       " 'before',\n",
       " 'in',\n",
       " 'nashville',\n",
       " 'and',\n",
       " 'i',\n",
       " 'told',\n",
       " 'it',\n",
       " 'pretty',\n",
       " 'much',\n",
       " 'the',\n",
       " 'same',\n",
       " 'way',\n",
       " 'i',\n",
       " 'just',\n",
       " 'shared',\n",
       " 'it',\n",
       " 'with',\n",
       " 'you',\n",
       " 'tipper',\n",
       " 'and',\n",
       " 'i',\n",
       " 'were',\n",
       " 'driving',\n",
       " 'ourselves',\n",
       " 'shoney',\n",
       " 'low',\n",
       " 'cost',\n",
       " 'family',\n",
       " 'restaurant',\n",
       " 'chain',\n",
       " 'what',\n",
       " 'the',\n",
       " 'man',\n",
       " 'said',\n",
       " 'they',\n",
       " 'laughed',\n",
       " 'i',\n",
       " 'gave',\n",
       " 'my',\n",
       " 'speech',\n",
       " 'then',\n",
       " 'went',\n",
       " 'back',\n",
       " 'out',\n",
       " 'to',\n",
       " 'the',\n",
       " 'airport',\n",
       " 'to',\n",
       " 'fly',\n",
       " 'back',\n",
       " 'home',\n",
       " 'i',\n",
       " 'fell',\n",
       " 'asleep',\n",
       " 'on',\n",
       " 'the',\n",
       " 'plane',\n",
       " 'until',\n",
       " 'during',\n",
       " 'the',\n",
       " 'middle',\n",
       " 'of',\n",
       " 'the',\n",
       " 'night',\n",
       " 'we',\n",
       " 'landed',\n",
       " 'on',\n",
       " 'the',\n",
       " 'azores',\n",
       " 'islands',\n",
       " 'for',\n",
       " 'refueling',\n",
       " 'i',\n",
       " 'woke',\n",
       " 'up',\n",
       " 'they',\n",
       " 'opened',\n",
       " 'the',\n",
       " 'door',\n",
       " 'i',\n",
       " 'went',\n",
       " 'out',\n",
       " 'to',\n",
       " 'get',\n",
       " 'some',\n",
       " 'fresh',\n",
       " 'air',\n",
       " 'and',\n",
       " 'i',\n",
       " 'looked',\n",
       " 'and',\n",
       " 'there',\n",
       " 'was',\n",
       " 'a',\n",
       " 'man',\n",
       " 'running',\n",
       " 'across',\n",
       " 'the',\n",
       " 'runway',\n",
       " 'and',\n",
       " 'he',\n",
       " 'was',\n",
       " 'waving',\n",
       " 'a',\n",
       " 'piece',\n",
       " 'of',\n",
       " 'paper',\n",
       " 'and',\n",
       " 'he',\n",
       " 'was',\n",
       " 'yelling',\n",
       " 'call',\n",
       " 'washington',\n",
       " 'call',\n",
       " 'washington',\n",
       " 'and',\n",
       " 'i',\n",
       " 'thought',\n",
       " 'to',\n",
       " 'myself',\n",
       " 'in',\n",
       " 'the',\n",
       " 'middle',\n",
       " 'of',\n",
       " 'the',\n",
       " 'night',\n",
       " 'in',\n",
       " 'the',\n",
       " 'middle',\n",
       " 'of',\n",
       " 'the',\n",
       " 'atlantic',\n",
       " 'what',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " 'could',\n",
       " 'be',\n",
       " 'wrong',\n",
       " 'in',\n",
       " 'washington',\n",
       " 'then',\n",
       " 'i',\n",
       " 'remembered',\n",
       " 'it',\n",
       " 'could',\n",
       " 'be',\n",
       " 'a',\n",
       " 'bunch',\n",
       " 'of',\n",
       " 'things',\n",
       " 'laughter',\n",
       " 'but',\n",
       " 'what',\n",
       " 'it',\n",
       " 'turned',\n",
       " 'out',\n",
       " 'to',\n",
       " 'be',\n",
       " 'was',\n",
       " 'that',\n",
       " 'my',\n",
       " 'staff',\n",
       " 'was',\n",
       " 'extremely',\n",
       " 'upset',\n",
       " 'because',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'wire',\n",
       " 'services',\n",
       " 'in',\n",
       " 'nigeria',\n",
       " 'had',\n",
       " 'already',\n",
       " 'written',\n",
       " 'a',\n",
       " 'story',\n",
       " 'about',\n",
       " 'my',\n",
       " 'speech',\n",
       " 'and',\n",
       " 'it',\n",
       " 'had',\n",
       " 'already',\n",
       " 'been',\n",
       " 'printed',\n",
       " 'in',\n",
       " 'cities',\n",
       " 'all',\n",
       " 'across',\n",
       " 'the',\n",
       " 'united',\n",
       " 'states',\n",
       " 'of',\n",
       " 'america',\n",
       " 'it',\n",
       " 'was',\n",
       " 'printed',\n",
       " 'in',\n",
       " 'monterey',\n",
       " 'i',\n",
       " 'checked',\n",
       " 'laughter',\n",
       " 'and',\n",
       " 'the',\n",
       " 'story',\n",
       " 'began',\n",
       " 'former',\n",
       " 'vice',\n",
       " 'president',\n",
       " 'al',\n",
       " 'gore',\n",
       " 'announced',\n",
       " 'in',\n",
       " 'nigeria',\n",
       " 'yesterday',\n",
       " 'quote',\n",
       " 'my',\n",
       " 'wife',\n",
       " 'tipper',\n",
       " 'and',\n",
       " 'i',\n",
       " 'have',\n",
       " 'opened',\n",
       " 'a',\n",
       " 'low',\n",
       " 'cost',\n",
       " 'family',\n",
       " 'restaurant',\n",
       " 'laughter',\n",
       " 'named',\n",
       " 'shoney',\n",
       " 'and',\n",
       " 'we',\n",
       " 'are',\n",
       " 'running',\n",
       " 'it',\n",
       " 'ourselves',\n",
       " 'laughter',\n",
       " 'before',\n",
       " 'i',\n",
       " 'could',\n",
       " 'get',\n",
       " 'back',\n",
       " 'to',\n",
       " 'soil',\n",
       " 'david',\n",
       " 'letterman',\n",
       " 'and',\n",
       " 'jay',\n",
       " 'leno',\n",
       " 'had',\n",
       " 'already',\n",
       " 'started',\n",
       " 'in',\n",
       " 'on',\n",
       " 'one',\n",
       " 'of',\n",
       " 'them',\n",
       " 'had',\n",
       " 'me',\n",
       " 'in',\n",
       " 'a',\n",
       " 'big',\n",
       " 'white',\n",
       " 'chef',\n",
       " 'hat',\n",
       " 'tipper',\n",
       " 'was',\n",
       " 'saying',\n",
       " 'one',\n",
       " 'more',\n",
       " 'burger',\n",
       " 'with',\n",
       " 'fries',\n",
       " 'laughter',\n",
       " 'three',\n",
       " 'days',\n",
       " 'later',\n",
       " 'i',\n",
       " 'got',\n",
       " 'a',\n",
       " 'nice',\n",
       " 'long',\n",
       " 'handwritten',\n",
       " 'letter',\n",
       " 'from',\n",
       " 'my',\n",
       " 'friend',\n",
       " 'and',\n",
       " 'partner',\n",
       " 'and',\n",
       " 'colleague',\n",
       " 'bill',\n",
       " 'clinton',\n",
       " 'saying',\n",
       " 'congratulations',\n",
       " 'on',\n",
       " 'the',\n",
       " 'new',\n",
       " 'restaurant',\n",
       " 'al',\n",
       " 'laughter',\n",
       " 'we',\n",
       " 'like',\n",
       " 'to',\n",
       " 'celebrate',\n",
       " 'each',\n",
       " 'other',\n",
       " 'successes',\n",
       " 'in',\n",
       " 'life',\n",
       " 'laughter',\n",
       " 'i',\n",
       " 'was',\n",
       " 'going',\n",
       " 'to',\n",
       " 'talk',\n",
       " 'about',\n",
       " 'information',\n",
       " 'ecology',\n",
       " 'but',\n",
       " 'i',\n",
       " 'was',\n",
       " 'thinking',\n",
       " 'that',\n",
       " 'since',\n",
       " 'i',\n",
       " 'plan',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'lifelong',\n",
       " 'habit',\n",
       " 'of',\n",
       " 'coming',\n",
       " 'back',\n",
       " 'to',\n",
       " 'ted',\n",
       " 'that',\n",
       " 'maybe',\n",
       " 'i',\n",
       " 'could',\n",
       " 'talk',\n",
       " 'about',\n",
       " 'that',\n",
       " 'another',\n",
       " 'time',\n",
       " 'applause',\n",
       " 'chris',\n",
       " 'anderson',\n",
       " 'it',\n",
       " 'a',\n",
       " 'deal',\n",
       " 'applause',\n",
       " 'al',\n",
       " 'gore',\n",
       " 'i',\n",
       " 'want',\n",
       " 'to',\n",
       " 'focus',\n",
       " 'on',\n",
       " 'what',\n",
       " 'many',\n",
       " 'of',\n",
       " 'you',\n",
       " 'have',\n",
       " 'said',\n",
       " 'you',\n",
       " 'would',\n",
       " 'like',\n",
       " 'me',\n",
       " 'to',\n",
       " 'elaborate',\n",
       " 'on',\n",
       " 'what',\n",
       " 'can',\n",
       " 'you',\n",
       " 'do',\n",
       " 'about',\n",
       " 'the',\n",
       " 'climate',\n",
       " 'crisis',\n",
       " 'i',\n",
       " 'want',\n",
       " 'to',\n",
       " 'start',\n",
       " 'with',\n",
       " 'a',\n",
       " 'couple',\n",
       " 'of',\n",
       " 'i',\n",
       " 'going',\n",
       " 'to',\n",
       " 'show',\n",
       " 'some',\n",
       " 'new',\n",
       " 'images',\n",
       " 'and',\n",
       " 'i',\n",
       " 'going',\n",
       " 'to',\n",
       " 'recapitulate',\n",
       " 'just',\n",
       " 'four',\n",
       " 'or',\n",
       " 'five',\n",
       " 'now',\n",
       " 'the',\n",
       " 'slide',\n",
       " 'show',\n",
       " 'i',\n",
       " 'update',\n",
       " 'the',\n",
       " 'slide',\n",
       " 'show',\n",
       " 'every',\n",
       " 'time',\n",
       " 'i',\n",
       " 'give',\n",
       " 'it',\n",
       " 'i',\n",
       " 'add',\n",
       " 'new',\n",
       " 'images',\n",
       " 'because',\n",
       " 'i',\n",
       " 'learn',\n",
       " 'more',\n",
       " 'about',\n",
       " 'it',\n",
       " 'every',\n",
       " 'time',\n",
       " 'i',\n",
       " 'give',\n",
       " 'it',\n",
       " 'it',\n",
       " 'like',\n",
       " 'beach',\n",
       " 'combing',\n",
       " 'you',\n",
       " 'know',\n",
       " 'every',\n",
       " 'time',\n",
       " 'the',\n",
       " 'tide',\n",
       " 'comes',\n",
       " 'in',\n",
       " 'and',\n",
       " 'out',\n",
       " 'you',\n",
       " 'find',\n",
       " 'some',\n",
       " 'more',\n",
       " 'shells',\n",
       " 'just',\n",
       " 'in',\n",
       " 'the',\n",
       " 'last',\n",
       " 'two',\n",
       " 'days',\n",
       " 'we',\n",
       " 'got',\n",
       " 'the',\n",
       " 'new',\n",
       " 'temperature',\n",
       " 'records',\n",
       " 'in',\n",
       " 'january',\n",
       " 'this',\n",
       " 'is',\n",
       " 'just',\n",
       " 'for',\n",
       " 'the',\n",
       " 'united',\n",
       " 'states',\n",
       " 'of',\n",
       " 'america',\n",
       " 'historical',\n",
       " 'average',\n",
       " 'for',\n",
       " 'januarys',\n",
       " 'is',\n",
       " 'degrees',\n",
       " 'last',\n",
       " 'month',\n",
       " 'was',\n",
       " 'degrees',\n",
       " 'now',\n",
       " 'i',\n",
       " 'know',\n",
       " 'that',\n",
       " 'you',\n",
       " 'wanted',\n",
       " 'some',\n",
       " 'more',\n",
       " 'bad',\n",
       " 'news',\n",
       " 'about',\n",
       " 'the',\n",
       " 'environment',\n",
       " 'i',\n",
       " 'kidding',\n",
       " 'but',\n",
       " 'these',\n",
       " 'are',\n",
       " 'the',\n",
       " 'recapitulation',\n",
       " 'slides',\n",
       " 'and',\n",
       " 'then',\n",
       " 'i',\n",
       " 'going',\n",
       " 'to',\n",
       " 'go',\n",
       " 'into',\n",
       " 'new',\n",
       " 'material',\n",
       " 'about',\n",
       " 'what',\n",
       " 'you',\n",
       " 'can',\n",
       " 'do',\n",
       " 'but',\n",
       " 'i',\n",
       " 'wanted',\n",
       " 'to',\n",
       " 'elaborate',\n",
       " 'on',\n",
       " 'a',\n",
       " 'couple',\n",
       " 'of',\n",
       " 'these',\n",
       " 'first',\n",
       " 'of',\n",
       " 'all',\n",
       " 'this',\n",
       " 'is',\n",
       " 'where',\n",
       " 'we',\n",
       " 'projected',\n",
       " 'to',\n",
       " 'go',\n",
       " 'with',\n",
       " 'the',\n",
       " 'contribution',\n",
       " 'to',\n",
       " 'global',\n",
       " 'warming',\n",
       " 'under',\n",
       " 'business',\n",
       " 'as',\n",
       " 'usual',\n",
       " 'efficiency',\n",
       " 'in',\n",
       " 'end',\n",
       " 'use',\n",
       " 'electricity',\n",
       " 'and',\n",
       " 'end',\n",
       " 'use',\n",
       " 'of',\n",
       " 'all',\n",
       " 'energy',\n",
       " 'is',\n",
       " 'the',\n",
       " 'low',\n",
       " 'hanging',\n",
       " 'fruit',\n",
       " 'efficiency',\n",
       " 'and',\n",
       " 'conservation',\n",
       " 'it',\n",
       " 'not',\n",
       " 'a',\n",
       " 'cost',\n",
       " 'it',\n",
       " 'a',\n",
       " 'profit',\n",
       " 'the',\n",
       " 'sign',\n",
       " 'is',\n",
       " 'wrong',\n",
       " 'it',\n",
       " 'not',\n",
       " 'negative',\n",
       " 'it',\n",
       " 'positive',\n",
       " 'these',\n",
       " 'are',\n",
       " 'investments',\n",
       " 'that',\n",
       " 'pay',\n",
       " 'for',\n",
       " 'themselves',\n",
       " 'but',\n",
       " 'they',\n",
       " 'are',\n",
       " 'also',\n",
       " 'very',\n",
       " 'effective',\n",
       " 'in',\n",
       " 'deflecting',\n",
       " 'our',\n",
       " ...]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ce3a1330",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(doc_texts, window = 10, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5ee68ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('saying', 0.7347651124000549),\n",
       " ('am', 0.7292705774307251),\n",
       " ('swear', 0.7259172201156616),\n",
       " ('sorry', 0.7208622097969055),\n",
       " ('say', 0.7200601100921631),\n",
       " ('remember', 0.7195522785186768),\n",
       " ('wonder', 0.7048721313476562),\n",
       " ('mean', 0.6956779360771179),\n",
       " ('wondering', 0.6921308040618896),\n",
       " ('oh', 0.6743535995483398)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.most_similar(\"guess\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f8ae5c",
   "metadata": {},
   "source": [
    "## Bigrams\n",
    "\n",
    "https://stackoverflow.com/questions/19560044/how-to-concatenate-element-wise-two-lists-in-python\n",
    "https://www.w3schools.com/python/ref_string_format.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2fc74cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_bigrams = []\n",
    "\n",
    "for text_list in doc_texts[:100]:\n",
    "    # Create two lists from the original text list\n",
    "    # The first includes the 0 -> (n-1) words\n",
    "    # The second includes the 1 -> n words\n",
    "    l_text = text_list[:-1]\n",
    "    r_text = text_list[1:]\n",
    "    \n",
    "    # Use zip and format with list comprehension to get a new list\n",
    "    bi_list = [\"{} {}\".format(l_word,r_word) for l_word,r_word in zip(l_text,r_text)]\n",
    "    \n",
    "    doc_bigrams.append(bi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "610c6b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "441e3c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2cc08893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thank you',\n",
       " 'you so',\n",
       " 'so much',\n",
       " 'much chris',\n",
       " 'chris and',\n",
       " 'and it',\n",
       " 'it truly',\n",
       " 'truly a',\n",
       " 'a great',\n",
       " 'great honor',\n",
       " 'honor to',\n",
       " 'to have',\n",
       " 'have the',\n",
       " 'the opportunity',\n",
       " 'opportunity to',\n",
       " 'to come',\n",
       " 'come to',\n",
       " 'to this',\n",
       " 'this stage',\n",
       " 'stage twice',\n",
       " 'twice i',\n",
       " 'i extremely',\n",
       " 'extremely grateful',\n",
       " 'grateful i',\n",
       " 'i have',\n",
       " 'have been',\n",
       " 'been blown',\n",
       " 'blown away',\n",
       " 'away by',\n",
       " 'by this',\n",
       " 'this conference',\n",
       " 'conference and',\n",
       " 'and i',\n",
       " 'i want',\n",
       " 'want to',\n",
       " 'to thank',\n",
       " 'thank all',\n",
       " 'all of',\n",
       " 'of you',\n",
       " 'you for',\n",
       " 'for the',\n",
       " 'the many',\n",
       " 'many nice',\n",
       " 'nice comments',\n",
       " 'comments about',\n",
       " 'about what',\n",
       " 'what i',\n",
       " 'i had',\n",
       " 'had to',\n",
       " 'to say',\n",
       " 'say the',\n",
       " 'the other',\n",
       " 'other night',\n",
       " 'night and',\n",
       " 'and i',\n",
       " 'i say',\n",
       " 'say that',\n",
       " 'that sincerely',\n",
       " 'sincerely partly',\n",
       " 'partly because',\n",
       " 'because mock',\n",
       " 'mock sob',\n",
       " 'sob i',\n",
       " 'i need',\n",
       " 'need that',\n",
       " 'that laughter',\n",
       " 'laughter put',\n",
       " 'put yourselves',\n",
       " 'yourselves in',\n",
       " 'in my',\n",
       " 'my position',\n",
       " 'position laughter',\n",
       " 'laughter i',\n",
       " 'i flew',\n",
       " 'flew on',\n",
       " 'on air',\n",
       " 'air force',\n",
       " 'force two',\n",
       " 'two for',\n",
       " 'for eight',\n",
       " 'eight years',\n",
       " 'years laughter',\n",
       " 'laughter now',\n",
       " 'now i',\n",
       " 'i have',\n",
       " 'have to',\n",
       " 'to take',\n",
       " 'take off',\n",
       " 'off my',\n",
       " 'my shoes',\n",
       " 'shoes or',\n",
       " 'or boots',\n",
       " 'boots to',\n",
       " 'to get',\n",
       " 'get on',\n",
       " 'on an',\n",
       " 'an airplane',\n",
       " 'airplane laughter',\n",
       " 'laughter applause',\n",
       " 'applause i',\n",
       " 'i tell',\n",
       " 'tell you',\n",
       " 'you one',\n",
       " 'one quick',\n",
       " 'quick story',\n",
       " 'story to',\n",
       " 'to illustrate',\n",
       " 'illustrate what',\n",
       " 'what that',\n",
       " 'that been',\n",
       " 'been like',\n",
       " 'like for',\n",
       " 'for me',\n",
       " 'me laughter',\n",
       " 'laughter it',\n",
       " 'it a',\n",
       " 'a true',\n",
       " 'true story',\n",
       " 'story every',\n",
       " 'every bit',\n",
       " 'bit of',\n",
       " 'of this',\n",
       " 'this is',\n",
       " 'is true',\n",
       " 'true soon',\n",
       " 'soon after',\n",
       " 'after tipper',\n",
       " 'tipper and',\n",
       " 'and i',\n",
       " 'i left',\n",
       " 'left the',\n",
       " 'the mock',\n",
       " 'mock sob',\n",
       " 'sob white',\n",
       " 'white house',\n",
       " 'house laughter',\n",
       " 'laughter we',\n",
       " 'we were',\n",
       " 'were driving',\n",
       " 'driving from',\n",
       " 'from our',\n",
       " 'our home',\n",
       " 'home in',\n",
       " 'in nashville',\n",
       " 'nashville to',\n",
       " 'to a',\n",
       " 'a little',\n",
       " 'little farm',\n",
       " 'farm we',\n",
       " 'we have',\n",
       " 'have miles',\n",
       " 'miles east',\n",
       " 'east of',\n",
       " 'of nashville',\n",
       " 'nashville driving',\n",
       " 'driving ourselves',\n",
       " 'ourselves laughter',\n",
       " 'laughter i',\n",
       " 'i know',\n",
       " 'know it',\n",
       " 'it sounds',\n",
       " 'sounds like',\n",
       " 'like a',\n",
       " 'a little',\n",
       " 'little thing',\n",
       " 'thing to',\n",
       " 'to you',\n",
       " 'you but',\n",
       " 'but laughter',\n",
       " 'laughter i',\n",
       " 'i looked',\n",
       " 'looked in',\n",
       " 'in the',\n",
       " 'the rear',\n",
       " 'rear view',\n",
       " 'view mirror',\n",
       " 'mirror and',\n",
       " 'and all',\n",
       " 'all of',\n",
       " 'of a',\n",
       " 'a sudden',\n",
       " 'sudden it',\n",
       " 'it just',\n",
       " 'just hit',\n",
       " 'hit me',\n",
       " 'me there',\n",
       " 'there was',\n",
       " 'was no',\n",
       " 'no motorcade',\n",
       " 'motorcade back',\n",
       " 'back there',\n",
       " 'there laughter',\n",
       " 'laughter you',\n",
       " 'you heard',\n",
       " 'heard of',\n",
       " 'of phantom',\n",
       " 'phantom limb',\n",
       " 'limb pain',\n",
       " 'pain laughter',\n",
       " 'laughter this',\n",
       " 'this was',\n",
       " 'was a',\n",
       " 'a rented',\n",
       " 'rented ford',\n",
       " 'ford taurus',\n",
       " 'taurus laughter',\n",
       " 'laughter it',\n",
       " 'it was',\n",
       " 'was dinnertime',\n",
       " 'dinnertime and',\n",
       " 'and we',\n",
       " 'we started',\n",
       " 'started looking',\n",
       " 'looking for',\n",
       " 'for a',\n",
       " 'a place',\n",
       " 'place to',\n",
       " 'to eat',\n",
       " 'eat we',\n",
       " 'we were',\n",
       " 'were on',\n",
       " 'on i',\n",
       " 'i we',\n",
       " 'we got',\n",
       " 'got to',\n",
       " 'to exit',\n",
       " 'exit lebanon',\n",
       " 'lebanon tennessee',\n",
       " 'tennessee we',\n",
       " 'we got',\n",
       " 'got off',\n",
       " 'off the',\n",
       " 'the exit',\n",
       " 'exit we',\n",
       " 'we found',\n",
       " 'found a',\n",
       " 'a shoney',\n",
       " 'shoney restaurant',\n",
       " 'restaurant low',\n",
       " 'low cost',\n",
       " 'cost family',\n",
       " 'family restaurant',\n",
       " 'restaurant chain',\n",
       " 'chain for',\n",
       " 'for those',\n",
       " 'those of',\n",
       " 'of you',\n",
       " 'you who',\n",
       " 'who don',\n",
       " 'don know',\n",
       " 'know it',\n",
       " 'it we',\n",
       " 'we went',\n",
       " 'went in',\n",
       " 'in and',\n",
       " 'and sat',\n",
       " 'sat down',\n",
       " 'down at',\n",
       " 'at the',\n",
       " 'the booth',\n",
       " 'booth and',\n",
       " 'and the',\n",
       " 'the waitress',\n",
       " 'waitress came',\n",
       " 'came over',\n",
       " 'over made',\n",
       " 'made a',\n",
       " 'a big',\n",
       " 'big commotion',\n",
       " 'commotion over',\n",
       " 'over tipper',\n",
       " 'tipper laughter',\n",
       " 'laughter she',\n",
       " 'she took',\n",
       " 'took our',\n",
       " 'our order',\n",
       " 'order and',\n",
       " 'and then',\n",
       " 'then went',\n",
       " 'went to',\n",
       " 'to the',\n",
       " 'the couple',\n",
       " 'couple in',\n",
       " 'in the',\n",
       " 'the booth',\n",
       " 'booth next',\n",
       " 'next to',\n",
       " 'to us',\n",
       " 'us and',\n",
       " 'and she',\n",
       " 'she lowered',\n",
       " 'lowered her',\n",
       " 'her voice',\n",
       " 'voice so',\n",
       " 'so much',\n",
       " 'much i',\n",
       " 'i had',\n",
       " 'had to',\n",
       " 'to really',\n",
       " 'really strain',\n",
       " 'strain to',\n",
       " 'to hear',\n",
       " 'hear what',\n",
       " 'what she',\n",
       " 'she was',\n",
       " 'was saying',\n",
       " 'saying and',\n",
       " 'and she',\n",
       " 'she said',\n",
       " 'said yes',\n",
       " 'yes that',\n",
       " 'that former',\n",
       " 'former vice',\n",
       " 'vice president',\n",
       " 'president al',\n",
       " 'al gore',\n",
       " 'gore and',\n",
       " 'and his',\n",
       " 'his wife',\n",
       " 'wife tipper',\n",
       " 'tipper and',\n",
       " 'and the',\n",
       " 'the man',\n",
       " 'man said',\n",
       " 'said he',\n",
       " 'he come',\n",
       " 'come down',\n",
       " 'down a',\n",
       " 'a long',\n",
       " 'long way',\n",
       " 'way hasn',\n",
       " 'hasn he',\n",
       " 'he laughter',\n",
       " 'laughter applause',\n",
       " 'applause there',\n",
       " 'there been',\n",
       " 'been kind',\n",
       " 'kind of',\n",
       " 'of a',\n",
       " 'a series',\n",
       " 'series of',\n",
       " 'of epiphanies',\n",
       " 'epiphanies laughter',\n",
       " 'laughter the',\n",
       " 'the very',\n",
       " 'very next',\n",
       " 'next day',\n",
       " 'day continuing',\n",
       " 'continuing the',\n",
       " 'the totally',\n",
       " 'totally true',\n",
       " 'true story',\n",
       " 'story i',\n",
       " 'i got',\n",
       " 'got on',\n",
       " 'on a',\n",
       " 'a to',\n",
       " 'to fly',\n",
       " 'fly to',\n",
       " 'to africa',\n",
       " 'africa to',\n",
       " 'to make',\n",
       " 'make a',\n",
       " 'a speech',\n",
       " 'speech in',\n",
       " 'in nigeria',\n",
       " 'nigeria in',\n",
       " 'in the',\n",
       " 'the city',\n",
       " 'city of',\n",
       " 'of lagos',\n",
       " 'lagos on',\n",
       " 'on the',\n",
       " 'the topic',\n",
       " 'topic of',\n",
       " 'of energy',\n",
       " 'energy and',\n",
       " 'and i',\n",
       " 'i began',\n",
       " 'began the',\n",
       " 'the speech',\n",
       " 'speech by',\n",
       " 'by telling',\n",
       " 'telling them',\n",
       " 'them the',\n",
       " 'the story',\n",
       " 'story of',\n",
       " 'of what',\n",
       " 'what had',\n",
       " 'had just',\n",
       " 'just happened',\n",
       " 'happened the',\n",
       " 'the day',\n",
       " 'day before',\n",
       " 'before in',\n",
       " 'in nashville',\n",
       " 'nashville and',\n",
       " 'and i',\n",
       " 'i told',\n",
       " 'told it',\n",
       " 'it pretty',\n",
       " 'pretty much',\n",
       " 'much the',\n",
       " 'the same',\n",
       " 'same way',\n",
       " 'way i',\n",
       " 'i just',\n",
       " 'just shared',\n",
       " 'shared it',\n",
       " 'it with',\n",
       " 'with you',\n",
       " 'you tipper',\n",
       " 'tipper and',\n",
       " 'and i',\n",
       " 'i were',\n",
       " 'were driving',\n",
       " 'driving ourselves',\n",
       " 'ourselves shoney',\n",
       " 'shoney low',\n",
       " 'low cost',\n",
       " 'cost family',\n",
       " 'family restaurant',\n",
       " 'restaurant chain',\n",
       " 'chain what',\n",
       " 'what the',\n",
       " 'the man',\n",
       " 'man said',\n",
       " 'said they',\n",
       " 'they laughed',\n",
       " 'laughed i',\n",
       " 'i gave',\n",
       " 'gave my',\n",
       " 'my speech',\n",
       " 'speech then',\n",
       " 'then went',\n",
       " 'went back',\n",
       " 'back out',\n",
       " 'out to',\n",
       " 'to the',\n",
       " 'the airport',\n",
       " 'airport to',\n",
       " 'to fly',\n",
       " 'fly back',\n",
       " 'back home',\n",
       " 'home i',\n",
       " 'i fell',\n",
       " 'fell asleep',\n",
       " 'asleep on',\n",
       " 'on the',\n",
       " 'the plane',\n",
       " 'plane until',\n",
       " 'until during',\n",
       " 'during the',\n",
       " 'the middle',\n",
       " 'middle of',\n",
       " 'of the',\n",
       " 'the night',\n",
       " 'night we',\n",
       " 'we landed',\n",
       " 'landed on',\n",
       " 'on the',\n",
       " 'the azores',\n",
       " 'azores islands',\n",
       " 'islands for',\n",
       " 'for refueling',\n",
       " 'refueling i',\n",
       " 'i woke',\n",
       " 'woke up',\n",
       " 'up they',\n",
       " 'they opened',\n",
       " 'opened the',\n",
       " 'the door',\n",
       " 'door i',\n",
       " 'i went',\n",
       " 'went out',\n",
       " 'out to',\n",
       " 'to get',\n",
       " 'get some',\n",
       " 'some fresh',\n",
       " 'fresh air',\n",
       " 'air and',\n",
       " 'and i',\n",
       " 'i looked',\n",
       " 'looked and',\n",
       " 'and there',\n",
       " 'there was',\n",
       " 'was a',\n",
       " 'a man',\n",
       " 'man running',\n",
       " 'running across',\n",
       " 'across the',\n",
       " 'the runway',\n",
       " 'runway and',\n",
       " 'and he',\n",
       " 'he was',\n",
       " 'was waving',\n",
       " 'waving a',\n",
       " 'a piece',\n",
       " 'piece of',\n",
       " 'of paper',\n",
       " 'paper and',\n",
       " 'and he',\n",
       " 'he was',\n",
       " 'was yelling',\n",
       " 'yelling call',\n",
       " 'call washington',\n",
       " 'washington call',\n",
       " 'call washington',\n",
       " 'washington and',\n",
       " 'and i',\n",
       " 'i thought',\n",
       " 'thought to',\n",
       " 'to myself',\n",
       " 'myself in',\n",
       " 'in the',\n",
       " 'the middle',\n",
       " 'middle of',\n",
       " 'of the',\n",
       " 'the night',\n",
       " 'night in',\n",
       " 'in the',\n",
       " 'the middle',\n",
       " 'middle of',\n",
       " 'of the',\n",
       " 'the atlantic',\n",
       " 'atlantic what',\n",
       " 'what in',\n",
       " 'in the',\n",
       " 'the world',\n",
       " 'world could',\n",
       " 'could be',\n",
       " 'be wrong',\n",
       " 'wrong in',\n",
       " 'in washington',\n",
       " 'washington then',\n",
       " 'then i',\n",
       " 'i remembered',\n",
       " 'remembered it',\n",
       " 'it could',\n",
       " 'could be',\n",
       " 'be a',\n",
       " 'a bunch',\n",
       " 'bunch of',\n",
       " 'of things',\n",
       " 'things laughter',\n",
       " 'laughter but',\n",
       " 'but what',\n",
       " 'what it',\n",
       " 'it turned',\n",
       " 'turned out',\n",
       " 'out to',\n",
       " 'to be',\n",
       " 'be was',\n",
       " 'was that',\n",
       " 'that my',\n",
       " 'my staff',\n",
       " 'staff was',\n",
       " 'was extremely',\n",
       " 'extremely upset',\n",
       " 'upset because',\n",
       " 'because one',\n",
       " 'one of',\n",
       " 'of the',\n",
       " 'the wire',\n",
       " 'wire services',\n",
       " 'services in',\n",
       " 'in nigeria',\n",
       " 'nigeria had',\n",
       " 'had already',\n",
       " 'already written',\n",
       " 'written a',\n",
       " 'a story',\n",
       " 'story about',\n",
       " 'about my',\n",
       " 'my speech',\n",
       " 'speech and',\n",
       " 'and it',\n",
       " 'it had',\n",
       " 'had already',\n",
       " 'already been',\n",
       " 'been printed',\n",
       " 'printed in',\n",
       " 'in cities',\n",
       " 'cities all',\n",
       " 'all across',\n",
       " 'across the',\n",
       " 'the united',\n",
       " 'united states',\n",
       " 'states of',\n",
       " 'of america',\n",
       " 'america it',\n",
       " 'it was',\n",
       " 'was printed',\n",
       " 'printed in',\n",
       " 'in monterey',\n",
       " 'monterey i',\n",
       " 'i checked',\n",
       " 'checked laughter',\n",
       " 'laughter and',\n",
       " 'and the',\n",
       " 'the story',\n",
       " 'story began',\n",
       " 'began former',\n",
       " 'former vice',\n",
       " 'vice president',\n",
       " 'president al',\n",
       " 'al gore',\n",
       " 'gore announced',\n",
       " 'announced in',\n",
       " 'in nigeria',\n",
       " 'nigeria yesterday',\n",
       " 'yesterday quote',\n",
       " 'quote my',\n",
       " 'my wife',\n",
       " 'wife tipper',\n",
       " 'tipper and',\n",
       " 'and i',\n",
       " 'i have',\n",
       " 'have opened',\n",
       " 'opened a',\n",
       " 'a low',\n",
       " 'low cost',\n",
       " 'cost family',\n",
       " 'family restaurant',\n",
       " 'restaurant laughter',\n",
       " 'laughter named',\n",
       " 'named shoney',\n",
       " 'shoney and',\n",
       " 'and we',\n",
       " 'we are',\n",
       " 'are running',\n",
       " 'running it',\n",
       " 'it ourselves',\n",
       " 'ourselves laughter',\n",
       " 'laughter before',\n",
       " 'before i',\n",
       " 'i could',\n",
       " 'could get',\n",
       " 'get back',\n",
       " 'back to',\n",
       " 'to soil',\n",
       " 'soil david',\n",
       " 'david letterman',\n",
       " 'letterman and',\n",
       " 'and jay',\n",
       " 'jay leno',\n",
       " 'leno had',\n",
       " 'had already',\n",
       " 'already started',\n",
       " 'started in',\n",
       " 'in on',\n",
       " 'on one',\n",
       " 'one of',\n",
       " 'of them',\n",
       " 'them had',\n",
       " 'had me',\n",
       " 'me in',\n",
       " 'in a',\n",
       " 'a big',\n",
       " 'big white',\n",
       " 'white chef',\n",
       " 'chef hat',\n",
       " 'hat tipper',\n",
       " 'tipper was',\n",
       " 'was saying',\n",
       " 'saying one',\n",
       " 'one more',\n",
       " 'more burger',\n",
       " 'burger with',\n",
       " 'with fries',\n",
       " 'fries laughter',\n",
       " 'laughter three',\n",
       " 'three days',\n",
       " 'days later',\n",
       " 'later i',\n",
       " 'i got',\n",
       " 'got a',\n",
       " 'a nice',\n",
       " 'nice long',\n",
       " 'long handwritten',\n",
       " 'handwritten letter',\n",
       " 'letter from',\n",
       " 'from my',\n",
       " 'my friend',\n",
       " 'friend and',\n",
       " 'and partner',\n",
       " 'partner and',\n",
       " 'and colleague',\n",
       " 'colleague bill',\n",
       " 'bill clinton',\n",
       " 'clinton saying',\n",
       " 'saying congratulations',\n",
       " 'congratulations on',\n",
       " 'on the',\n",
       " 'the new',\n",
       " 'new restaurant',\n",
       " 'restaurant al',\n",
       " 'al laughter',\n",
       " 'laughter we',\n",
       " 'we like',\n",
       " 'like to',\n",
       " 'to celebrate',\n",
       " 'celebrate each',\n",
       " 'each other',\n",
       " 'other successes',\n",
       " 'successes in',\n",
       " 'in life',\n",
       " 'life laughter',\n",
       " 'laughter i',\n",
       " 'i was',\n",
       " 'was going',\n",
       " 'going to',\n",
       " 'to talk',\n",
       " 'talk about',\n",
       " 'about information',\n",
       " 'information ecology',\n",
       " 'ecology but',\n",
       " 'but i',\n",
       " 'i was',\n",
       " 'was thinking',\n",
       " 'thinking that',\n",
       " 'that since',\n",
       " 'since i',\n",
       " 'i plan',\n",
       " 'plan to',\n",
       " 'to make',\n",
       " 'make a',\n",
       " 'a lifelong',\n",
       " 'lifelong habit',\n",
       " 'habit of',\n",
       " 'of coming',\n",
       " 'coming back',\n",
       " 'back to',\n",
       " 'to ted',\n",
       " 'ted that',\n",
       " 'that maybe',\n",
       " 'maybe i',\n",
       " 'i could',\n",
       " 'could talk',\n",
       " 'talk about',\n",
       " 'about that',\n",
       " 'that another',\n",
       " 'another time',\n",
       " 'time applause',\n",
       " 'applause chris',\n",
       " 'chris anderson',\n",
       " 'anderson it',\n",
       " 'it a',\n",
       " 'a deal',\n",
       " 'deal applause',\n",
       " 'applause al',\n",
       " 'al gore',\n",
       " 'gore i',\n",
       " 'i want',\n",
       " 'want to',\n",
       " 'to focus',\n",
       " 'focus on',\n",
       " 'on what',\n",
       " 'what many',\n",
       " 'many of',\n",
       " 'of you',\n",
       " 'you have',\n",
       " 'have said',\n",
       " 'said you',\n",
       " 'you would',\n",
       " 'would like',\n",
       " 'like me',\n",
       " 'me to',\n",
       " 'to elaborate',\n",
       " 'elaborate on',\n",
       " 'on what',\n",
       " 'what can',\n",
       " 'can you',\n",
       " 'you do',\n",
       " 'do about',\n",
       " 'about the',\n",
       " 'the climate',\n",
       " 'climate crisis',\n",
       " 'crisis i',\n",
       " 'i want',\n",
       " 'want to',\n",
       " 'to start',\n",
       " 'start with',\n",
       " 'with a',\n",
       " 'a couple',\n",
       " 'couple of',\n",
       " 'of i',\n",
       " 'i going',\n",
       " 'going to',\n",
       " 'to show',\n",
       " 'show some',\n",
       " 'some new',\n",
       " 'new images',\n",
       " 'images and',\n",
       " 'and i',\n",
       " 'i going',\n",
       " 'going to',\n",
       " 'to recapitulate',\n",
       " 'recapitulate just',\n",
       " 'just four',\n",
       " 'four or',\n",
       " 'or five',\n",
       " 'five now',\n",
       " 'now the',\n",
       " 'the slide',\n",
       " 'slide show',\n",
       " 'show i',\n",
       " 'i update',\n",
       " 'update the',\n",
       " 'the slide',\n",
       " 'slide show',\n",
       " 'show every',\n",
       " 'every time',\n",
       " 'time i',\n",
       " 'i give',\n",
       " 'give it',\n",
       " 'it i',\n",
       " 'i add',\n",
       " 'add new',\n",
       " 'new images',\n",
       " 'images because',\n",
       " 'because i',\n",
       " 'i learn',\n",
       " 'learn more',\n",
       " 'more about',\n",
       " 'about it',\n",
       " 'it every',\n",
       " 'every time',\n",
       " 'time i',\n",
       " 'i give',\n",
       " 'give it',\n",
       " 'it it',\n",
       " 'it like',\n",
       " 'like beach',\n",
       " 'beach combing',\n",
       " 'combing you',\n",
       " 'you know',\n",
       " 'know every',\n",
       " 'every time',\n",
       " 'time the',\n",
       " 'the tide',\n",
       " 'tide comes',\n",
       " 'comes in',\n",
       " 'in and',\n",
       " 'and out',\n",
       " 'out you',\n",
       " 'you find',\n",
       " 'find some',\n",
       " 'some more',\n",
       " 'more shells',\n",
       " 'shells just',\n",
       " 'just in',\n",
       " 'in the',\n",
       " 'the last',\n",
       " 'last two',\n",
       " 'two days',\n",
       " 'days we',\n",
       " 'we got',\n",
       " 'got the',\n",
       " 'the new',\n",
       " 'new temperature',\n",
       " 'temperature records',\n",
       " 'records in',\n",
       " 'in january',\n",
       " 'january this',\n",
       " 'this is',\n",
       " 'is just',\n",
       " 'just for',\n",
       " 'for the',\n",
       " 'the united',\n",
       " 'united states',\n",
       " 'states of',\n",
       " 'of america',\n",
       " 'america historical',\n",
       " 'historical average',\n",
       " 'average for',\n",
       " 'for januarys',\n",
       " 'januarys is',\n",
       " 'is degrees',\n",
       " 'degrees last',\n",
       " 'last month',\n",
       " 'month was',\n",
       " 'was degrees',\n",
       " 'degrees now',\n",
       " 'now i',\n",
       " 'i know',\n",
       " 'know that',\n",
       " 'that you',\n",
       " 'you wanted',\n",
       " 'wanted some',\n",
       " 'some more',\n",
       " 'more bad',\n",
       " 'bad news',\n",
       " 'news about',\n",
       " 'about the',\n",
       " 'the environment',\n",
       " 'environment i',\n",
       " 'i kidding',\n",
       " 'kidding but',\n",
       " 'but these',\n",
       " 'these are',\n",
       " 'are the',\n",
       " 'the recapitulation',\n",
       " 'recapitulation slides',\n",
       " 'slides and',\n",
       " 'and then',\n",
       " 'then i',\n",
       " 'i going',\n",
       " 'going to',\n",
       " 'to go',\n",
       " 'go into',\n",
       " 'into new',\n",
       " 'new material',\n",
       " 'material about',\n",
       " 'about what',\n",
       " 'what you',\n",
       " 'you can',\n",
       " 'can do',\n",
       " 'do but',\n",
       " 'but i',\n",
       " 'i wanted',\n",
       " 'wanted to',\n",
       " 'to elaborate',\n",
       " 'elaborate on',\n",
       " 'on a',\n",
       " 'a couple',\n",
       " 'couple of',\n",
       " 'of these',\n",
       " 'these first',\n",
       " 'first of',\n",
       " 'of all',\n",
       " 'all this',\n",
       " 'this is',\n",
       " 'is where',\n",
       " 'where we',\n",
       " 'we projected',\n",
       " 'projected to',\n",
       " 'to go',\n",
       " 'go with',\n",
       " 'with the',\n",
       " 'the contribution',\n",
       " 'contribution to',\n",
       " 'to global',\n",
       " 'global warming',\n",
       " 'warming under',\n",
       " 'under business',\n",
       " 'business as',\n",
       " 'as usual',\n",
       " 'usual efficiency',\n",
       " 'efficiency in',\n",
       " 'in end',\n",
       " 'end use',\n",
       " 'use electricity',\n",
       " 'electricity and',\n",
       " 'and end',\n",
       " 'end use',\n",
       " 'use of',\n",
       " 'of all',\n",
       " 'all energy',\n",
       " 'energy is',\n",
       " 'is the',\n",
       " 'the low',\n",
       " 'low hanging',\n",
       " 'hanging fruit',\n",
       " 'fruit efficiency',\n",
       " 'efficiency and',\n",
       " 'and conservation',\n",
       " 'conservation it',\n",
       " 'it not',\n",
       " 'not a',\n",
       " 'a cost',\n",
       " 'cost it',\n",
       " 'it a',\n",
       " 'a profit',\n",
       " 'profit the',\n",
       " 'the sign',\n",
       " 'sign is',\n",
       " 'is wrong',\n",
       " 'wrong it',\n",
       " 'it not',\n",
       " 'not negative',\n",
       " 'negative it',\n",
       " 'it positive',\n",
       " 'positive these',\n",
       " 'these are',\n",
       " 'are investments',\n",
       " 'investments that',\n",
       " 'that pay',\n",
       " 'pay for',\n",
       " 'for themselves',\n",
       " 'themselves but',\n",
       " 'but they',\n",
       " 'they are',\n",
       " 'are also',\n",
       " 'also very',\n",
       " 'very effective',\n",
       " 'effective in',\n",
       " 'in deflecting',\n",
       " 'deflecting our',\n",
       " 'our path',\n",
       " ...]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_bigrams[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b93459ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram2vec = Word2Vec(doc_bigrams, min_count=5, window = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062813a9",
   "metadata": {},
   "source": [
    "### 20 talks, default window\n",
    "bigram2vec.wv.most_similar(\"kind of\")\n",
    "\n",
    "`[('is the', 0.9678242802619934),\n",
    " ('of the', 0.9669575691223145),\n",
    " ('it s', 0.9658999443054199),\n",
    " ('in the', 0.9641684889793396),\n",
    " ('and i', 0.9638648629188538),\n",
    " ('on the', 0.9616329669952393),\n",
    " ('and the', 0.9615666270256042),\n",
    " ('if you', 0.9613533616065979),\n",
    " ('you can', 0.9594166874885559),\n",
    " ('to do', 0.959026575088501)]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d36e60",
   "metadata": {},
   "source": [
    "### 100 talks, default window\n",
    "bigram2vec.wv.most_similar(\"kind of\")\n",
    "\n",
    "`[('on the', 0.9999475479125977),\n",
    " ('of a', 0.9999454021453857),\n",
    " ('sort of', 0.9999436736106873),\n",
    " ('and the', 0.9999433755874634),\n",
    " ('into the', 0.9999430179595947),\n",
    " ('and he', 0.9999375343322754),\n",
    " ('it the', 0.9999349117279053),\n",
    " ('on a', 0.9999347925186157),\n",
    " ('from the', 0.9999346733093262),\n",
    " ('in this', 0.9999346733093262)]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6c82aa",
   "metadata": {},
   "source": [
    "### 100 talks, window = 20\n",
    "bigram2vec.wv.most_similar(\"kind of\")\n",
    "\n",
    "`[('of a', 0.9999916553497314),\n",
    " ('into the', 0.999990701675415),\n",
    " ('it a', 0.9999901056289673),\n",
    " ('on the', 0.9999899864196777),\n",
    " ('on a', 0.9999896287918091),\n",
    " ('it the', 0.9999895691871643),\n",
    " ('sort of', 0.99998939037323),\n",
    " ('like this', 0.9999883770942688),\n",
    " ('and a', 0.9999881982803345),\n",
    " ('to a', 0.9999878406524658)]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba4ba8",
   "metadata": {},
   "source": [
    "### 100 talks, window = 20, min = 5\n",
    "bigram2vec.wv.most_similar(\"kind of\")\n",
    "\n",
    "`[('on a', 0.9999414682388306),\n",
    " ('sort of', 0.9999383687973022),\n",
    " ('into the', 0.9999372959136963),\n",
    " ('in a', 0.9999362230300903),\n",
    " ('it the', 0.9999334812164307),\n",
    " ('it a', 0.9999327659606934),\n",
    " ('to a', 0.9999301433563232),\n",
    " ('so it', 0.9999282360076904),\n",
    " ('and a', 0.9999277591705322),\n",
    " ('like a', 0.9999269247055054)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bb38ed0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('on a', 0.9999414682388306),\n",
       " ('sort of', 0.9999383687973022),\n",
       " ('into the', 0.9999372959136963),\n",
       " ('in a', 0.9999362230300903),\n",
       " ('it the', 0.9999334812164307),\n",
       " ('it a', 0.9999327659606934),\n",
       " ('to a', 0.9999301433563232),\n",
       " ('so it', 0.9999282360076904),\n",
       " ('and a', 0.9999277591705322),\n",
       " ('like a', 0.9999269247055054)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram2vec.wv.most_similar(\"kind of\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707a4fbe",
   "metadata": {},
   "source": [
    "# Scratch work below here\n",
    "\n",
    "## WANT: a list of lists \n",
    "\n",
    " * Each text should be preserved \n",
    " * Then we should create a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe11cfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "test = ['one',\"Two\\'s\",'.ThreE']\n",
    "#test = partitioned_texts[0:3]\n",
    "print(len(test))\n",
    "#https://www.delftstack.com/howto/python/python-lowercase-list/\n",
    "\n",
    "test = [word.lower() for word in test]\n",
    "print(len(test))\n",
    "test = [re.sub('[^a-zA-Z]', ' ', word) for word in test]\n",
    "print(len(test))\n",
    "test= [re.sub(r'\\s+', ' ', word) for word in test]\n",
    "print(len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d2db97ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', 'two s', ' three']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8176f03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'two and'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stoplist('two s and')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "81a380ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = [remove_stoplist(text) for text in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d278cc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', 'two', 'three']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "30d59411",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = [remove_stoplist(text) for text in test]\n",
    "\n",
    "test_texts = [nltk.word_tokenize(text) for text in test_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8c0d27a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['one'], ['two'], ['three']]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dacc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "constants = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0eb0955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_letters = string.ascii_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ba3686c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = list(all_letters[:26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "55d44d4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'pop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6h/xgfgqk0j3cs7fqvzc0b6l868t3nxsy/T/ipykernel_44867/2532388332.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'pop'"
     ]
    }
   ],
   "source": [
    "stops.pop(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "40e796d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "148e35a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3935e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba6a0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_texts = [text.lower() for text in partitioned_texts]\n",
    "processed_texts = [re.sub('[^a-zA-Z]', ' ', text) for text in processed_texts]\n",
    "processed_texts = [re.sub(r'\\s+', ' ', text) for text in processed_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43760ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test_sub[:-1]\n",
    "test2 = test_sub[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5629f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1\n",
    "test2\n",
    "\n",
    "test3 = []\n",
    "for inds in range(len(test1)):\n",
    "    bigram = test1[inds] + \" \" + test2[inds]\n",
    "    test3.append(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3dba1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one twos', 'twos three']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "349d1ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one twos', 'twos three']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"{} {}\".format(l_word,r_word) for l_word,r_word in zip(test1,test2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9d5ffe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twos\n",
      "three\n"
     ]
    }
   ],
   "source": [
    "for l_word,r_word in zip(test1,test2):\n",
    "    print(r_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ac4168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66abb41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8b04535",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_texts = text_all.lower()\n",
    "processed_texts = re.sub('[^a-zA-Z]', ' ', processed_texts)\n",
    "processed_texts = re.sub(r'\\s+', ' ', processed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c79d74a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' thank you so much chris and it s truly a great ho'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_texts[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e9c01f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://stackabuse.com/implementing-word2vec-with-gensim-library-in-python/\n",
    "\n",
    "all_sentences = nltk.sent_tokenize(processed_texts)\n",
    "\n",
    "all_words = [nltk.word_tokenize(sent) for sent in all_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9db6b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82c523ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10699443"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f51c9481",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Word2Vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6h/xgfgqk0j3cs7fqvzc0b6l868t3nxsy/T/ipykernel_19515/3725673184.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Word2Vec' is not defined"
     ]
    }
   ],
   "source": [
    "word2vec = Word2Vec(all_words, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d705e8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
