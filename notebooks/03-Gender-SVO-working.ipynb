{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject-Verb-Objects\n",
    "\n",
    "In this notebook, we conduct a series of experiments in order: \n",
    "\n",
    "- **First**, we isolate the subject-verb-object (SVO) triples in the texts of speakers we have gendered male or female. (Using a pandas dataframe, we save the results to s CSV files for later re-use.)\n",
    "- **Second**, we compare the SVO count against the overall sentence count to determine how much of the texts have been included for analysis. See [Counts of Sentences vs SVOs](#sentences).\n",
    "- **Third**, we explore usage of male and female pronouns and nouns as subjects in both corpus: first by raw count, and then by actions (verbs) associated with those nouns and pronouns. See: [Gendered Subjects](#genderedsubjects)\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">It might be useful to find a way to combine verbs via WordNet.</div>\n",
    "\n",
    "- **Fourth**, we map the objects associated with those actions. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">The same wish, to compress a variety of words under some form of hypernym.</div>\n",
    "\n",
    "then to explore the *character spaces* they establish for gendered entities within their speech as well as the nature of the *character space* they create for themselves as speakers. \n",
    "\n",
    "**Note**: We are not excluding parentheticals in this notebook.\n",
    "\n",
    "**Next Steps**: Work on code to compile / visualize this as a network graph (?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From our 992x14 CSV, we have a list of 992 talks: 260 by women and 720 by men.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import re, spacy, textacy\n",
    "import pandas as pd\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "# Loading the Data in a gendered partitioned fashion: \n",
    "talks_m = pd.read_csv('talks_male.csv', index_col='Talk_ID')\n",
    "talks_f = pd.read_csv('talks_female.csv', index_col='Talk_ID')\n",
    "talks_nog = pd.read_csv('talks_nog.csv', index_col='Talk_ID')\n",
    "talks_all = pd.concat([talks_m, talks_f, talks_nog])\n",
    "\n",
    "# And then grabbing on the texts of the talks:\n",
    "texts_all = talks_all.text.tolist()\n",
    "texts_women = talks_f.text.tolist()\n",
    "texts_men = talks_m.text.tolist()\n",
    "\n",
    "print(f\"From our {talks_all.shape[0]}x{talks_all.shape[1]} CSV, \\\n",
    "we have a list of {len(texts_all)} talks: {len(texts_women)} by women and \\\n",
    "{len(texts_men)} by men.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowercasing everything upfront because we don't care whether it is *She* or *she*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase everything before we create spaCy doc and Textacy SVO triple\n",
    "texts_w = [text.lower() for text in texts_women]\n",
    "texts_m = [text.lower() for text in texts_men]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Create the SVOs\n",
    "\n",
    "spaCy has three different English language models: small, medium, and large. We use the large model here because our corpus is small and the syntax may be a bit more involved. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> We need to make sure we understand the difference between the models.</div>\n",
    "\n",
    "After determining telling spaCy which model to use, we then use its conventions for feeding a set of texts as a list of strings, to it. \n",
    "\n",
    "The preview simply checks that everything went as planned: it gives us a word count and the first 50 characters -- which is weird because in theory it has converted the string to a series of spacy objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Doc(2690 tokens: \"  thank you so much, chris. and it\\'s truly a gr...\")'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Space pipeline to be used\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# Use the pipe method to feed documents \n",
    "docs_w = list(nlp.pipe(texts_w))\n",
    "docs_m = list(nlp.pipe(texts_m))\n",
    "\n",
    "# A quick check of our work:\n",
    "docs_m[0]._.preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. SVOs to Dataframe\n",
    "\n",
    "Since we create SVOs for every sentence in the two subcorpora, why not save both to two dataframes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actions(doc, svo_list):\n",
    "    svotriples = list(textacy.extract.triples.subject_verb_object_triples(doc))\n",
    "    for item in svotriples:\n",
    "        svo_list.append(\n",
    "            {\n",
    "                'subject': str(item[0][-1]), \n",
    "                'verb': str(item[1][-1]), \n",
    "                'object': str(item[2])\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80331, 3) (26527, 3)\n"
     ]
    }
   ],
   "source": [
    "# Create the two lists\n",
    "all_svos_m = []\n",
    "all_svos_w = []\n",
    "\n",
    "# Populate the lists with SVO triples\n",
    "for doc in docs_m:\n",
    "    actions(doc, all_svos_m)\n",
    "\n",
    "for doc in docs_w:\n",
    "    actions(doc, all_svos_w)\n",
    "\n",
    "# Convert the lists to dataframes\n",
    "svos_w = pd.DataFrame(all_svos_w)\n",
    "svos_m = pd.DataFrame(all_svos_m)\n",
    "\n",
    "print(svos_m.shape, svos_w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV files\n",
    "svos_w.to_csv(\"../output/svos_w.csv\")\n",
    "svos_m.to_csv(\"../output/svos_m.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "In a prior code run, we had fed the function a list of pronouns asked it to output only those SVOs: `pronouns = ['i', 'we', 'she', 'he', 'they', 'it', 'you']`.\n",
    "\n",
    "Comparing the two outputs: there are 80,331 SVOs in total in the male speaker subcorpora and 56,781 begin with on of the pronouns listed above and 26,527 total SVOs for the female speaker subcorpus with 18,602 beginning with pronouns, then the preponderance of sentences in TED talks begin with a rather small set of pronouns:\n",
    "\n",
    "```\n",
    "male:   56,781 / 80,331 = .706\n",
    "female: 18,602 / 26,527 = .701\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Counts of Sentences vs SVOs <a id='sentences'></a>\n",
    "\n",
    "The code above suggests that 70% of the SVOs in TED talks have `'i', 'we', 'she', 'he', 'they', 'it', 'you'` as their subject. It's not clear, however, how much the SVO pattern represents all sentences in the talks. In this section we explore counting sentences, both through NLTK and spaCy, but also a hand count of a few sample texts to see how well our code is reflecting underlying realities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n"
     ]
    }
   ],
   "source": [
    "sents_w = [ sent_tokenize(text) for text in texts_w ]    \n",
    "sents_m = [ sent_tokenize(text) for text in texts_m ]\n",
    "\n",
    "print(len(sents_w[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Female corp sent count: 30799\n",
      " Male corp sent count: 96342\n"
     ]
    }
   ],
   "source": [
    "sent_count_m = 0\n",
    "for text in texts_m:\n",
    "    sent_count_m += len(sent_tokenize(text))\n",
    "\n",
    "sent_count_w = 0\n",
    "for text in texts_w:\n",
    "    sent_count_w += len(sent_tokenize(text))\n",
    "\n",
    "print(f\" Female corp sent count: {sent_count_w}\\n Male corp sent count: {sent_count_m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That results in the following percentages of SVOs out of the total number of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female subcorpora: 0.861294197863567\n",
      "Male subcorpora: 0.8338107990284611\n"
     ]
    }
   ],
   "source": [
    "print(f\"Female subcorpora: {svos_w.shape[0] / sent_count_w}\")\n",
    "print(f\"Male subcorpora: {svos_m.shape[0] / sent_count_m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy\n",
    "\n",
    "Our spaCy documents already exist, so we just need to use the `.sents` method to call the sentences and count them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F: 31673, M: 99039.\n"
     ]
    }
   ],
   "source": [
    "snt_cnt_w = 0\n",
    "for doc in docs_w:\n",
    "    snt_cnt_w += len(list(doc.sents))\n",
    "\n",
    "snt_cnt_m = 0\n",
    "for doc in docs_m:\n",
    "    snt_cnt_m += len(list(doc.sents))\n",
    "\n",
    "print(f\"F: {snt_cnt_w}, M: {snt_cnt_m}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F: 0.8375272313958261\n",
      "M: 0.8111047163238724\n"
     ]
    }
   ],
   "source": [
    "print(f\"F: {svos_w.shape[0] / snt_cnt_w}\")\n",
    "print(f\"M: {svos_m.shape[0] / snt_cnt_m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total sentence counts are:\n",
    "```\n",
    "Women - NLTK : 30,799 with SVO ratio of 86%\n",
    "        spaCy: 31,673 with SVO ratio of 84%\n",
    "Men -   NLTK : 96,342 with SVO ratio of 83%\n",
    "        spaCy: 99,039 with SVO ratio of 81%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gendered Subjects <a id='genderedsubjects'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gendered Subject Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2529, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_he = svos_m[svos_m[\"subject\"] == \"he\"]\n",
    "m_he.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(842, 3)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_she = svos_m[svos_m[\"subject\"] == \"she\"]\n",
    "m_she.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Women said \"he\" 739 times, and\n",
      "women said \"she\" 636 times.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w_he = svos_w[svos_w[\"subject\"] == \"he\"]\n",
    "w_he.shape\n",
    "\n",
    "w_she = svos_w[svos_w[\"subject\"] == \"she\"]\n",
    "w_she.shape\n",
    "\n",
    "print(f\"\"\"\n",
    "Women said \"he\" {w_he.shape[0]} times, and\n",
    "women said \"she\" {w_she.shape[0]} times.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Men said \"i\" 2529 times, or 0.031 percent of SVOs.\n",
      "Women said \"i\" 739 times, or 0.028 percent of SVOs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m_he = svos_m[svos_m[\"subject\"] == \"he\"]\n",
    "w_he = svos_w[svos_w[\"subject\"] == \"he\"]\n",
    "\n",
    "print(f\"\"\"\n",
    "Men said \"i\" {m_he.shape[0]} times, or {m_he.shape[0]/svos_m.shape[0]:.3f} percent of SVOs.\n",
    "Women said \"i\" {w_he.shape[0]} times, or {w_he.shape[0]/svos_w.shape[0]:.3f} percent of SVOs.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare (subject):\n",
    "    # Create  name:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Men said \"i\" 15502 times, or 0.193 percent of SVOs.\n",
      "Women said \"i\" 6220 times, or 0.234 percent of SVOs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m_i = svos_m[svos_m[\"subject\"] == \"i\"]\n",
    "w_i = svos_w[svos_w[\"subject\"] == \"i\"]\n",
    "\n",
    "print(f\"\"\"\n",
    "Men said \"i\" {m_i.shape[0]} times, or {m_i.shape[0]/svos_m.shape[0]:.3f} percent of SVOs.\n",
    "Women said \"i\" {w_i.shape[0]} times, or {w_i.shape[0]/svos_w.shape[0]:.3f} percent of SVOs.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Men said \"we\" 15517 times, or 0.193 percent of SVOs.\n",
      "Women said \"we\" 4645 times, or 0.175 percent of SVOs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m_we = svos_m[svos_m[\"subject\"] == \"we\"]\n",
    "w_we = svos_w[svos_w[\"subject\"] == \"we\"]\n",
    "\n",
    "print(f\"\"\"\n",
    "Men said \"we\" {m_we.shape[0]} times, or {m_we.shape[0]/svos_m.shape[0]:.3f} percent of SVOs.\n",
    "Women said \"we\" {w_we.shape[0]} times, or {w_we.shape[0]/svos_w.shape[0]:.3f} percent of SVOs.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        verb  obs\n",
      "297      had  144\n",
      "588     said   85\n",
      "288      got   57\n",
      "285    going   51\n",
      "301      has   50\n",
      "718     took   46\n",
      "522      put   44\n",
      "764   wanted   43\n",
      "168      did   37\n",
      "717     told   36\n",
      "405     made   36\n",
      "790    wrote   35\n",
      "303     have   31\n",
      "657  started   30\n",
      "26     asked   29\n",
      "179       do   27\n",
      "182    doing   24\n",
      "765    wants   23\n",
      "73    called   22\n",
      "596      saw   21\n"
     ]
    }
   ],
   "source": [
    "m_he = m_he.groupby([\"verb\"]).size().reset_index(\n",
    "    name='obs').sort_values(['obs'], ascending=False).iloc[:20]\n",
    "print(m_he)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is my attempt to create a function that would return an appropriately named dataframe which was 20 rows long and contained the top 20 verbs for a given subject. It does not work in the `for` loop in the cell below. It returns the dataframe, but the name of the dataframe does not come along for the ride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbCount (dataframe, subject):\n",
    "    # This first line just makes sure the space is empty     \n",
    "    name = ''\n",
    "    # Create a unique name for the subset of the dataframe\n",
    "    name = str(dataframe.name+'_'+subject)\n",
    "    # Populate the sub-dataframe\n",
    "    name = dataframe[dataframe[\"subject\"] == subject].groupby([\"verb\"]).size().reset_index(\n",
    "    name='obs').sort_values(['obs'], ascending=False).iloc[:20]\n",
    "    # Output the dataframe\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "genderedSubjects = ['she', 'he', 'man', 'men', 'woman', 'women']\n",
    "for i in genderedSubjects:\n",
    "    verbCount(svos_m, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svos_m_she' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mz/k5p3f5wj0czgd_5m4dw59py00000gn/T/ipykernel_81947/1165417552.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvos_m_she\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'svos_m_she' is not defined"
     ]
    }
   ],
   "source": [
    "print(svos_m_she)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_she = verbCount(svos_m, 'she')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_man = verbCount(svos_m, 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_woman = verbCount(svos_m, 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "      <th>verb</th>\n",
       "      <th>obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>he</td>\n",
       "      <td>waving</td>\n",
       "      <td>[piece]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>he</td>\n",
       "      <td>yelling</td>\n",
       "      <td>[call, washington]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>did</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>does</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>doing</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80229</th>\n",
       "      <td>he</td>\n",
       "      <td>accompanied</td>\n",
       "      <td>[sharon]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80231</th>\n",
       "      <td>he</td>\n",
       "      <td>lost</td>\n",
       "      <td>[life]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80232</th>\n",
       "      <td>he</td>\n",
       "      <td>lost</td>\n",
       "      <td>[identity]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80234</th>\n",
       "      <td>he</td>\n",
       "      <td>failed</td>\n",
       "      <td>[what, to, recognize]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80265</th>\n",
       "      <td>he</td>\n",
       "      <td>wished</td>\n",
       "      <td>[leporsy]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2549 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject         verb                 object   verb   obs\n",
       "29         he       waving                [piece]    NaN   NaN\n",
       "30         he      yelling     [call, washington]    NaN   NaN\n",
       "74        NaN          NaN                    NaN    did  18.0\n",
       "79        NaN          NaN                    NaN   does   8.0\n",
       "80        NaN          NaN                    NaN  doing   9.0\n",
       "...       ...          ...                    ...    ...   ...\n",
       "80229      he  accompanied               [sharon]    NaN   NaN\n",
       "80231      he         lost                 [life]    NaN   NaN\n",
       "80232      he         lost             [identity]    NaN   NaN\n",
       "80234      he       failed  [what, to, recognize]    NaN   NaN\n",
       "80265      he       wished              [leporsy]    NaN   NaN\n",
       "\n",
       "[2549 rows x 5 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([m_he, m_she], axis = 1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "14a02b88778d8fb8b6aeb4ad427a942bc53dfcda9d7e3737237788289e0d2d23"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": 2,
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
