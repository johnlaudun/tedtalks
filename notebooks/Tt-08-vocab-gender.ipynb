{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gendered Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we want to examine the potential preferred usage of certain words by male/female speakers. We will not begin with filtering out stop words, both because they will account for a relatively small percentage of words but also because there may be something interesting there. \n",
    "\n",
    "To start, we will need to:\n",
    "\n",
    "* import the csv\n",
    "* grab all the texts and calculate word frequencies\n",
    "* then grab all the texts by gender and calculate word frequencies\n",
    "* compare frequencies\n",
    "* BONUS: create a useful visualization\n",
    "\n",
    "Double word-score bonus might be to look at trends: all and gendered. (I'm not sure what, if anything, that might reveal.)\n",
    "\n",
    "Okay, onto the code.\n",
    "\n",
    "Initial work: 2018-03-22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'citation', 'author', 'gender', 'title', 'date', 'length', 'text', 'occupation', 'numDate']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>citation</th>\n",
       "      <th>author</th>\n",
       "      <th>gender</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "      <th>text</th>\n",
       "      <th>occupation</th>\n",
       "      <th>numDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>citation</td>\n",
       "      <td>author</td>\n",
       "      <td>gender</td>\n",
       "      <td>title</td>\n",
       "      <td>date</td>\n",
       "      <td>length</td>\n",
       "      <td>text</td>\n",
       "      <td>occupation</td>\n",
       "      <td>numDate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Al Gore 2006</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>male</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>Jun 2006</td>\n",
       "      <td>957</td>\n",
       "      <td>Thank you so much  Chris. And it's truly a gre...</td>\n",
       "      <td>Climate advocate</td>\n",
       "      <td>200606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>David Pogue 2006</td>\n",
       "      <td>David Pogue</td>\n",
       "      <td>male</td>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>Jun 2006</td>\n",
       "      <td>1271</td>\n",
       "      <td>Hello voice mail  my old friend. I've called f...</td>\n",
       "      <td>Technology columnist</td>\n",
       "      <td>200606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Cameron Sinclair 2006</td>\n",
       "      <td>Cameron Sinclair</td>\n",
       "      <td>male</td>\n",
       "      <td>My wish: A call for open-source architecture</td>\n",
       "      <td>Jul 2006</td>\n",
       "      <td>1398</td>\n",
       "      <td>I'm going to take you on a journey very quickl...</td>\n",
       "      <td>Co-founder, Architecture for Humanity</td>\n",
       "      <td>200607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Sergey Brin + Larry Page 2007</td>\n",
       "      <td>Sergey Brin + Larry Page</td>\n",
       "      <td>male</td>\n",
       "      <td>The genesis of Google</td>\n",
       "      <td>May 2007</td>\n",
       "      <td>1205</td>\n",
       "      <td>Sergey Brin  I want to discuss a question I kn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             citation                    author  gender  \\\n",
       "0  NaN                       citation                    author  gender   \n",
       "1  1.0                   Al Gore 2006                   Al Gore    male   \n",
       "2  2.0               David Pogue 2006               David Pogue    male   \n",
       "3  3.0          Cameron Sinclair 2006          Cameron Sinclair    male   \n",
       "4  4.0  Sergey Brin + Larry Page 2007  Sergey Brin + Larry Page    male   \n",
       "\n",
       "                                          title      date  length  \\\n",
       "0                                         title      date  length   \n",
       "1                   Averting the climate crisis  Jun 2006     957   \n",
       "2                              Simplicity sells  Jun 2006    1271   \n",
       "3  My wish: A call for open-source architecture  Jul 2006    1398   \n",
       "4                         The genesis of Google  May 2007    1205   \n",
       "\n",
       "                                                text  \\\n",
       "0                                               text   \n",
       "1  Thank you so much  Chris. And it's truly a gre...   \n",
       "2  Hello voice mail  my old friend. I've called f...   \n",
       "3  I'm going to take you on a journey very quickl...   \n",
       "4  Sergey Brin  I want to discuss a question I kn...   \n",
       "\n",
       "                              occupation  numDate  \n",
       "0                             occupation  numDate  \n",
       "1                       Climate advocate   200606  \n",
       "2                   Technology columnist   200606  \n",
       "3  Co-founder, Architecture for Humanity   200607  \n",
       "4                                    NaN   200705  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the data\n",
    "\n",
    "# Let python create the column names list:\n",
    "with open('../data/talks_6d.csv') as f:\n",
    "    colnames = f.readline().strip().split(\",\")\n",
    "print(colnames)\n",
    "\n",
    "# Now will import the csv as a dataframe\n",
    "import pandas\n",
    "TEDtalks = pandas.read_csv('../data/talks_6d.csv', names=colnames)\n",
    "\n",
    "TEDtalks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Talks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm importing all of the `nltk` below because I'm not sure what, if any, of the library might be useful here. Otherwise I would simply `from nltk.tokenize import WhitespaceTokenizer`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373823 text thank you so much  chris. and it's truly a great honor to have the opportunity to come to this stage twice  i'm extremely grateful. i have been blown away by this conference  and i want to thank \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Create a list of just the texts\n",
    "texts = TEDtalks.text.tolist()\n",
    "\n",
    "# Mash all the talks together & then tokenize\n",
    "alltexts = \" \".join(texts).lower()\n",
    "tokens = nltk.tokenize.WhitespaceTokenizer().tokenize(alltexts)\n",
    "\n",
    "# Remove the name of the column which is the first item in the list:\n",
    "tokens.pop(0)\n",
    "\n",
    "print(len(tokens), alltexts[0:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the past, I've used simply dictionaries to count word frequencies -- see `Tt-02a-words` -- but we not only want to use already available functionality but we want more then word frequencies, we want to normalize word frequencies as percentage of overall corpus so that we can distinguish words that are more frequent in one or another.\n",
    "\n",
    "**TBH (2018-03-22)**: About the only thing that `nltk.FreqDist`, from what I can tell, does is deliver a containerized dictionary. I'll keep the code as is for now, in the belief that sticking with the NLTK is good for interoperability (or something)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Below it has to be `fd.update([word])` and not `fd.update(word)`: \n",
    "# the latter returns a list of letters.\n",
    "\n",
    "fd = nltk.FreqDist()\n",
    "for sentence in nltk.sent_tokenize(alltexts):\n",
    "    for word in nltk.word_tokenize(sentence):\n",
    "        fd.update([word])\n",
    "\n",
    "fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means there are a total of 54,269 words with a total usage of 4,746,253. The difference between a raw token count above of 4,373,823 is not explained by adding back in the frequency of periods of 251,860. If you subtract the total of those two combined, you are still left with a difference of: `4,746,253 - (4,373,823 + 251,860) = 120,570`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An NLTK `FreqDist` is a list of tuples containing the word and its frequency, e.g. `('and', 110130)`. I need to iterate through these three million tuples and normalize:\n",
    "\n",
    "    percentages = []\n",
    "    for word, count in old_tuple:\n",
    "        percentage = count / total words\n",
    "        word, percentage in new_tuple\n",
    "\n",
    "Even my pseudo-code is kind of ugly, I'm afraid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To doublecheck the \"outcomes\" listed above is also the \n",
    "# total number of words: FreqDist is a Python counter and \n",
    "# inherits those methods:\n",
    "\n",
    "total_words = sum(fd.values()) \n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now to calculate relative frequencies\n",
    "\n",
    "freq_dist = dict(fd)\n",
    "\n",
    "# MODEL: d2 = dict((k, f(v)) for k, v in d1.items())\n",
    "rel_freq = {k: v/total_words for k, v in freq_dist.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# It dawned on me we could have a function that does everything we need:\n",
    "\n",
    "import nltk\n",
    "import operator\n",
    "\n",
    "def RelaFreq (list_of_texts):\n",
    "    # Take the list and turn it into one long string\n",
    "    all_texts = \" \".join(list_of_texts).lower()\n",
    "    # Invoke the NLTK god\n",
    "    freqdist = nltk.FreqDist()\n",
    "    # We're getting sentence data here, but I'm not sure it's needed\n",
    "    # and I don't know how much it might be slowing the process.\n",
    "    for sentence in nltk.sent_tokenize(all_texts):\n",
    "        for word in nltk.word_tokenize(sentence):\n",
    "            freqdist.update([word])\n",
    "    # Get the total number of words so we can establish relative frequencies\n",
    "    total_words = sum(freqdist.values())\n",
    "    # Convert the FreqDist container to a dictionary\n",
    "    freqdist_dict = dict(freqdist)\n",
    "    # Create a new dictionary of relative frequencies\n",
    "    relative_frequency = {k: v/total_words for k, v in freqdist_dict.items()}\n",
    "    # Convert the dictionary to a rankable list of tuples\n",
    "    # & rank it with the most frequent word first\n",
    "    ranked = sorted(relative_frequency.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    # return the ranked list of tuples\n",
    "    return(ranked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018-03-27: The code above was the first function I wrote to generate a list of words and then to rank them, but the NLTK functionality is keeping apostrophes at the beginning and end of words and splitting contractions on the apostrophe, so the function below was written using the `string` module to see if we can't get better results. \n",
    "\n",
    "The first version of the new function below results in a list of 56,043 words, some of which include some apparent oddities. The original function produced a list of 54269 words. \n",
    "\n",
    "What if we filter using the NLTK sentence tokenizer? It returns a list of **more** words: 56039.\n",
    "\n",
    "New chain: **sentence tokenizer > string methods > word tokenizer**. This is, no doubt very inefficient, but we just need a clean list for now.\n",
    "\n",
    "    justwords = [word.strip(string.punctuation) for word in all_texts.split(\" \")]\n",
    "    for word in justwords:\n",
    "        freqdist.update([word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import operator\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def relafreq (list_of_texts):\n",
    "    # Take the list and turn it into one long string\n",
    "    all_texts = \" \".join(list_of_texts).lower()\n",
    "    # Invoke the NLTK god\n",
    "    freqdist = nltk.FreqDist()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(all_texts)\n",
    "    for word in words:\n",
    "        freqdist.update([word])\n",
    "    # Get the total number of words so we can establish relative frequencies\n",
    "    total_words = sum(freqdist.values())\n",
    "    # Convert the FreqDist container to a dictionary\n",
    "    freqdist_dict = dict(freqdist)\n",
    "    # Create a new dictionary of relative frequencies\n",
    "    relative_frequency = {k: v/total_words for k, v in freqdist_dict.items()}\n",
    "    # Convert the dictionary to a rankable list of tuples\n",
    "    # & rank it with the most frequent word first\n",
    "    ranked = sorted(relative_frequency.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    # return the ranked list of tuples\n",
    "    return(ranked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 0.04672706044585814),\n",
       " ('and', 0.03357979585941176),\n",
       " ('to', 0.02819363043262475),\n",
       " ('of', 0.025808681516734926),\n",
       " ('a', 0.023719291779671314),\n",
       " ('that', 0.021429153263013395),\n",
       " ('i', 0.01863113368755923),\n",
       " ('in', 0.017549716481296756),\n",
       " ('it', 0.016799913112723334),\n",
       " ('you', 0.015928369630582185)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_talks = relafreq(texts)\n",
    "all_talks[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53705\n"
     ]
    }
   ],
   "source": [
    "print(len(all_talks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Words\n",
    "\n",
    "This next bit of code is just to have a number to multiply very small numbers by in order to get back the frequency of a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltexts = \" \".join(texts).lower()\n",
    "freqdist = nltk.FreqDist()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "words = tokenizer.tokenize(alltexts)\n",
    "for word in words:\n",
    "    freqdist.update([word])\n",
    "# Get the total number of words so we can establish relative frequencies\n",
    "total_words = sum(freqdist.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4493178\n"
     ]
    }
   ],
   "source": [
    "print(total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gendered Talks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create two additional collections filtered by the `gender` column of the dataframe. What happens in the first line below is that we filter the dataframe, in the line that follows we pull the text column out. Originally, I had this as one line:\n",
    "\n",
    "    f_talks = TEDtalks[TEDtalks.gender == 'female'].text.tolist()\n",
    "\n",
    "But that produced a string and not a list object. I don't know why the one line would not work.\n",
    "\n",
    "**2018-03-22**: Now it's working. Did I have `texts.tolist()` -- I'm not clear what happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 2069 TED talks given, 607 were given by women and 1437 by men.\n"
     ]
    }
   ],
   "source": [
    "# Filter by gender\n",
    "\n",
    "m_talks = TEDtalks[TEDtalks.gender == 'male'].text.tolist()\n",
    "f_talks = TEDtalks[TEDtalks.gender == 'female'].text.tolist()\n",
    "\n",
    "# A quick check of numbers:\n",
    "\n",
    "print(\"Of the {} TED talks given, {} were given by women and {} by men.\".format\n",
    "      (len(texts), len(f_talks), len(m_talks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: One thing to do here is to compare the talks to see which words are used **only** by women or **only** by men."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_relative = relafreq(f_talks)\n",
    "m_relative = relafreq(m_talks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 ('but', 0.00630225218420012) ('have', 0.0061547439624038865)\n"
     ]
    }
   ],
   "source": [
    "# Just a way to check against rank\n",
    "import random\n",
    "random_num = random.randint(1,500)\n",
    "print(random_num, f_relative[random_num], m_relative[random_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Other Talks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of curiosity, how many talks are given by more than one speaker or by a non-single gender speaker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many talks does that leave:\n",
    "\n",
    "len(texts) - (len(f_talks) + len(m_talks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "o_talks = TEDtalks[(TEDtalks.gender != 'male')&(TEDtalks.gender != 'female')]\n",
    "\n",
    "# This will show you all 25 rows:\n",
    "o_talks.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing M/F Word Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to start by converting the list of tuples to a dictionary both because I think matching keys is going to be easier (at least based on my limited coding ability) and because, according to what I read, it appears to be faster. Since we don't really need a ranked listing for this work, it would probably be wise to rewrite the `RelaFreq` function so that it produces a dictionary. No reason to go back and forth like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_rf = dict(f_relative)\n",
    "\n",
    "m_rf = dict(m_relative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes on how to compare -- as I write this I am trying to find a way to limit my for loop through the two dictionaries only to N results just so I can see if it's working. \n",
    "\n",
    "[Python - Return first N key:value pairs from dict](https://stackoverflow.com/questions/7971618/python-return-first-n-keyvalue-pairs-from-dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a way to match words in the f/m dictionaries\n",
    "\n",
    "for key in f_rf:\n",
    "    if key in m_rf:\n",
    "        print(key, f_rf[key], m_rf[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I decided to do was run the cell and then stop it. The results from above look like this:\n",
    "\n",
    "    hour 8.613999628814925e-05 0.00012193460211598934\n",
    "    debased 7.830908753468114e-07 2.924091177841471e-07\n",
    "    deteriorate 3.1323635013872456e-06 1.7544547067048825e-06\n",
    "    perimeter 1.5661817506936228e-06 3.508909413409765e-06\n",
    "\n",
    "What we need now is to compare one list against the other for differences in usage. I am starting with twice as often to see what that turns up. >>> I need to re-read the literature here to see what comparison thresholds have been used. \n",
    "\n",
    "**2018-03-26**: I decided that the easiest way to approach this is to create a dictionary comprehension that divides the female relative frequency by the male. We can then look at numbers >1 for the words preferred by women and numbers < 1 for words preferred by men."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are just going to do math:\n",
    "\n",
    "weighted = {f_rf[key]/m_rf[key] for key in f_rf}\n",
    "\n",
    "for key in f_rf:\n",
    "    \n",
    "if f_rf[key] > m_rf[key]:\n",
    "    print(key, f_rf[key], m_rf[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>women</th>\n",
       "      <th>men</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.022903</td>\n",
       "      <td>2.403695e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.472778e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.854583e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.090972e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaa</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          women           men\n",
       "a      0.022903  2.403695e-02\n",
       "aa     0.000003  2.472778e-06\n",
       "aaa    0.000002  1.854583e-06\n",
       "aaaa        NaN  3.090972e-07\n",
       "aaaaa  0.000002           NaN"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from a list of dictionaries\n",
    "comp = pandas.DataFrame([f_rf, m_rf]).T\n",
    "\n",
    "# Rename the columns to something human readable\n",
    "comp.columns = ['women', 'men']\n",
    "\n",
    "# Check our results\n",
    "comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm doing the vision manually below instead of using the built-in functionality: \n",
    "# DataFrame.divide(other, axis='columns', level=None, fill_value=None)\n",
    "ratios = comp.assign(ratio = comp.women / comp.men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>women</th>\n",
       "      <th>men</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.022903</td>\n",
       "      <td>2.403695e-02</td>\n",
       "      <td>0.952835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.472778e-06</td>\n",
       "      <td>1.335422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.854583e-06</td>\n",
       "      <td>0.890281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaa</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          women           men     ratio\n",
       "a      0.022903  2.403695e-02  0.952835\n",
       "aa     0.000003  2.472778e-06  1.335422\n",
       "aaa    0.000002  1.854583e-06  0.890281\n",
       "aaaa        NaN  3.090972e-07       NaN\n",
       "aaaaa  0.000002           NaN       NaN"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios.index.rename('word', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>women</th>\n",
       "      <th>men</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.022903</td>\n",
       "      <td>2.403695e-02</td>\n",
       "      <td>0.952835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.472778e-06</td>\n",
       "      <td>1.335422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.854583e-06</td>\n",
       "      <td>0.890281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaa</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          women           men     ratio\n",
       "word                                   \n",
       "a      0.022903  2.403695e-02  0.952835\n",
       "aa     0.000003  2.472778e-06  1.335422\n",
       "aaa    0.000002  1.854583e-06  0.890281\n",
       "aaaa        NaN  3.090972e-07       NaN\n",
       "aaaaa  0.000002           NaN       NaN"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'word'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Library/Python/3.4/lib/python/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2133\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2134\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'word'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-022913b161c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mratios\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ratio'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.4/lib/python/site-packages/pandas/tools/plotting.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, **kwds)\u001b[0m\n\u001b[1;32m   3950\u001b[0m         \u001b[0maxes\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAxesSubplot\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3951\u001b[0m         \"\"\"\n\u001b[0;32m-> 3952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'scatter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3954\u001b[0m     def hexbin(self, x, y, C=None, reduce_C_function=None, gridsize=None,\n",
      "\u001b[0;32m~/Library/Python/3.4/lib/python/site-packages/pandas/tools/plotting.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, y, kind, ax, subplots, sharex, sharey, layout, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, secondary_y, sort_columns, **kwds)\u001b[0m\n\u001b[1;32m   3772\u001b[0m                           \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolormap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolormap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3773\u001b[0m                           \u001b[0myerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecondary_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3774\u001b[0;31m                           sort_columns=sort_columns, **kwds)\n\u001b[0m\u001b[1;32m   3775\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.4/lib/python/site-packages/pandas/tools/plotting.py\u001b[0m in \u001b[0;36mplot_frame\u001b[0;34m(data, x, y, kind, ax, subplots, sharex, sharey, layout, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, secondary_y, sort_columns, **kwds)\u001b[0m\n\u001b[1;32m   2641\u001b[0m                  \u001b[0myerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2642\u001b[0m                  \u001b[0msecondary_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2643\u001b[0;31m                  **kwds)\n\u001b[0m\u001b[1;32m   2644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.4/lib/python/site-packages/pandas/tools/plotting.py\u001b[0m in \u001b[0;36m_plot\u001b[0;34m(data, x, y, subplots, ax, kind, **kwds)\u001b[0m\n\u001b[1;32m   2468\u001b[0m         \u001b[0mplot_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubplots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2470\u001b[0;31m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2471\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.4/lib/python/site-packages/pandas/tools/plotting.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_legend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.4/lib/python/site-packages/pandas/tools/plotting.py\u001b[0m in \u001b[0;36m_make_plot\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1617\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1618\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1619\u001b[0;31m         scatter = ax.scatter(data[x].values, data[y].values, c=c_values,\n\u001b[0m\u001b[1;32m   1620\u001b[0m                              label=label, cmap=cmap, **self.kwds)\n\u001b[1;32m   1621\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.4/lib/python/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2057\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.4/lib/python/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.4/lib/python/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.4/lib/python/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3542\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3543\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3544\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3545\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.4/lib/python/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2134\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2136\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'word'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ratios.plot.scatter(x='word', y='ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurs = ratios.assign(woccurs = comp.women * 4493178, moccurs = comp.men*4493178)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>women</th>\n",
       "      <th>men</th>\n",
       "      <th>ratio</th>\n",
       "      <th>moccurs</th>\n",
       "      <th>woccurs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pms</th>\n",
       "      <td>4.045197e-05</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>130.871354</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>181.757912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vagina</th>\n",
       "      <td>5.943963e-05</td>\n",
       "      <td>6.181945e-07</td>\n",
       "      <td>96.150382</td>\n",
       "      <td>2.777658</td>\n",
       "      <td>267.072851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tapirs</th>\n",
       "      <td>2.146431e-05</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>69.441943</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>96.442974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sw</th>\n",
       "      <td>3.797532e-05</td>\n",
       "      <td>6.181945e-07</td>\n",
       "      <td>61.429411</td>\n",
       "      <td>2.777658</td>\n",
       "      <td>170.629877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mantis</th>\n",
       "      <td>1.568546e-05</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>50.746035</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>70.477558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jf</th>\n",
       "      <td>2.971982e-05</td>\n",
       "      <td>6.181945e-07</td>\n",
       "      <td>48.075191</td>\n",
       "      <td>2.777658</td>\n",
       "      <td>133.536425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glamour</th>\n",
       "      <td>4.457972e-05</td>\n",
       "      <td>9.272917e-07</td>\n",
       "      <td>48.075191</td>\n",
       "      <td>4.166487</td>\n",
       "      <td>200.304638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feminism</th>\n",
       "      <td>2.889427e-05</td>\n",
       "      <td>6.181945e-07</td>\n",
       "      <td>46.739769</td>\n",
       "      <td>2.777658</td>\n",
       "      <td>129.827080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brigades</th>\n",
       "      <td>1.403436e-05</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>45.404347</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>63.058868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>replicator</th>\n",
       "      <td>1.320881e-05</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>42.733503</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>59.349522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hum</th>\n",
       "      <td>6.274183e-05</td>\n",
       "      <td>1.545486e-06</td>\n",
       "      <td>40.596828</td>\n",
       "      <td>6.944144</td>\n",
       "      <td>281.910231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ruby</th>\n",
       "      <td>1.238326e-05</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>40.062659</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>55.640177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sobule</th>\n",
       "      <td>1.238326e-05</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>40.062659</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>55.640177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exoplanets</th>\n",
       "      <td>1.238326e-05</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>40.062659</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>55.640177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>np</th>\n",
       "      <td>1.238326e-05</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>40.062659</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>55.640177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoo</th>\n",
       "      <td>1.238326e-05</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>40.062659</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>55.640177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>introverts</th>\n",
       "      <td>1.238326e-05</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>40.062659</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>55.640177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crochet</th>\n",
       "      <td>1.155771e-05</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>37.391815</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>51.930832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monologues</th>\n",
       "      <td>1.155771e-05</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>37.391815</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>51.930832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>papaya</th>\n",
       "      <td>1.073216e-05</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>34.720971</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>48.221487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toughness</th>\n",
       "      <td>1.073216e-05</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>34.720971</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>48.221487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silks</th>\n",
       "      <td>1.073216e-05</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>34.720971</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>48.221487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>honolulu</th>\n",
       "      <td>1.073216e-05</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>34.720971</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>48.221487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sarajevo</th>\n",
       "      <td>1.073216e-05</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>34.720971</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>48.221487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abortion</th>\n",
       "      <td>2.063876e-05</td>\n",
       "      <td>6.181945e-07</td>\n",
       "      <td>33.385549</td>\n",
       "      <td>2.777658</td>\n",
       "      <td>92.733629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passwords</th>\n",
       "      <td>6.026518e-05</td>\n",
       "      <td>1.854583e-06</td>\n",
       "      <td>32.495268</td>\n",
       "      <td>8.332973</td>\n",
       "      <td>270.782196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thyroid</th>\n",
       "      <td>9.906605e-06</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>32.050127</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>44.512142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crispr</th>\n",
       "      <td>2.971982e-05</td>\n",
       "      <td>9.272917e-07</td>\n",
       "      <td>32.050127</td>\n",
       "      <td>4.166487</td>\n",
       "      <td>133.536425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saddle</th>\n",
       "      <td>9.081055e-06</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>29.379283</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>40.802797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mystic</th>\n",
       "      <td>9.081055e-06</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>29.379283</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>40.802797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoum</th>\n",
       "      <td>8.255505e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.709345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zquez</th>\n",
       "      <td>2.476651e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.128035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zs</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zu</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zubin</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zucchini</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuckerbergs</th>\n",
       "      <td>8.255505e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.709345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zucman</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zullinger</th>\n",
       "      <td>4.953303e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.256071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zulu</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.181945e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.777658</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zulus</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuma</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zumra</th>\n",
       "      <td>2.476651e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.128035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zumthor</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zune</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuzana</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.181945e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.777658</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zweep</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zworkykin</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zworykin</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwyiec</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zx</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.236389e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.555315</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zygomatic</th>\n",
       "      <td>8.255505e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.709345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zygotes</th>\n",
       "      <td>8.255505e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.709345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zynga</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.181945e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.777658</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyprexa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zywiec</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.090972e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.388829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zz</th>\n",
       "      <td>8.255505e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.709345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzzzzt</th>\n",
       "      <td>8.255505e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.709345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzzzzzip</th>\n",
       "      <td>8.255505e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.709345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53412 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    women           men       ratio   moccurs     woccurs\n",
       "pms          4.045197e-05  3.090972e-07  130.871354  1.388829  181.757912\n",
       "vagina       5.943963e-05  6.181945e-07   96.150382  2.777658  267.072851\n",
       "tapirs       2.146431e-05  3.090972e-07   69.441943  1.388829   96.442974\n",
       "sw           3.797532e-05  6.181945e-07   61.429411  2.777658  170.629877\n",
       "mantis       1.568546e-05  3.090972e-07   50.746035  1.388829   70.477558\n",
       "jf           2.971982e-05  6.181945e-07   48.075191  2.777658  133.536425\n",
       "glamour      4.457972e-05  9.272917e-07   48.075191  4.166487  200.304638\n",
       "feminism     2.889427e-05  6.181945e-07   46.739769  2.777658  129.827080\n",
       "brigades     1.403436e-05  3.090972e-07   45.404347  1.388829   63.058868\n",
       "replicator   1.320881e-05  3.090972e-07   42.733503  1.388829   59.349522\n",
       "hum          6.274183e-05  1.545486e-06   40.596828  6.944144  281.910231\n",
       "ruby         1.238326e-05  3.090972e-07   40.062659  1.388829   55.640177\n",
       "sobule       1.238326e-05  3.090972e-07   40.062659  1.388829   55.640177\n",
       "exoplanets   1.238326e-05  3.090972e-07   40.062659  1.388829   55.640177\n",
       "np           1.238326e-05  3.090972e-07   40.062659  1.388829   55.640177\n",
       "hoo          1.238326e-05  3.090972e-07   40.062659  1.388829   55.640177\n",
       "introverts   1.238326e-05  3.090972e-07   40.062659  1.388829   55.640177\n",
       "crochet      1.155771e-05  3.090972e-07   37.391815  1.388829   51.930832\n",
       "monologues   1.155771e-05  3.090972e-07   37.391815  1.388829   51.930832\n",
       "papaya       1.073216e-05  3.090972e-07   34.720971  1.388829   48.221487\n",
       "toughness    1.073216e-05  3.090972e-07   34.720971  1.388829   48.221487\n",
       "silks        1.073216e-05  3.090972e-07   34.720971  1.388829   48.221487\n",
       "honolulu     1.073216e-05  3.090972e-07   34.720971  1.388829   48.221487\n",
       "sarajevo     1.073216e-05  3.090972e-07   34.720971  1.388829   48.221487\n",
       "abortion     2.063876e-05  6.181945e-07   33.385549  2.777658   92.733629\n",
       "passwords    6.026518e-05  1.854583e-06   32.495268  8.332973  270.782196\n",
       "thyroid      9.906605e-06  3.090972e-07   32.050127  1.388829   44.512142\n",
       "crispr       2.971982e-05  9.272917e-07   32.050127  4.166487  133.536425\n",
       "saddle       9.081055e-06  3.090972e-07   29.379283  1.388829   40.802797\n",
       "mystic       9.081055e-06  3.090972e-07   29.379283  1.388829   40.802797\n",
       "...                   ...           ...         ...       ...         ...\n",
       "zoum         8.255505e-07           NaN         NaN       NaN    3.709345\n",
       "zquez        2.476651e-06           NaN         NaN       NaN   11.128035\n",
       "zr                    NaN  3.090972e-07         NaN  1.388829         NaN\n",
       "zs                    NaN  3.090972e-07         NaN  1.388829         NaN\n",
       "zu                    NaN  3.090972e-07         NaN  1.388829         NaN\n",
       "zubin                 NaN  3.090972e-07         NaN  1.388829         NaN\n",
       "zucchini              NaN  3.090972e-07         NaN  1.388829         NaN\n",
       "zuckerbergs  8.255505e-07           NaN         NaN       NaN    3.709345\n",
       "zucman                NaN  3.090972e-07         NaN  1.388829         NaN\n",
       "zullinger    4.953303e-06           NaN         NaN       NaN   22.256071\n",
       "zulu                  NaN  6.181945e-07         NaN  2.777658         NaN\n",
       "zulus                 NaN  3.090972e-07         NaN  1.388829         NaN\n",
       "zuma                  NaN  3.090972e-07         NaN  1.388829         NaN\n",
       "zumra        2.476651e-06           NaN         NaN       NaN   11.128035\n",
       "zumthor               NaN  3.090972e-07         NaN  1.388829         NaN\n",
       "zune                  NaN  3.090972e-07         NaN  1.388829         NaN\n",
       "zuzana                NaN  6.181945e-07         NaN  2.777658         NaN\n",
       "zweep                 NaN  3.090972e-07         NaN  1.388829         NaN\n",
       "zworkykin             NaN  3.090972e-07         NaN  1.388829         NaN\n",
       "zworykin              NaN  3.090972e-07         NaN  1.388829         NaN\n",
       "zwyiec                NaN  3.090972e-07         NaN  1.388829         NaN\n",
       "zx                    NaN  1.236389e-06         NaN  5.555315         NaN\n",
       "zygomatic    8.255505e-07           NaN         NaN       NaN    3.709345\n",
       "zygotes      8.255505e-07           NaN         NaN       NaN    3.709345\n",
       "zynga                 NaN  6.181945e-07         NaN  2.777658         NaN\n",
       "zyprexa               NaN  3.090972e-07         NaN  1.388829         NaN\n",
       "zywiec                NaN  3.090972e-07         NaN  1.388829         NaN\n",
       "zz           8.255505e-07           NaN         NaN       NaN    3.709345\n",
       "zzzzzt       8.255505e-07           NaN         NaN       NaN    3.709345\n",
       "zzzzzzip     8.255505e-07           NaN         NaN       NaN    3.709345\n",
       "\n",
       "[53412 rows x 5 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And now to sort:\n",
    "\n",
    "occurs.sort_values(by='ratio', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
