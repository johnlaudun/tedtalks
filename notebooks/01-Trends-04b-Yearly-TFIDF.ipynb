{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Talks by Event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we load the updated dataset with the year a talk was presented as an added feature. We group the texts of the talks by that year and then vectorize the terms into a TF-IDF matrix.\n",
    "\n",
    "The TF-IDF score for the word t in the document d from the document set D is calculated as follows:\n",
    "\n",
    "> tfidf ( t, d, D ) = tf ( t, d ) · idf ( t, D )\n",
    "\n",
    "where:\n",
    "\n",
    "> tf ( t, d ) = log ( 1 + freq (t, d ))\n",
    "\n",
    "> idf (t, D) = log ( N / count ( d € D; t € D ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "* [Hedonometer](https://hedonometer.org/timeseries/en_all/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd, re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1747, 30) ['Unnamed: 0', 'Set', 'Talk_ID', 'public_url', 'headline', 'description', 'event', 'duration', 'published', 'tags', 'views', 'text', 'speaker_1', 'speaker1_occupation', 'speaker1_introduction', 'speaker1_profile', 'speaker_2', 'speaker2_occupation', 'speaker2_introduction', 'speaker2_profile', 'speaker_3', 'speaker3_occupation', 'speaker3_introduction', 'speaker3_profile', 'speaker_4', 'speaker4_occupation', 'speaker4_introduction', 'speaker4_profile', 'presented', 'TEDevent']\n"
     ]
    }
   ],
   "source": [
    "# Load the Data\n",
    "df = pd.read_csv('../output/TEDall.csv')\n",
    "\n",
    "# .shape is just to check to make sure everything loaded correctly\n",
    "# `list()` is to remind us of column names\n",
    "print(df.shape, list(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the Years into Pseudo-Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by reminding ourselves of the years involved and the number of talks per year available to us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1984      1\n",
       "1990      1\n",
       "1994      1\n",
       "1998      6\n",
       "2001      3\n",
       "2002     28\n",
       "2003     34\n",
       "2004     31\n",
       "2005     62\n",
       "2006     43\n",
       "2007     92\n",
       "2008     56\n",
       "2009    155\n",
       "2010    162\n",
       "2011    150\n",
       "2012    146\n",
       "2013    162\n",
       "2014    154\n",
       "2015    149\n",
       "2016    145\n",
       "2017    166\n",
       "Name: presented, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['presented'].value_counts().sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there's not much point in including the first five years on record: they total to 11, which is only half as many as the total of 28 for 2002. We start there with concatenating all the texts of the talks into a pandas series with the years as index. In pandas you can [concatenate strings][] based on some other criteria: here we are *grouping by* the year a talk was given, which is `presented` in our dataset. (We use the `all_years` variable initially so that we can call the edited series simply `years`.)\n",
    "\n",
    "[concatenate strings]: https://stackoverflow.com/questions/27298178/concatenate-strings-from-several-rows-using-pandas-groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "presented\n",
       "1984      In this rather long sort of marathon present...\n",
       "1990      I'm going to go right into the slides. And a...\n",
       "1994      Because I usually take the role of trying to...\n",
       "1998      As a clergyman, you can imagine how out of p...\n",
       "2001      So I understand that this meeting was planne...\n",
       "2002      What I want to talk about is, as background,...\n",
       "2003      You know, one of the intense pleasures of tr...\n",
       "2004      (Music)    (Music ends)    (Applause)    Tha...\n",
       "2005      My name is Lovegrove. I only know nine Loveg...\n",
       "2006      Thank you so much, Chris. And it's truly a g...\n",
       "2007      I have all my life wondered what \"mind-boggl...\n",
       "2008      Roy Gould: Less than a year from now, the wo...\n",
       "2009      I wrote a letter last week talking about the...\n",
       "2010      Sadly, in the next 18 minutes when I do our ...\n",
       "2011      Ten years ago exactly, I was in Afghanistan....\n",
       "2012      Let me begin with four words that will provi...\n",
       "2013      What is going to be the future of learning? ...\n",
       "2014      Chris Anderson: The rights of citizens, the ...\n",
       "2015      We are built out of very small stuff, and we...\n",
       "2016      So a while ago, I tried an experiment. For o...\n",
       "2017      Gayle King: Have a seat, Serena Williams, or...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_years = df.groupby(['presented'])['text'].apply(lambda x: ','.join(x))#.reset_index()\n",
    "all_years.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "presented\n",
       "2002      What I want to talk about is, as background,...\n",
       "2003      You know, one of the intense pleasures of tr...\n",
       "2004      (Music)    (Music ends)    (Applause)    Tha...\n",
       "2005      My name is Lovegrove. I only know nine Loveg...\n",
       "2006      Thank you so much, Chris. And it's truly a g...\n",
       "2007      I have all my life wondered what \"mind-boggl...\n",
       "2008      Roy Gould: Less than a year from now, the wo...\n",
       "2009      I wrote a letter last week talking about the...\n",
       "2010      Sadly, in the next 18 minutes when I do our ...\n",
       "2011      Ten years ago exactly, I was in Afghanistan....\n",
       "2012      Let me begin with four words that will provi...\n",
       "2013      What is going to be the future of learning? ...\n",
       "2014      Chris Anderson: The rights of citizens, the ...\n",
       "2015      We are built out of very small stuff, and we...\n",
       "2016      So a while ago, I tried an experiment. For o...\n",
       "2017      Gayle King: Have a seat, Serena Williams, or...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = all_years.drop([1984, 1990, 1994, 1998, 2001])\n",
    "years.head(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`years.values` returns an array of all the values. `years.values[0]` gives you the first item in the array/list, and as you count up the index, you walk through the collected talks for each year. \n",
    "\n",
    "Not entirely intuitively, you can get the values without explicitly calling them om a `for` loop:\n",
    "\n",
    "```python\n",
    "for item in years:\n",
    "    print(item[0:20])\n",
    "```\n",
    "\n",
    "But this explicit version, which here also includes the index, is bit more clear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002:   What I want to tal\n",
      "2003:   You know, one of t\n",
      "2004:   (Music)    (Music \n",
      "2005:   My name is Lovegro\n",
      "2006:   Thank you so much,\n",
      "2007:   I have all my life\n",
      "2008:   Roy Gould: Less th\n",
      "2009:   I wrote a letter l\n",
      "2010:   Sadly, in the next\n",
      "2011:   Ten years ago exac\n",
      "2012:   Let me begin with \n",
      "2013:   What is going to b\n",
      "2014:   Chris Anderson: Th\n",
      "2015:   We are built out o\n",
      "2016:   So a while ago, I \n",
      "2017:   Gayle King: Have a\n"
     ]
    }
   ],
   "source": [
    "for index, value in years.iteritems():\n",
    "    print(f'{index}: {value[0:20]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the Year Pseudo-Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to take the text in the value and run it through **sklearn**'s `tfidf` functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step is to load the data and the function that cleans the parentheticals out of the texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parentheticals = [ \"\\(laughter\\)\", \"\\(applause\\)\", \"\\(music\\)\", \"\\(video\\)\", \n",
    "                  \"\\(laughs\\)\", \"\\(applause ends\\)\", \"\\(audio\\)\", \"\\(singing\\)\", \n",
    "                  \"\\(music ends\\)\", \"\\(cheers\\)\", \"\\(cheering\\)\", \"\\(recording\\)\", \n",
    "                  \"\\(beatboxing\\)\", \"\\(audience\\)\", \"\\(guitar strum\\)\", \n",
    "                  \"\\(clicks metronome\\)\", \"\\(sighs\\)\", \"\\(guitar\\)\", \"\\(marimba sounds\\)\", \n",
    "                  \"\\(drum sounds\\)\" ]\n",
    "\n",
    "def clean_parens(text):\n",
    "    new_text = text\n",
    "    for rgx_match in parentheticals:\n",
    "        new_text = re.sub(rgx_match, ' ', new_text.lower(), flags=re.IGNORECASE)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we instantiate our term frequency vectorizer and turn it loose on our pseudo-documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(preprocessor = clean_parens, min_df = 2)\n",
    "word_count_vector=vec.fit_transform(year for year in years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run `shape` to see if the output is close to what we expected, we have a matrix that is 16 x 28530. That looks good, so now we will transform those TFs into TFIDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it easier to inspect our results, we invoke a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, \n",
    "                      index=vec.get_feature_names(), \n",
    "                      columns=[\"idf_weights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>island</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>built</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strong</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freshen</th>\n",
       "      <td>2.734601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frescoes</th>\n",
       "      <td>2.734601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocky</th>\n",
       "      <td>2.734601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>silvery</th>\n",
       "      <td>2.734601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ism</th>\n",
       "      <td>2.734601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28530 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           idf_weights\n",
       "island        1.000000\n",
       "building      1.000000\n",
       "buildings     1.000000\n",
       "built         1.000000\n",
       "strong        1.000000\n",
       "...                ...\n",
       "freshen       2.734601\n",
       "frescoes      2.734601\n",
       "cocky         2.734601\n",
       "silvery       2.734601\n",
       "ism           2.734601\n",
       "\n",
       "[28530 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_idf.sort_values(by=['idf_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.516398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.401365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.320451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>0.280900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>0.252489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>garments</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>garment</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>garlic</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gardner</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zurich</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28530 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             tfidf\n",
       "the       0.516398\n",
       "and       0.401365\n",
       "to        0.320451\n",
       "of        0.280900\n",
       "that      0.252489\n",
       "...            ...\n",
       "garments  0.000000\n",
       "garment   0.000000\n",
       "garlic    0.000000\n",
       "gardner   0.000000\n",
       "zurich    0.000000\n",
       "\n",
       "[28530 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf-idf scores\n",
    "tf_idf_vector=tfidf_transformer.transform(word_count_vector)\n",
    "\n",
    "# Establish feature names:\n",
    "feature_names = vec.get_feature_names()\n",
    " \n",
    "# get tfidf vector for first document\n",
    "first_document_vector=tf_idf_vector[0]\n",
    " \n",
    "# print the scores\n",
    "df = pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"])\n",
    "df.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-7c824be19cc7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-7c824be19cc7>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    for year in years\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for year in years"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": 2,
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
