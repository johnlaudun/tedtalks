{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citation</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Author</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Al Gore 2006</td>\n",
       "      <td>Thank you so much  Chris. And it's truly a gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Pogue 2006</td>\n",
       "      <td>Hello voice mail  my old friend. I've called f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cameron Sinclair 2006</td>\n",
       "      <td>I'm going to take you on a journey very quickl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sergey Brin + Larry Page 2007</td>\n",
       "      <td>Sergey Brin  I want to discuss a question I kn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        citation  \\\n",
       "0                        Author    \n",
       "1                   Al Gore 2006   \n",
       "2               David Pogue 2006   \n",
       "3          Cameron Sinclair 2006   \n",
       "4  Sergey Brin + Larry Page 2007   \n",
       "\n",
       "                                                text  \n",
       "0                                               Text  \n",
       "1  Thank you so much  Chris. And it's truly a gre...  \n",
       "2  Hello voice mail  my old friend. I've called f...  \n",
       "3  I'm going to take you on a journey very quickl...  \n",
       "4  Sergey Brin  I want to discuss a question I kn...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEDtalks: Topics with LDA\n",
    "\n",
    "# =-=-=-=-=-=\n",
    "# Read CSV into DataFrame and then create lists\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "import pandas\n",
    "import re\n",
    "\n",
    "\n",
    "# Create pandas dataframe\n",
    "colnames = ['author', 'title', 'date' , 'length', 'text']\n",
    "df = pandas.read_csv('../data/talks_3a.csv', names=colnames)\n",
    "\n",
    "# Create lists for the data\n",
    "talks = df.text.tolist()\n",
    "authors = df.author.tolist()\n",
    "dates = df.date.tolist()\n",
    "\n",
    "# Getting only the years from dates list\n",
    "years = [re.sub('[A-Za-z ]', '', item) for item in dates]\n",
    "\n",
    "# Combining year with presenter for citation\n",
    "authordate = [author+\" \"+year for author, year in zip(authors, years)]\n",
    "\n",
    "# Just to check to see if things are synced,\n",
    "# let's create a new df with the two lists.\n",
    "\n",
    "citations = pandas.DataFrame(\n",
    "    {'citation': authordate,\n",
    "     'text': talks,\n",
    "    })\n",
    "\n",
    "# This just shows that the citation and the text are paired correctly.\n",
    "# citations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Settings & Display Functions\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "n_topics = 50\n",
    "n_features = 5000\n",
    "n_top_words = 10\n",
    "n_top_documents = 3\n",
    "\n",
    "\n",
    "stopwords = re.split('\\s+', open('../data/stopwords_all.txt', 'r').read().lower())\n",
    "\n",
    "def display_topics(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"| \"+str(topic_idx)+\" |\"+' '.join([feature_names[i] + ' ' + str(round(topic[i], 2))\n",
    "              +',' for i in topic.argsort()[:-n_top_words - 1:-1]])+\"|\")\n",
    "        \n",
    "# Both NMF **and** LDA produce two matrices: \n",
    "# H - words to topics\n",
    "# W - topics to documents\n",
    "\n",
    "def display_topics(H, W, feature_names, documents, n_top_words, n_top_documents):\n",
    "    for topic_idx, topic in enumerate(H):\n",
    "        print(\"Topic {}:\".format(topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        top_doc_indices = np.argsort( W[:,topic_idx] )[::-1][0:n_top_documents]\n",
    "        for doc_index in top_doc_indices:\n",
    "            print(documents[doc_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        print(\"| {}| \".format(topic_idx))\n",
    "        print(''.join([feature_names[i] + ' ' + str(round(topic[i], 2))\n",
    "              +', ' for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "\n",
    "# This version of the print/display function only lists words (no values)\n",
    "#        print(\" \".join([feature_names[i]\n",
    "#                        for i in topic.argsort()[:-no_top_words - 1:-1]]))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=\n",
    "# Generate LDA Model\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "\n",
    "# LDA can only use raw term counts (virtual BoW)\n",
    "tf_vectorizer = CountVectorizer(max_df = 0.95, \n",
    "                                min_df = 2, \n",
    "                                max_features = n_features, \n",
    "                                stop_words = stopwords)\n",
    "tf = tf_vectorizer.fit_transform(talks)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics = n_topics, \n",
    "                                max_iter = 5, \n",
    "                                learning_method = 'online', \n",
    "                                learning_offset = 50.,\n",
    "                                random_state = 0).fit(tf)\n",
    "lda_W = lda_model.transform(tf)\n",
    "lda_H = lda_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 0 |just 0.59, africa 0.59, people 0.43, africans 0.39, sectors 0.31, think 0.31, time 0.26, million 0.25, dollars 0.24, sector 0.24,|\n",
      "| 1 |know 0.54, battery 0.51, just 0.41, see 0.3, people 0.29, places 0.28, time 0.27, back 0.27, think 0.26, first 0.26,|\n",
      "| 2 |energy 0.17, earth 0.14, warming 0.12, climate 0.12, year 0.12, co 0.11, years 0.11, change 0.1, time 0.09, ocean 0.09,|\n",
      "| 3 |iran 145.87, east 113.02, israel 98.82, middle 87.35, region 66.98, arab 61.62, peace 59.92, israeli 49.68, islamic 47.91, great 47.7,|\n",
      "| 4 |weather 14.61, scores 4.46, score 3.87, data 3.11, numbers 2.25, colored 1.9, versus 1.71, element 1.59, vertical 1.51, dimensional 1.38,|\n",
      "| 5 |device 93.58, surveillance 67.07, gps 65.98, devices 59.69, wireless 59.34, hackers 55.55, security 54.6, rb 52.88, software 51.17, hacking 47.43,|\n",
      "| 6 |universe 258.72, quantum 164.32, particles 103.74, higgs 73.19, atoms 62.62, mechanics 59.88, particle 57.07, field 39.75, physics 37.23, physicists 29.85,|\n",
      "| 7 |data 460.88, just 406.8, computer 316.79, information 315.79, web 304.86, know 250.98, google 225.4, think 191.71, page 191.4, book 172.08,|\n",
      "| 8 |microbes 121.95, lt 56.89, microbial 54.28, community 28.65, gut 13.83, donor 6.11, communities 5.84, turns 5.26, project 4.48, just 3.86,|\n",
      "| 9 |sharks 126.16, shark 120.57, awesome 37.16, tag 34.89, fish 12.15, boat 10.64, caught 9.93, diversity 8.9, samples 8.35, slime 6.99,|\n",
      "| 10 |window 6.35, farms 2.51, systems 2.15, concerns 1.7, apartment 1.38, contributing 0.99, dirt 0.93, michael 0.59, open 0.47, collaboration 0.46,|\n",
      "| 11 |see 0.35, first 0.34, know 0.34, years 0.33, people 0.32, think 0.29, cancer 0.28, just 0.26, time 0.26, percent 0.23,|\n",
      "| 12 |great 0.18, people 0.16, know 0.13, think 0.11, see 0.11, different 0.11, passion 0.11, data 0.11, career 0.11, product 0.1,|\n",
      "| 13 |nuclear 237.14, power 156.92, fusion 91.83, energy 74.61, reactor 44.25, ab 43.87, digit 29.41, fuel 24.4, number 12.73, reaction 12.42,|\n",
      "| 14 |people 0.59, know 0.54, see 0.49, just 0.47, time 0.43, think 0.32, years 0.32, started 0.28, let 0.25, life 0.23,|\n",
      "| 15 |dolphins 73.05, dolphin 53.57, mold 41.23, slime 40.55, keyboard 10.24, request 8.51, rope 7.02, toy 6.62, underwater 4.99, researchers 4.82,|\n",
      "| 16 |lego 34.56, concrete 1.54, just 1.07, time 0.67, block 0.66, years 0.56, see 0.55, blocks 0.51, made 0.49, life 0.44,|\n",
      "| 17 |people 0.25, know 0.16, technology 0.13, need 0.12, years 0.12, just 0.12, book 0.11, problem 0.11, percent 0.11, afghanistan 0.1,|\n",
      "| 18 |women 0.55, heart 0.35, disease 0.24, people 0.24, years 0.21, men 0.21, think 0.21, just 0.21, see 0.2, breast 0.17,|\n",
      "| 19 |people 0.26, just 0.24, see 0.17, time 0.16, percent 0.15, think 0.15, magic 0.14, different 0.14, body 0.14, cancer 0.13,|\n",
      "| 20 |food 947.92, eat 339.31, bread 139.33, know 137.46, meat 132.84, eating 131.59, kids 116.19, feed 110.92, diet 93.17, waste 88.1,|\n",
      "| 21 |government 0.17, people 0.08, just 0.07, years 0.07, think 0.07, swim 0.07, know 0.07, city 0.07, important 0.06, getting 0.06,|\n",
      "| 22 |shame 57.95, vulnerability 51.79, vulnerable 10.22, researcher 9.97, courage 3.93, dish 1.18, said 1.13, uh 0.96, fuels 0.79, oil 0.69,|\n",
      "| 23 |africa 0.08, just 0.07, know 0.06, people 0.06, countries 0.06, brain 0.06, reform 0.06, talk 0.06, able 0.06, story 0.06,|\n",
      "| 24 |einstein 72.51, ooh 52.26, sw 46.83, birthday 6.26, penguin 6.09, drink 2.56, tweet 2.52, gore 1.99, caves 1.88, wrap 1.81,|\n",
      "| 25 |weapons 203.16, military 114.72, police 100.8, cyber 98.76, non 71.31, force 61.8, lethal 49.85, defense 49.19, attack 25.29, advantage 24.17,|\n",
      "| 26 |bees 178.41, choice 152.89, choices 131.46, ants 117.32, pollen 97.72, bee 80.08, chimpanzees 78.2, colony 69.82, cooperation 55.77, flowers 55.36,|\n",
      "| 27 |see 0.16, just 0.13, people 0.13, think 0.13, design 0.13, machine 0.12, time 0.11, nuclear 0.11, years 0.11, started 0.1,|\n",
      "| 28 |dinosaurs 125.85, dinosaur 81.51, museum 52.86, bone 48.02, bones 44.43, skull 29.35, found 20.24, duck 19.25, teeth 18.94, birds 18.81,|\n",
      "| 29 |silk 105.39, spider 74.78, fibers 20.35, web 13.39, protein 8.75, prey 7.43, proteins 6.67, repeat 6.06, fiber 5.98, capture 3.89,|\n",
      "| 30 |gay 150.94, deception 112.49, glamorous 62.17, copyright 58.48, glamour 55.26, rights 48.25, magic 47.71, mt 36.33, equality 31.4, protection 31.23,|\n",
      "| 31 |music 1010.12, play 743.09, sound 574.21, video 337.44, just 306.26, hear 277.85, song 253.16, piece 209.52, playing 195.89, sounds 194.77,|\n",
      "| 32 |religion 96.28, gun 62.04, religions 60.76, memes 45.17, violence 44.75, religious 42.23, guns 31.54, meme 28.83, ideas 9.52, darwin 9.16,|\n",
      "| 33 |just 0.33, people 0.25, see 0.23, know 0.23, time 0.22, first 0.21, think 0.2, sharks 0.17, day 0.17, power 0.16,|\n",
      "| 34 |just 0.23, people 0.19, see 0.19, time 0.18, dna 0.18, back 0.17, first 0.16, years 0.15, brain 0.15, think 0.15,|\n",
      "| 35 |percent 1278.15, years 913.7, people 908.81, countries 874.46, need 840.25, water 826.91, africa 825.81, country 672.68, global 666.57, year 650.29,|\n",
      "| 36 |life 0.1, just 0.09, different 0.07, movement 0.07, time 0.07, genes 0.07, living 0.07, long 0.06, people 0.06, old 0.06,|\n",
      "| 37 |robots 0.24, robot 0.23, see 0.2, people 0.18, create 0.14, time 0.14, think 0.12, just 0.12, today 0.12, data 0.12,|\n",
      "| 38 |mistake 3.89, people 0.94, see 0.8, think 0.75, just 0.7, brain 0.68, ll 0.63, know 0.59, time 0.52, years 0.45,|\n",
      "| 39 |people 0.16, choices 0.15, battery 0.14, choice 0.12, metal 0.11, think 0.11, just 0.11, today 0.11, liquid 0.11, high 0.11,|\n",
      "| 40 |see 4941.22, just 4870.91, think 3133.56, time 2837.9, know 2822.41, years 2303.44, first 2058.62, life 1947.92, back 1908.27, different 1838.25,|\n",
      "| 41 |people 0.51, life 0.36, just 0.3, time 0.3, see 0.27, first 0.25, know 0.22, think 0.22, important 0.19, different 0.19,|\n",
      "| 42 |brain 1323.29, cancer 1305.67, cells 1023.01, disease 839.93, just 785.23, people 783.7, body 757.2, see 745.43, patient 702.24, patients 687.29,|\n",
      "| 43 |just 0.41, people 0.38, life 0.32, years 0.26, online 0.22, know 0.2, today 0.2, think 0.2, three 0.19, last 0.19,|\n",
      "| 44 |people 0.47, just 0.42, know 0.35, life 0.26, think 0.26, person 0.25, year 0.24, brain 0.23, first 0.22, went 0.22,|\n",
      "| 45 |war 275.81, attack 84.81, bomb 79.53, muslim 74.4, attacks 71.25, islam 66.85, muslims 60.33, killed 59.75, terrorism 56.44, al 56.25,|\n",
      "| 46 |app 56.92, apps 30.08, programming 6.16, iphone 5.19, fortune 3.44, store 3.25, earth 2.64, development 2.58, software 2.42, teachers 2.31,|\n",
      "| 47 |people 0.17, just 0.16, know 0.16, time 0.13, said 0.12, sharks 0.11, back 0.11, water 0.11, carbon 0.11, ll 0.09,|\n",
      "| 48 |see 0.21, think 0.19, people 0.17, said 0.17, need 0.17, just 0.16, self 0.16, brain 0.14, know 0.14, different 0.14,|\n",
      "| 49 |people 12445.22, know 7275.57, just 7032.83, think 5953.96, said 5510.69, time 5012.65, see 3876.97, years 3765.44, first 3443.41, life 3107.94,|\n"
     ]
    }
   ],
   "source": [
    "display_topics(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# NMF Model\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# NMF is able to use tf-idf\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df = 0.95, \n",
    "                                   min_df = 2, \n",
    "                                   max_features = n_features, \n",
    "                                   stop_words = stopwords)\n",
    "tfidf = tfidf_vectorizer.fit_transform(talks)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "nmf = NMF(n_components=n_topics, \n",
    "          random_state=1, \n",
    "          alpha=.1, \n",
    "          l1_ratio=.5, \n",
    "          init='nndsvd').fit(tfidf)\n",
    "nmf_W = nmf.transform(tfidf)\n",
    "nmf_H = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 0 |people 0.8, just 0.73, know 0.66, think 0.54, time 0.48, see 0.47, said 0.44, life 0.36, years 0.36, first 0.33,|\n",
      "| 1 |kids 1.05, school 0.97, students 0.75, teachers 0.63, education 0.62, teacher 0.35, schools 0.3, learning 0.29, classroom 0.28, teach 0.24,|\n",
      "| 2 |countries 0.47, people 0.46, percent 0.38, money 0.34, country 0.34, government 0.33, dollars 0.32, global 0.32, economic 0.32, economy 0.29,|\n",
      "| 3 |brain 2.1, neurons 0.48, brains 0.28, cortex 0.16, neuron 0.15, activity 0.14, neuroscience 0.13, arm 0.13, memory 0.12, disorders 0.12,|\n",
      "| 4 |cancer 1.78, tumor 0.42, breast 0.22, disease 0.19, drug 0.18, tumors 0.16, body 0.16, protein 0.14, blood 0.13, cancers 0.12,|\n",
      "| 5 |dna 1.19, genome 0.5, genes 0.35, gene 0.3, chromosome 0.28, genetic 0.27, cell 0.24, molecular 0.21, code 0.21, species 0.19,|\n",
      "| 6 |universe 1.2, galaxies 0.47, galaxy 0.43, stars 0.35, light 0.27, telescope 0.25, dark 0.25, see 0.2, planets 0.17, theory 0.17,|\n",
      "| 7 |women 2.05, men 0.89, girls 0.51, woman 0.39, girl 0.22, gender 0.21, violence 0.19, pm 0.17, boys 0.16, said 0.15,|\n",
      "| 8 |robot 1.62, robots 1.03, robotics 0.15, see 0.08, video 0.07, move 0.07, legs 0.07, autonomous 0.06, robotic 0.06, lab 0.06,|\n",
      "| 9 |sound 1.3, voice 0.45, listening 0.45, noise 0.45, sounds 0.25, hear 0.23, ears 0.2, listen 0.18, hearing 0.18, voices 0.14,|\n",
      "| 10 |music 1.84, musical 0.26, orchestra 0.25, musicians 0.19, song 0.18, piece 0.16, playing 0.15, classical 0.15, instruments 0.15, musician 0.15,|\n",
      "| 11 |city 1.44, cities 1.11, rio 0.25, urban 0.24, cars 0.23, york 0.17, people 0.16, neighborhood 0.16, park 0.16, map 0.16,|\n",
      "| 12 |data 2.41, information 0.36, map 0.16, web 0.12, see 0.11, linked 0.06, patterns 0.06, numbers 0.05, analysis 0.05, points 0.05,|\n",
      "| 13 |energy 1.17, nuclear 0.43, climate 0.41, solar 0.33, fusion 0.28, electricity 0.26, coal 0.26, carbon 0.24, emissions 0.23, power 0.22,|\n",
      "| 14 |building 0.99, architecture 0.69, buildings 0.59, architects 0.25, project 0.2, built 0.18, architect 0.18, house 0.14, build 0.14, architectural 0.14,|\n",
      "| 15 |cells 1.57, stem 0.64, cell 0.45, tissue 0.24, bone 0.24, organs 0.21, disease 0.19, liver 0.18, body 0.17, drug 0.16,|\n",
      "| 16 |compassion 1.55, compassionate 0.24, suffering 0.13, religious 0.13, traditions 0.09, golden 0.09, beings 0.08, bread 0.08, love 0.08, happy 0.07,|\n",
      "| 17 |ice 0.97, pole 0.46, antarctica 0.4, glacier 0.23, south 0.17, snow 0.17, climate 0.16, polar 0.15, north 0.14, expedition 0.14,|\n",
      "| 18 |chinese 1.28, china 1.06, west 0.13, beijing 0.11, political 0.1, shanghai 0.09, state 0.09, north 0.08, chicken 0.07, asia 0.07,|\n",
      "| 19 |india 1.62, indian 0.64, cricket 0.18, innovation 0.16, china 0.13, growth 0.11, delhi 0.1, indians 0.09, country 0.07, pakistan 0.06,|\n",
      "| 20 |language 1.05, english 1.01, words 0.43, word 0.39, dictionary 0.27, arabic 0.26, languages 0.24, speak 0.14, usage 0.1, sentence 0.09,|\n",
      "| 21 |happiness 1.43, happy 0.31, wandering 0.19, mind 0.18, self 0.13, happier 0.11, experience 0.09, positive 0.09, remembering 0.08, experiencing 0.08,|\n",
      "| 22 |ocean 0.98, sea 0.55, coral 0.32, animals 0.31, oceans 0.27, shark 0.26, sharks 0.26, corals 0.23, marine 0.23, whales 0.2,|\n",
      "| 23 |space 1.85, spaces 0.17, body 0.16, nasa 0.12, moon 0.09, mall 0.09, prize 0.06, garage 0.06, experience 0.05, orbit 0.05,|\n",
      "| 24 |mars 0.97, earth 0.62, planets 0.62, planet 0.58, stars 0.26, solar 0.25, life 0.24, surface 0.21, atmosphere 0.2, star 0.2,|\n",
      "| 25 |design 1.91, designers 0.63, designer 0.25, designing 0.22, designed 0.19, products 0.12, product 0.11, technology 0.1, exhibition 0.09, furniture 0.09,|\n",
      "| 26 |machine 1.51, computer 0.85, machines 0.43, computers 0.43, learning 0.16, web 0.13, technology 0.12, algorithms 0.11, human 0.11, algorithm 0.1,|\n",
      "| 27 |autism 1.34, autistic 0.42, individuals 0.12, diagnosis 0.07, social 0.06, normal 0.05, vaccines 0.05, spectrum 0.05, mind 0.04, disorder 0.04,|\n",
      "| 28 |plants 1.08, plant 0.83, seeds 0.24, pollen 0.22, species 0.2, percent 0.14, genes 0.14, seed 0.12, flower 0.1, animals 0.09,|\n",
      "| 29 |water 2.2, river 0.23, drinking 0.16, waste 0.12, stream 0.11, desert 0.1, lake 0.09, sanitation 0.09, dry 0.09, supply 0.07,|\n",
      "| 30 |oil 1.56, gas 0.32, gulf 0.17, coal 0.16, energy 0.14, cars 0.09, carbon 0.09, fuel 0.09, price 0.08, natural 0.07,|\n",
      "| 31 |film 1.02, stories 0.95, story 0.73, films 0.42, storytelling 0.3, movie 0.19, man 0.13, tell 0.12, fiction 0.11, news 0.1,|\n",
      "| 32 |africa 1.66, african 0.66, continent 0.33, africans 0.33, nigeria 0.23, hiv 0.22, south 0.19, ghana 0.18, countries 0.16, kenya 0.14,|\n",
      "| 33 |dog 1.18, dogs 0.21, sit 0.12, song 0.12, cause 0.09, owner 0.08, catching 0.08, singing 0.07, animals 0.05, noise 0.05,|\n",
      "| 34 |malaria 0.93, mosquitos 0.49, mosquito 0.43, nets 0.17, gene 0.13, disease 0.12, bed 0.1, parasite 0.09, smell 0.07, bite 0.07,|\n",
      "| 35 |food 1.42, eat 0.35, farmers 0.25, meat 0.21, hunger 0.21, bread 0.21, feed 0.19, waste 0.18, eating 0.16, diet 0.14,|\n",
      "| 36 |quantum 0.88, higgs 0.43, particles 0.36, mechanics 0.28, particle 0.2, atoms 0.18, magnetic 0.15, field 0.14, theory 0.13, physics 0.13,|\n",
      "| 37 |patients 0.88, health 0.72, patient 0.55, care 0.47, medical 0.4, doctors 0.39, disease 0.31, hospital 0.28, medicine 0.28, doctor 0.28,|\n",
      "| 38 |internet 0.91, information 0.69, web 0.48, media 0.43, online 0.41, phone 0.3, government 0.27, twitter 0.27, digital 0.26, page 0.26,|\n",
      "| 39 |games 1.19, game 1.06, video 0.59, playing 0.21, players 0.17, player 0.13, play 0.12, virtual 0.1, real 0.1, online 0.07,|\n",
      "| 40 |children 1.75, child 0.82, family 0.34, parents 0.33, babies 0.33, families 0.24, mother 0.22, said 0.15, school 0.12, schools 0.12,|\n",
      "| 41 |fly 1.09, flying 0.34, flight 0.33, wing 0.31, wings 0.3, aircraft 0.25, airplane 0.2, flies 0.2, baby 0.14, pilot 0.11,|\n",
      "| 42 |fish 1.35, fisheries 0.25, feed 0.2, farm 0.18, tuna 0.17, fishing 0.14, shrimp 0.13, catch 0.12, oceans 0.09, wild 0.09,|\n",
      "| 43 |forest 0.9, trees 0.54, forests 0.36, species 0.34, tree 0.31, canopy 0.24, carbon 0.24, amazon 0.23, animals 0.19, deforestation 0.18,|\n",
      "| 44 |play 1.6, serious 0.18, piano 0.12, playing 0.09, kids 0.08, fun 0.08, creativity 0.06, played 0.03, think 0.03, laughter 0.03,|\n",
      "| 45 |bees 1.33, bee 0.32, pollen 0.28, flowers 0.17, honey 0.11, flower 0.1, colonies 0.09, colony 0.07, laughter 0.05, urban 0.04,|\n",
      "| 46 |art 1.23, artists 0.54, artist 0.51, painting 0.39, museum 0.3, paint 0.19, images 0.19, project 0.19, paintings 0.18, exhibition 0.15,|\n",
      "| 47 |sex 0.89, males 0.52, female 0.45, male 0.32, females 0.32, insects 0.32, sexual 0.31, sperm 0.27, love 0.09, arab 0.08,|\n",
      "| 48 |bacteria 1.39, molecule 0.28, antibiotics 0.2, molecules 0.15, organisms 0.12, bacterial 0.11, viruses 0.1, immune 0.08, species 0.08, sensing 0.07,|\n",
      "| 49 |iran 1.08, israel 0.42, israeli 0.2, war 0.08, east 0.07, islamic 0.07, jewish 0.07, iraq 0.06, poster 0.06, middle 0.06,|\n"
     ]
    }
   ],
   "source": [
    "display_topics(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "people just know think time see said life years first\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1051",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Users/john/Library/Python/3.4/lib/python/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1944\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1945\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1946\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1051",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-ac7500c904c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnmf_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnmf_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfidf_feature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcitations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_top_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_top_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-2d207692dbfb>\u001b[0m in \u001b[0;36mdisplay_topics\u001b[0;34m(H, W, feature_names, documents, no_top_words, no_top_documents)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtop_doc_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtopic_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mno_top_documents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_doc_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/john/Library/Python/3.4/lib/python/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/john/Library/Python/3.4/lib/python/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2002\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2004\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/john/Library/Python/3.4/lib/python/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/john/Library/Python/3.4/lib/python/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3290\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3291\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3292\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/john/Library/Python/3.4/lib/python/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1945\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1051"
     ]
    }
   ],
   "source": [
    "display_topics(nmf_H, nmf_W, tfidf_feature_names, talks, n_top_words, n_top_documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
