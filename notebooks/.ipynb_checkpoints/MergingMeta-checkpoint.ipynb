{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic code outline is as follows:   \n",
    "0. Import both *talks_6e.csv* and *metadata_all.csv*. Create output file *talks_6f.csv*\n",
    "1. Sort each import by the author name\n",
    "2. ~~For *metadata_all.csv*, create a new colum that breaks the slug up into a list of lower-cased words.~~ \n",
    "3. Create an index list for *metadata_all.csv*. The idea of this list is to remove rows from consideration as we match the slugs to rows in *talks_6e.csv*.\n",
    "4. Loop over each row in *talks_6e.csv*:\n",
    "  1. Create two new lists to use: \n",
    "    * The list of names, all lower cased\n",
    "    * The list of words in the title, all lowered case\n",
    "  2. Iterate over each available row in *metadata_all.csv*, matching the author lists to the slug lists. \n",
    "    * If the author and slug lists intersect over at least 50% of the words in the author list, then compare the title and slug lists\n",
    "    * If the title and slug lists match over 50% of the words in the title list, then match these rows and create a new row in the output that has the information from both *talks_6e.csv* and *metadata_all.csv*. Then move on to the next row of *metadata_all.csv*.\n",
    "    * If no match is found, move on to the next row of *metadata_all.csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 0 - Import CSV files\n",
    "read1 = csv.reader(open('../data/talks_6e.csv'))\n",
    "headers = next(read1)\n",
    "\n",
    "read2 = csv.reader(open('../../tedmetadata/metadata_all.csv'))\n",
    "head2 = next(read2)\n",
    "\n",
    "# Create headers for the output file, such that:\n",
    "#    * 'date' --> 'published'\n",
    "#    * 'numDate' --> numPub'\n",
    "\n",
    "ind = headers.index('date')\n",
    "headers[ind] = 'published'\n",
    "\n",
    "ind = headers.index('numDate')\n",
    "headers[ind] = 'numPub'\n",
    "\n",
    "# 2) Add headers from the *metadata_all.csv* file\n",
    "headers = headers[1:] + head2[1:] + ['numFilmed']\n",
    "\n",
    "# Set index names:\n",
    "#aund = headers.index('author')\n",
    "#tnd = headers.index('title')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = next(read1)\n",
    "#print(type(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(headers)\n",
    "#print(head2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(talks6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#talks6.iloc[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#talks6.loc[talks6.iloc[0].name].tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#row_test = talks6.loc[talks6.iloc[0].name]\n",
    "#row_test[\"author\"].lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the thinking.... maybe using pandas we can do all the things in place? Create a few fake lists that we add values to as we go. Then create a new pandas dataframe that has all the pieces. \n",
    "\n",
    "It seems to be easy to add a column to a pandas dataframe, but you have to have a full column. So basically, we pull each talk, add the info we need to new lists at the index that things will appear (using a hack of iloc+loc) and then add the new columns after the loop...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1 - Sort each import: one by slug, the other by author\n",
    "read1pd = pd.read_csv('../data/talks_6e.csv')\n",
    "talks6 = read1pd.sort_values(\"author\", kind=\"mergesort\")\n",
    "\n",
    "# Import *metadata_all.csv* as pandas data frame\n",
    "meta_raw = pd.read_csv('../../tedmetadata/metadata_all.csv')\n",
    "meta = meta_raw.sort_values(\"slug\", kind=\"mergesort\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#row2 = meta.iloc[2]\n",
    "#slist = row2['slug']\n",
    "#type(slist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 2 - For *metadata_all.csv*, create a dataframe with a new column where there is a list of words\n",
    "# jk, we're just going to do this in the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 3 - Create an index list for *metadata_all.csv*\n",
    "mnds = list(range(len(meta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Loop over the rows in *talks_6e.csv*\n",
    "with open('../data/talks_7.csv', 'w') as csvfile:\n",
    "    # Make the output file\n",
    "    outfile = csv.writer(csvfile)\n",
    "    outfile.writerow(headers)\n",
    "    \n",
    "    # Loop over each row in *talks_6e.csv*\n",
    "    for inds in range(len(talks6)):\n",
    "        talk_row = talks6.loc[talks6.iloc[inds].name]\n",
    "        aulist = talk_row[\"author\"].lower().split()\n",
    "        tlist = talk_row[\"title\"].lower().split()\n",
    "        \n",
    "        # Set MATCH flag\n",
    "        match = False\n",
    "        \n",
    "        for m in mnds:\n",
    "            # Grab row associated to index M in *metadata_all.csv*\n",
    "            row2 = meta.iloc[m]\n",
    "            slist = row2['slug'].lower().split('_')\n",
    "            \n",
    "            # Compare author and slug lists:\n",
    "            if len(set(aulist) & set(slist)) >= 0.5*len(aulist):\n",
    "                # If comparison goes well, then compare title and slug lists:\n",
    "                if len(set(tlist) & set(slist)) > 0.5*len(tlist):\n",
    "                    match = True\n",
    "                    \n",
    "            # If we find a match, then we need to add the output row:\n",
    "            if match: \n",
    "                add_row = talk_row.tolist()[1:]\n",
    "                add_row.append(row2['view_count'])\n",
    "                add_row.append(row2['event'])\n",
    "                add_row.append(row2['filmed'])\n",
    "                numFilmed = ''.join(row2[\"filmed\"].split('-'))\n",
    "                add_row.append(numFilmed)\n",
    "                \n",
    "                outfile.writerow(add_row)\n",
    "                \n",
    "                mnds.remove(m)\n",
    "                break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[2, 4, 5, 6]\n",
      "[4, 5, 6]\n",
      "5\n",
      "[4, 5, 6]\n",
      "[4, 6]\n"
     ]
    }
   ],
   "source": [
    "test = [2,4,5,6]\n",
    "for m in test:\n",
    "    print(m)\n",
    "    print(test)\n",
    "    test.remove(m)\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1375"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pd.read_csv('../data/talks_7.csv')\n",
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
