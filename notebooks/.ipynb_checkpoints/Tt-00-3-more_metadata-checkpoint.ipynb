{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Get the metadata for each of the talks which will tell us when the talk actually occurred along with the particular TED event at which it occurred. Bonus: get the view count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I consulted my own [notes][] (from May 2016) on how I previously downloaded the transcripts, and, as it turns out, the Google Doc is still available and up to date. This time I only copied the URLs and pasted them into a text file.  \n",
    "\n",
    "[notes]: http://johnlaudun.org/20160518-wgetting-ted-talk-transcripts/\n",
    "\n",
    "I tested the `wget` command twice:\n",
    "\n",
    "    wget -w 2 -i tedtalks_test.txt\n",
    "\n",
    "The first time I used the top three entries -- what now feels like the triumvirate of Gore, Pogue, and Carter -- but then discovered that all three are from the same TED event in 2006. I then re-tested the script with URLs for talks by Dawkins and Gladwell:\n",
    "\n",
    "    https://www.ted.com/talks/richard_dawkins_on_our_queer_universe\n",
    "    https://www.ted.com/talks/malcolm_gladwell_on_spaghetti_sauce\n",
    "\n",
    "The script worked both times. I appended HTML to the file names and opened in a text editor. I eventually located the information we want in a massive `<script>` block located near the end of a file. In one location is this:\n",
    "\n",
    "    \"recorded_at\":\"2005-07-07T00:00:00.000+00:00\"\n",
    "\n",
    "But a more interesting clump of data occurs just before this:\n",
    "\n",
    "    \"canonical\":\"https://www.ted.com/talks/richard_dawkins_on_our_queer_universe\",\n",
    "    \"external\":null,\"name\":\"Richard Dawkins: Why the universe seems so strange\",\n",
    "    \"title\":\"Why the universe seems so strange\",\n",
    "    \"speaker\":\"Richard Dawkins\",\n",
    "    \"thumb\":\"https://pi.tedcdn.com/r/pe.tedcdn.com/images/ted/160_480x360.jpg?quality=89&w=600\",\n",
    "    \"slug\":\"richard_dawkins_on_our_queer_universe\",\n",
    "    \"event\":\"TEDGlobal 2005\",\n",
    "    \"filmed\":1120694400,\n",
    "    \"published\":1158019860,\n",
    "\n",
    "Those last two are, of course, UNIX time codes that translate as follows:\n",
    "\n",
    "* `\"filmed\":1120694400` = Wednesday 6th July 2005\n",
    "* `\"published\":1158019860` = Monday 11th September 2006\n",
    "\n",
    "Elsewhere: `\"viewed_count\":2952227`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloaded Files\n",
    "\n",
    "The results of `wget -w 2 -i tedtalks_URLs.txt`:\n",
    "\n",
    "    FINISHED --2018-01-17 17:55:25--\n",
    "    Total wall clock time: 1h 54m 14s\n",
    "    Downloaded: 2628 files, 172M in 2m 27s (1.17 MB/s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments in Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "# LOAD the test file\n",
    "prefix = \"/Users/jjl5766/Dropbox/research/TEDTalks/tedarchives/\"\n",
    "text = open( prefix+'test_html/richard_dawkins_on_our_queer_universe.html',\n",
    "            'r').read()\n",
    "\n",
    "soup = BeautifulSoup(text, \"html5lib\")\n",
    "my_list = [i.string.lstrip('q(\"talkPage.init\", {\\n\\t\"el\": \"[data-talk-page]\",\\n\\t \"__INITIAL_DATA__\":')\n",
    "           .rstrip('})')\n",
    "           for i in soup.select('script') \n",
    "           if i.string and i.string.startswith('q')]\n",
    "\n",
    "# `my_list` is a list with only one item in it, but it is everything we want. \n",
    "# This could probably be a string, but I don't have that fu, so I now convert it \n",
    "# back to a string because that's what the JSON module wants.\n",
    "\n",
    "pre_json = '{\"' + \"\".join(my_list)\n",
    "# translation_table = dict.fromkeys(map(ord, '[]'), None)\n",
    "# delisted = pre_json.translate(translation_table)\n",
    "# print(delisted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event\n",
      "url\n",
      "viewed_count\n",
      "language\n",
      "description\n",
      "talks\n",
      "media\n",
      "speakers\n",
      "threadId\n",
      "comments\n",
      "current_talk\n",
      "name\n",
      "slug\n"
     ]
    }
   ],
   "source": [
    "my_json = json.loads(pre_json) # my_json is a Python dictionary\n",
    "# my_json = json.loads(delisted) # my_json is a Python dictionary\n",
    "\n",
    "# For those counting: we've gone string to list to string to dictionary.\n",
    "\n",
    "for key in my_json.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "682"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talks_listed = str(my_json['talks']).split(\",\")\n",
    "len(talks_listed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" 'filmed': 1120694400\"]\n",
      "[\" 'published': 1158019860\"]\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "re_list = [\n",
    "    \".*(filmed).*\",\n",
    "    \".*(published).*\" ]\n",
    "\n",
    "matches = []\n",
    "for e in re_list:\n",
    "    result = filter (re.compile(e).match, talks_listed)\n",
    "    matches.append(result)\n",
    "\n",
    "for i in range(len(matches)):\n",
    "    print(list(matches[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And here's an attempt to build a dictionary.\n",
    "\n",
    "import re \n",
    "\n",
    "properties = \"filmed,published\" # No spaces between terms!\n",
    "regex_list = [\".*(\"+i+\").*\" for i in properties.split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(string.split(':') for string in a_list)\n",
    "\n",
    "matches = []\n",
    "for prop in regex_list:\n",
    "    result = ''.join(list(filter(re.compile(prop).match, talks_listed)))#.split(\":\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.*(filmed).*', '.*( published).*']\n"
     ]
    }
   ],
   "source": [
    "print(regex_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Older Attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "data_dict = ast.literal_eval(str(my_json['talks']))\n",
    "\n",
    "len(data_dict)\n",
    "\n",
    "for key in data_dict.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "json_talks = json.loads(str(my_json['talks']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
