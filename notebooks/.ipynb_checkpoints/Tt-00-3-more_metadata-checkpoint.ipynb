{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Get the metadata for each of the talks which will tell us when the talk actually occurred along with the particular TED event at which it occurred. Bonus: get the view count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I consulted my own [notes][] (from May 2016) on how I previously downloaded the transcripts, and, as it turns out, the Google Doc is still available and up to date. This time I only copied the URLs and pasted them into a text file.  \n",
    "\n",
    "[notes]: http://johnlaudun.org/20160518-wgetting-ted-talk-transcripts/\n",
    "\n",
    "I tested the `wget` command twice:\n",
    "\n",
    "    wget -w 2 -i tedtalks_test.txt\n",
    "\n",
    "The first time I used the top three entries -- what now feels like the triumvirate of Gore, Pogue, and Carter -- but then discovered that all three are from the same TED event in 2006. I then re-tested the script with URLs for talks by Dawkins and Gladwell:\n",
    "\n",
    "    https://www.ted.com/talks/richard_dawkins_on_our_queer_universe\n",
    "    https://www.ted.com/talks/malcolm_gladwell_on_spaghetti_sauce\n",
    "\n",
    "The script worked both times. I appended HTML to the file names and opened in a text editor. I eventually located the information we want in a massive `<script>` block located near the end of a file. In one location is this:\n",
    "\n",
    "    \"recorded_at\":\"2005-07-07T00:00:00.000+00:00\"\n",
    "\n",
    "But a more interesting clump of data occurs just before this:\n",
    "\n",
    "    \"canonical\":\"https://www.ted.com/talks/richard_dawkins_on_our_queer_universe\",\n",
    "    \"external\":null,\"name\":\"Richard Dawkins: Why the universe seems so strange\",\n",
    "    \"title\":\"Why the universe seems so strange\",\n",
    "    \"speaker\":\"Richard Dawkins\",\n",
    "    \"thumb\":\"https://pi.tedcdn.com/r/pe.tedcdn.com/images/ted/160_480x360.jpg?quality=89&w=600\",\n",
    "    \"slug\":\"richard_dawkins_on_our_queer_universe\",\n",
    "    \"event\":\"TEDGlobal 2005\",\n",
    "    \"filmed\":1120694400,\n",
    "    \"published\":1158019860,\n",
    "\n",
    "Those last two are, of course, UNIX time codes that translate as follows:\n",
    "\n",
    "* `\"filmed\":1120694400` = Wednesday 6th July 2005\n",
    "* `\"published\":1158019860` = Monday 11th September 2006\n",
    "\n",
    "Elsewhere: `\"viewed_count\":2952227`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloaded Files\n",
    "\n",
    "The results of `wget -w 2 -i tedtalks_URLs.txt`:\n",
    "\n",
    "    FINISHED --2018-01-17 17:55:25--\n",
    "    Total wall clock time: 1h 54m 14s\n",
    "    Downloaded: 2628 files, 172M in 2m 27s (1.17 MB/s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments in Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re \n",
    "\n",
    "\n",
    "# LOAD the test file\n",
    "prefix = \"/Users/john/Code/tedarchives/\"\n",
    "text = open( prefix+'test_html/richard_dawkins_on_our_queer_universe.html',\n",
    "            'r').read()\n",
    "\n",
    "# We read the HTML into BS and then select only the script section we want\n",
    "soup = BeautifulSoup(text, \"html5lib\")\n",
    "my_list = [i.string.lstrip('q(\"talkPage.init\", {\\n\\t\"el\": \"[data-talk-page]\",\\n\\t \"__INITIAL_DATA__\":')\n",
    "           .rstrip('})')\n",
    "           for i in soup.select('script') \n",
    "           if i.string and i.string.startswith('q')]\n",
    "\n",
    "# `my_list` is a list with only one item in it, but it is everything we want.\n",
    "# Sadly the JSON module wants a string and the stripping above gets taking out\n",
    "# the opening curly brace, which JSON is very fussy about. \n",
    "\n",
    "# Add the opening brace, stringify, parse into JSON (which is a Python dictionary).\n",
    "# For those counting: we've gone string to list to string to dictionary.\n",
    "\n",
    "pre_json = '{\"' + \"\".join(my_list)\n",
    "my_json = json.loads(pre_json)\n",
    "\n",
    "# for key in my_json.keys():\n",
    "#     print(key) \n",
    "# viewed_count, current_talk, talks, media, speakers, description\n",
    "# url, name, slug, language, comments, threadId, event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'richard_dawkins_on_our_queer_universe'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_json['slug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# talks is a giant list with improper JSON using single quote marks\n",
    "# So we're going to string it and split it into a list (of 682 items!)\n",
    "# and then grab items out of the list using regex.\n",
    "\n",
    "talks_listed = str(my_json['talks']).split(\",\")\n",
    "\n",
    "properties = \"filmed,published\" # No spaces between terms!\n",
    "regex_list = [\".*(\"+i+\").*\" for i in properties.split(\",\")]\n",
    "\n",
    "matches = []\n",
    "for e in regex_list:\n",
    "    filtered = filter(re.compile(e).match, talks_listed)\n",
    "    indexed = \"\".join(filtered).split(\":\")[1]\n",
    "    matches.append(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 1120694400', ' 1158019860']\n"
     ]
    }
   ],
   "source": [
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2005-07-07'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "datetime.utcfromtimestamp(1120694400).strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2018-01-20**. At long last, results. I think the part that addresses what's inside the talks will need to go inside a function, but I think the rest can be in a `for` loop that works through all the texts. Now to compile these results into an executable script and try it on the `test_html`. From there, I will need to see how to capture the results -- it's not clear to me what data structure (unless it's straight to a dataframe) and then figure out how to sync that dataframe with the main one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "richard_dawkins_on_our_queer_universe 2952227 TEDGlobal 2005  1120694400  1158019860\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re \n",
    "\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "#  LOAD the file\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "prefix = \"/Users/john/Code/tedarchives/\"\n",
    "text = open( prefix+'test_html/richard_dawkins_on_our_queer_universe.html',\n",
    "            'r').read()\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Read the HTML & get the section we want\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "soup = BeautifulSoup(text, \"html5lib\")\n",
    "my_list = [i.string.lstrip('q(\"talkPage.init\", {\\n\\t\"el\": \"[data-talk-page]\",\\n\\t \"__INITIAL_DATA__\":')\n",
    "           .rstrip('})')\n",
    "           for i in soup.select('script') \n",
    "           if i.string and i.string.startswith('q')]\n",
    "\n",
    "pre_json = '{\"' + \"\".join(my_list)\n",
    "my_json = json.loads(pre_json)\n",
    "\n",
    "out_slug = my_json['slug']\n",
    "out_vcount = my_json['viewed_count']\n",
    "out_event = my_json['event']\n",
    "\n",
    "talks_listed = str(my_json['talks']).split(\",\")\n",
    "\n",
    "properties = \"filmed,published\" # No spaces between terms!\n",
    "regex_list = [\".*(\"+i+\").*\" for i in properties.split(\",\")]\n",
    "\n",
    "matches = []\n",
    "for e in regex_list:\n",
    "    filtered = filter(re.compile(e).match, talks_listed)\n",
    "    indexed = \"\".join(filtered).split(\":\")[1]\n",
    "    matches.append(indexed)\n",
    "\n",
    "out_filmed =  matches[0]\n",
    "out_published = matches[1]\n",
    "\n",
    "print(out_slug, out_vcount, out_event, out_filmed, out_published)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(the_file):\n",
    "    \n",
    "    # Load the modules we need\n",
    "    from bs4 import BeautifulSoup\n",
    "    import json\n",
    "    import re\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Read the file, load it into BS, then grab section we want\n",
    "    text = the_file.read()\n",
    "    soup = BeautifulSoup(text, \"html5lib\")\n",
    "    my_list = [i.string.lstrip('q(\"talkPage.init\", {\\n\\t\"el\": \"[data-talk-page]\",\\n\\t \"__INITIAL_DATA__\":')\n",
    "               .rstrip('})')\n",
    "               for i in soup.select('script') \n",
    "               if i.string and i.string.startswith('q')]\n",
    "    \n",
    "    # Read first layer of JSON and get out those elements we want\n",
    "    pre_json = '{\"' + \"\".join(my_list)\n",
    "    my_json = json.loads(pre_json)\n",
    "    slug = my_json['slug']\n",
    "    vcount = my_json['viewed_count']\n",
    "    event = my_json['event']\n",
    "    \n",
    "    # Read second layer of JSON and get out listed elements:\n",
    "    properties = \"filmed,published\" # No spaces between terms!\n",
    "    talks_listed = str(my_json['talks']).split(\",\")\n",
    "    regex_list = [\".*(\"+i+\").*\" for i in properties.split(\",\")]\n",
    "    matches = []\n",
    "    for e in regex_list:\n",
    "        filtered = filter(re.compile(e).match, talks_listed)\n",
    "        indexed = \"\".join(filtered).split(\":\")[1]\n",
    "        matches.append(indexed)\n",
    "    filmed = datetime.utcfromtimestamp(float(matches[0])).strftime('%Y-%m-%d')\n",
    "    published = datetime.utcfromtimestamp(float(matches[1])).strftime('%Y-%m-%d')\n",
    "    return slug, vcount, event, filmed, published\n",
    "\n",
    "def to_csv(pth, out):\n",
    "    # LOAD required modules\n",
    "    import csv\n",
    "    import os\n",
    "    # OPEN file to which to write:\n",
    "    with open(out, \"w\") as out:\n",
    "        # create csv.writer.\n",
    "        wr = csv.writer(out)\n",
    "        # write our headers.\n",
    "        wr.writerow([\"slug\", \"view_count\", \"event\", \"filmed\", \"published\"])\n",
    "        # get all our html files.\n",
    "        for html in os.listdir(pth):\n",
    "            with open(os.path.join(pth, html)) as f:\n",
    "                print(html)\n",
    "                # parse the file and write the data to a row.\n",
    "                wr.writerow(parse(BeautifulSoup(f, \"lxml\")))\n",
    "                \n",
    "# to_csv(\"./talks\",\"talks.csv\") # This is to the test directory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('richard_dawkins_on_our_queer_universe', 2952227, 'TEDGlobal 2005', '2005-07-07', '2006-09-12')\n"
     ]
    }
   ],
   "source": [
    "with open(\"/Users/john/Code/tedarchives/test_html/richard_dawkins_on_our_queer_universe.html\") as my_file:\n",
    "    print(get_metadata(my_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
