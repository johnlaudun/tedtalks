{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TEDtalks: Topics with LDA\n",
    "\n",
    "# =-=-=-=-=-=\n",
    "# Read CSV into DataFrame and then create lists\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "import pandas\n",
    "import re\n",
    "\n",
    "\n",
    "# Create pandas dataframe\n",
    "colnames = ['author', 'title', 'date' , 'length', 'text']\n",
    "df = pandas.read_csv('../data/talks_3a.csv', names=colnames)\n",
    "\n",
    "# Create lists for the data\n",
    "talks = df.text.tolist()\n",
    "authors = df.author.tolist()\n",
    "dates = df.date.tolist()\n",
    "\n",
    "# Getting only the years from dates list\n",
    "years = [re.sub('[A-Za-z ]', '', item) for item in dates]\n",
    "\n",
    "# Combining year with presenter for citation\n",
    "authordate = [author+\" \"+year for author, year in zip(authors, years)]\n",
    "\n",
    "# Just to check to see if things are synced,\n",
    "# let's create a new df with the two lists.\n",
    "\n",
    "citations = pandas.DataFrame(\n",
    "    {'citation': authordate,\n",
    "     'text': talks,\n",
    "    })\n",
    "\n",
    "# This just shows that the citation and the text are paired correctly.\n",
    "# citations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Settings & Display Functions\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "n_topics = 40\n",
    "n_features = 5000\n",
    "n_top_words = 10\n",
    "n_top_documents = 5\n",
    "\n",
    "\n",
    "stopwords = re.split('\\s+', open('../data/stopwords_all.txt', 'r').read().lower())\n",
    "\n",
    "def display_topics(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"| {:d} | \".format(topic_idx)\n",
    "        message += \" \".join([feature_names[i] + ' ' + str(round(topic[i], 2)) + ','\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "    \n",
    "# Both NMF **and** LDA produce two matrices: \n",
    "# H - words to topics\n",
    "# W - topics to documents\n",
    "\n",
    "def display_topics_HW(H, W, feature_names, documents, n_top_words, n_top_documents):\n",
    "    for topic_idx, topic in enumerate(H):\n",
    "        print(\"Topic {}:\".format(topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        top_doc_indices = np.argsort( W[:,topic_idx] )[::-1][0:n_top_documents]\n",
    "        for doc_index in top_doc_indices:\n",
    "            print(documents[doc_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=20, mean_change_tol=0.001,\n",
       "             n_components=40, n_jobs=1, n_topics=None, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =-=-=-=-=-=\n",
    "# Generate LDA Model\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# LDA can only use raw term counts (virtual BoW)\n",
    "tf_vectorizer = CountVectorizer(max_df = 0.95, \n",
    "                                min_df = 2, \n",
    "                                max_features = n_features, \n",
    "                                stop_words = stopwords)\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(talks)\n",
    "\n",
    "# Optional code to safe TF array\n",
    "# tf_array = tf.toarray()\n",
    "# np.savetxt(\"../outputs/tentexts_tf.csv\", tf_array.astype(np.int), fmt='%d', delimiter=\",\")\n",
    "# print(\"A tf array of {} has been saved to CSV.\".format(tf.shape))\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components = n_topics, \n",
    "                                max_iter = 20, \n",
    "                                learning_method = 'online', \n",
    "                                learning_offset = 50.,\n",
    "                                random_state = 0)\n",
    "\n",
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 0 | just 0.03, people 0.03, think 0.03, time 0.03, know 0.03, million 0.03, said 0.03, percent 0.03, fish 0.03, dollars 0.03,\n",
      "| 1 | energy 910.07, power 656.41, nuclear 318.98, electricity 211.46, wind 174.49, fuel 160.54, battery 157.58, coal 146.68, carbon 104.94, cell 58.55,\n",
      "| 2 | energy 0.03, earth 0.03, move 0.03, years 0.03, climate 0.03, year 0.03, warming 0.03, co 0.03, time 0.03, let 0.03,\n",
      "| 3 | century 319.58, th 259.33, religion 212.15, book 189.74, history 187.98, images 169.24, great 165.47, iran 153.75, war 139.71, east 138.46,\n",
      "| 4 | water 1056.35, air 297.12, map 203.32, plant 177.61, sand 166.56, see 164.58, environment 163.47, green 150.67, mushroom 130.52, temperature 124.68,\n",
      "| 5 | data 1111.57, information 1000.88, internet 806.08, people 638.91, computer 539.53, just 525.34, technology 505.28, system 447.64, phone 412.28, government 401.27,\n",
      "| 6 | see 1012.47, space 966.87, earth 918.17, universe 866.99, light 702.06, life 633.89, science 564.03, years 512.29, planet 511.07, time 403.51,\n",
      "| 7 | just 6559.56, know 6069.86, think 4083.88, people 4032.08, time 3753.03, see 3751.16, said 2946.0, back 2432.86, first 2198.98, ll 2151.6,\n",
      "| 8 | species 901.56, animals 804.7, just 734.16, food 662.68, fish 604.65, see 588.28, years 582.4, ocean 572.08, know 535.49, think 447.22,\n",
      "| 9 | black 509.7, white 182.4, sharks 137.32, shark 130.35, tag 71.99, awesome 61.15, boat 28.6, satellite 20.45, worldwide 19.97, net 16.47,\n",
      "| 10 | just 0.03, people 0.03, said 0.03, years 0.03, know 0.03, think 0.03, time 0.03, important 0.03, see 0.03, film 0.03,\n",
      "| 11 | know 0.03, see 0.03, people 0.03, think 0.03, years 0.03, first 0.03, cancer 0.03, just 0.03, said 0.03, time 0.03,\n",
      "| 12 | people 0.03, dinosaurs 0.03, sharks 0.03, different 0.03, think 0.03, just 0.03, see 0.03, know 0.03, found 0.03, three 0.03,\n",
      "| 13 | self 483.07, life 360.44, number 258.38, career 132.62, systems 72.89, square 71.19, numbers 69.9, passion 63.33, plus 60.14, system 59.92,\n",
      "| 14 | shame 91.79, vulnerability 71.63, bats 70.62, blindness 49.22, bat 42.69, mistake 42.25, empathy 37.21, dish 26.65, vulnerable 23.47, fortune 22.57,\n",
      "| 15 | sound 586.75, play 561.57, sounds 183.13, toy 92.6, communication 83.15, dolphins 77.65, communicate 72.38, mold 61.57, dolphin 55.9, toys 48.74,\n",
      "| 16 | malaria 196.85, bg 161.11, smell 95.04, mosquito 70.0, mosquitos 59.94, parachute 44.91, smells 23.76, altitude 18.54, bite 16.09, fly 9.09,\n",
      "| 17 | people 0.03, know 0.03, problem 0.03, percent 0.03, war 0.03, think 0.03, just 0.03, years 0.03, need 0.03, time 0.03,\n",
      "| 18 | monkey 142.32, monkeys 124.74, passwords 71.8, symbols 67.29, password 50.41, random 40.78, people 27.52, found 18.88, policy 15.67, computer 14.66,\n",
      "| 19 | people 0.03, just 0.03, see 0.03, time 0.03, percent 0.03, heart 0.03, body 0.03, think 0.03, information 0.03, data 0.03,\n",
      "| 20 | people 4065.03, percent 2091.22, think 2069.33, just 2022.1, need 1769.99, years 1762.46, see 1345.59, know 1334.5, year 1302.41, time 1202.45,\n",
      "| 21 | government 0.03, swim 0.03, see 0.03, years 0.03, know 0.03, said 0.03, cancer 0.03, help 0.03, think 0.03, just 0.03,\n",
      "| 22 | glamour 0.03, just 0.03, people 0.03, years 0.03, said 0.03, glamorous 0.03, think 0.03, shame 0.03, life 0.03, know 0.03,\n",
      "| 23 | talk 0.03, just 0.03, know 0.03, brain 0.03, different 0.03, time 0.03, people 0.03, groups 0.03, need 0.03, think 0.03,\n",
      "| 24 | ooh 94.07, beer 79.61, pig 61.1, einstein 55.41, sw 47.03, sing 24.1, penguin 10.61, birthday 7.55, drink 6.01, gore 4.14,\n",
      "| 25 | force 235.85, robots 234.73, police 228.4, robot 226.74, weapons 216.78, military 215.36, non 137.2, war 100.28, soldiers 94.97, people 80.02,\n",
      "| 26 | choice 196.29, bees 196.17, ants 170.43, choices 159.86, ant 103.73, pollen 102.85, different 96.91, bee 92.9, colony 91.38, choose 90.23,\n",
      "| 27 | see 0.03, just 0.03, machine 0.03, time 0.03, people 0.03, think 0.03, know 0.03, first 0.03, design 0.03, years 0.03,\n",
      "| 28 | dinosaurs 141.35, bone 131.6, chicken 92.13, prize 89.52, dinosaur 86.67, copyright 76.74, bones 69.51, found 59.76, rb 58.82, fashion 53.72,\n",
      "| 29 | silk 119.08, spider 90.39, glamorous 70.4, glamour 55.58, fibers 35.37, protein 33.03, web 19.96, proteins 18.94, fiber 17.16, see 16.9,\n",
      "| 30 | women 2078.58, men 1063.29, said 888.07, woman 695.31, children 621.57, school 566.35, girls 524.61, girl 418.32, sex 329.37, college 297.92,\n",
      "| 31 | people 5832.59, think 2034.94, said 1849.25, know 1809.72, life 1626.53, time 1449.35, just 1442.16, years 1071.56, first 929.42, believe 879.52,\n",
      "| 32 | language 821.77, building 711.48, english 396.58, words 317.12, buildings 282.29, word 239.62, books 165.78, languages 128.41, learning 117.34, architects 106.03,\n",
      "| 33 | fly 417.97, flight 189.67, flying 171.74, airplane 140.29, wing 79.29, aircraft 76.42, pilot 75.61, wings 53.65, transition 47.88, ground 22.36,\n",
      "| 34 | hum 76.94, titan 59.66, production 4.5, troops 3.81, brain 3.73, nation 3.52, bubbles 1.82, cell 1.09, clinical 0.96, globally 0.95,\n",
      "| 35 | years 1096.89, people 762.43, back 761.71, africa 672.14, war 600.3, time 570.74, see 568.49, went 560.38, first 547.93, day 545.15,\n",
      "| 36 | just 0.03, life 0.03, people 0.03, see 0.03, different 0.03, time 0.03, brain 0.03, said 0.03, old 0.03, know 0.03,\n",
      "| 37 | time 0.03, see 0.03, robot 0.03, robots 0.03, people 0.03, just 0.03, think 0.03, year 0.03, government 0.03, different 0.03,\n",
      "| 38 | brain 2230.4, see 1890.8, just 1759.5, think 1247.37, different 1123.4, cells 1098.08, cancer 1083.62, body 946.49, time 918.55, first 908.84,\n",
      "| 39 | just 0.03, time 0.03, battery 0.03, people 0.03, technology 0.03, see 0.03, think 0.03, metal 0.03, high 0.03, points 0.03,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Display the topics\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "display_topics(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Create dataframes of TF, H, and W\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "# Create TF dataframe\n",
    "df_tf = pd.DataFrame(data= tf_array, index = docs, columns = tf_feature_names)\n",
    "\n",
    "# Uncomment to glimpse dataframe\n",
    "# df_tf.head(10)\n",
    "\n",
    "# Save TF dataframe to CSV file\n",
    "df_tf.to_csv('../outputs/tf_frame.csv', sep=',')\n",
    "\n",
    "# Get W (DTM) and H (WTM) arrays\n",
    "lda_W = lda.transform(tf)\n",
    "lda_H = lda.components_\n",
    "\n",
    "df_lda_DTM = pd.DataFrame(data= lda_W, index = docs, columns = topic_labels)\n",
    "df_lda_DTM.to_csv('../outputs/lda_DTM.csv', sep=',')\n",
    "print(df_lda_DTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display_topics(nmf_H, nmf_W, tfidf_feature_names, talks, n_top_words, n_top_documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
