{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequently Occurring Numbers\n",
    "\n",
    "One of the dimensions of the corpus that arises out of a hand inspection of the terms if the frequency with which some numbers appear. The follow table captures the top ten numbers:\n",
    "\n",
    "| TERM | FREQUENCY |\n",
    "|------|-----------|\n",
    "| 000  | 2098 |\n",
    "| 10   | 1691 |\n",
    "|  20  | 1107 |\n",
    "| 100  |  902 |\n",
    "|  30  |  827 |\n",
    "|  50  |  784 |\n",
    "|  15  |  659 | \n",
    "|  40  |  494 |\n",
    "|  12  |  460 | \n",
    "|  25  |  410 |\n",
    "\n",
    "Other frequently occurring numbers: 60, 500, 200, 11, 18, 80, 14 (241 times!). \n",
    "\n",
    "In order to examine the appearance of the numbers in context, we make a giant string out of the list of strings, `texts`: in which text a number appears is less important than its immediate context. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd, re, nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1747, 27)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Main Dataframe\n",
    "df = pd.read_csv('../output/TEDall_speakers.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df.text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50379, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies = pd.read_csv('../output/word_freq.csv')\n",
    "frequencies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a quick reminder of what the `texts` look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Thank you so much, Chris. And it's truly a great honor to have the opportunity to come to this sta\n"
     ]
    }
   ],
   "source": [
    "print(texts[0][0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally I would use `words = re.sub(\"[^a-zA-Z']\",\" \", mdg).lower().split()` but in this case we want to keep the non-letter numbers, so we'll keep it simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thank', 'you', 'so', 'much,', 'Chris.', 'And', \"it's\", 'truly', 'a', 'great']\n"
     ]
    }
   ],
   "source": [
    "onetext = nltk.Text('\\n'.join(texts).split())\n",
    "# And here's what an NLTK text object looks like: a list of words, really\n",
    "print(onetext[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no matches\n"
     ]
    }
   ],
   "source": [
    "onetext.concordance(\"000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 1216 matches:\n",
      "Thank you very much. (Applause) About 10 years ago, I took on the task to teac\n",
      "tion of income of people. One dollar, 10 dollars or 100 dollars per day. There\n",
      " a long time, but they come out after 10 years very, very differently. And the\n",
      "at drives you in your life today? Not 10 years ago. Are you running the same p\n",
      "really heavy, but in the last five or 10 years, have there been some decisions\n",
      ". (Laughter) Are you sure? (Laughter) 10 seconds! (Laughter and applause) 10 s\n",
      ") 10 seconds! (Laughter and applause) 10 seconds, I want to be respectful. All\n",
      "principle in the Bible that says give 10 percent of what you get back to chari\n",
      "ional shelter that would last five to 10 years, that would be placed next to t\n",
      "tandards of five billion people? With 10 million solutions. So I wish to devel\n",
      " to go see Central Command, which was 10 minutes away. And that way, I could g\n",
      " will not launch this without five to 10 million units in the first run. And t\n",
      " down, and that's why I said seven to 10 million there. And we're doing it wit\n",
      " your laptop costs, in rough numbers, 10 dollars a diagonal inch. That can dro\n",
      "s; I can just go right up and use all 10 fingers if I wanted to. You know, lik\n",
      "ade by hand, and where, when you work 10 hours a day, you're still only earnin\n",
      "years; you have to be looking five or 10 years ahead. But I think with the vis\n",
      "ll from Earthlink that said, due to a 10 cents per megabyte overage charge, I \n",
      "umcised against her will when she was 10 years old, and she really made a deci\n",
      "and they simply point and they go for 10 percent, right in the middle. Howard \n",
      "ss in this country. And over the next 10 years, they made 600 million dollars \n",
      " you today is that, in fact, based on 10 years of research, a unique opportuni\n",
      "in the housing project on and off for 10 years, hanging out in crack houses, g\n",
      " marathons back to back. 800 miles in 10 weeks. And I was dragging all the foo\n",
      "week. He described this expedition as 10 times as dangerous as Everest. So for\n"
     ]
    }
   ],
   "source": [
    "onetext.concordance(\"10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 387 matches:\n",
      "w York City already handled more than 40 percent of the entire city's commerci\n",
      "ing rooms, whose evolution in 20, 30, 40 years we can't predict. So that liter\n",
      "nd all the other teams have done this 40 Days of Purpose, based on the book. A\n",
      "nternet tools, and we ended up having 40 chapters starting up, thousands of ar\n",
      "cumented the Lower Ninth for the last 40 years. That was their home, and these\n",
      "me. And a long time ago — well, about 40 years ago — my mom had an exchange st\n",
      " world where women and children spend 40 billion hours a year fetching water. \n",
      " age category of 76 to 85, as much as 40 percent of people have nothing really\n",
      "things tend to happen every 25 years. 40 years long, with an overlap. You can \n",
      " all high-rises. So they'll put 20 or 40 up at a time, and they just go up in \n",
      "te, we've seen no side effects in the 40 or so patients in whom it's been impl\n",
      " terms of price performance, that's a 40 to 50 percent deflation rate. And eco\n",
      " people may increase their volume 30, 40 percent, but they won't keep up with \n",
      "r hunters could smell animal urine at 40 paces and tell you what species left \n",
      "percent of all the pregnancies. About 40 percent of all the people — I said 40\n",
      "I said 400,000. I meant 40,000. About 40 percent of all the people who need TB\n",
      "tt-hours per kilogram nickel-cadmium, 40 watt-hours per kilogram in nickel-met\n",
      "n 60 in captivity, so we've only done 40 years in the wild so far. And we find\n",
      "ater. Imagine what the world was like 40 years ago, with just the Saturday Eve\n",
      " to India. India and China used to be 40 percent of the global economy just at\n",
      "ongo River. Canopied trees as tall as 40 meters, 130 feet, grow densely in the\n",
      "Hong Kong, with six million people in 40 square miles. During the dry season, \n",
      " farming the same piece of ground for 40 centuries. You can't farm the same pi\n",
      "n't farm the same piece of ground for 40 centuries without understanding nutri\n",
      "o measure it — but it's anywhere from 40 to 60 years. It goes on a long time. \n"
     ]
    }
   ],
   "source": [
    "onetext.concordance(\"40\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of things to note here:\n",
    "\n",
    "First, there is a discrepancy in the count between `sklearn` and the NLTK: the former counted 2098 occurrences of `000`, the latter none. In all the counts that follow, there is a similar mismatch:\n",
    "\n",
    "| TERM | `sklearn` | `nltk` |\n",
    "|------|-----------|--------|\n",
    "| 000  | 2098 | \"no match\" |\n",
    "|  10  | 1691 | 1216 |\n",
    "|  20  | 1107 | 879 |\n",
    "| 100  |  902 | 647 |\n",
    "|  30  |  827 | 650 |\n",
    "|  50  |  784 | 594 | \n",
    "|  15  |  659 | 512 | \n",
    "|  40  |  494 | 387 | \n",
    "| ...               | \n",
    "|  14  |  241 | 148 | \n",
    "\n",
    "I don't have a ready explanation for this.\n",
    "\n",
    "Second, the frequency of some numbers are readily explained:\n",
    "\n",
    "* Round numbers like 10, 20, 30, 50, and 100 are approximations -- though it would be interesting to explore how often they are attached to large scalars like \"thousand\" or million.\" \n",
    "* Some numbers seem to represent alternate ways of counting: 25 reagularly stands in for \"one-quarter\" -- though not as often as we might imagine -- and 18 is regularly paired with *month* as a more precise way to say \" a year and a half.\"\n",
    "* There are some numbers, like 11 and 14 which seem to have power all their own, perhaps tied to particular ages in humans. \n",
    "\n",
    "Next up is some code to explore the most common occurring words with these numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All my searches for \"collocations with specific words\" took me to the NLTK, which means, so far as I can tell, generating all the bigrams and then filtering to get the one(s) you want. This seems backwards to me: wouldn't it be faster simply to find the word and then what comes after it? I'll take a look at regex for this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bigrams\n",
    "finder = BigramCollocationFinder.from_words(onetext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('14', 'years'), ('14', 'billion'), ('was', '14'), ('14', 'years,'), ('14', 'hours'), ('14', 'orders'), ('14', 'million'), ('14', 'percent'), ('14', 'feet'), ('14', 'times')]\n"
     ]
    }
   ],
   "source": [
    "## Here's the filter operation:\n",
    "the_number = lambda *w: '14' not in w\n",
    "# only bigrams that appear 3+ times\n",
    "finder.apply_freq_filter(3)\n",
    "# only bigrams that contain the number\n",
    "finder.apply_ngram_filter(the_number)\n",
    "# return the 10 n-grams with the highest PMI\n",
    "print(finder.nbest(bigram_measures.likelihood_ratio, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not return a count. *Oi!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thank', 'you', 'so', 'much', 'chris', 'and', \"it's\", 'truly', 'a', 'great']\n"
     ]
    }
   ],
   "source": [
    "the_one = nltk.Text(re.sub(\"[^a-zA-Z0-9']\",\" \",'\\n'.join(texts)).lower().split())\n",
    "# And here's what an NLTK text object looks like: a list of words, really\n",
    "print(the_one[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 494 matches:\n",
      "oking for a place to eat we were on i 40 we got to exit 238 lebanon tennessee \n",
      "w york city already handled more than 40 percent of the entire city's commerci\n",
      "eading rooms whose evolution in 20 30 40 years we can't predict so that litera\n",
      "nd all the other teams have done this 40 days of purpose based on the book and\n",
      "internet tools and we ended up having 40 chapters starting up thousands of arc\n",
      "cumented the lower ninth for the last 40 years that was their home and these a\n",
      "e time and a long time ago well about 40 years ago my mom had an exchange stud\n",
      " world where women and children spend 40 billion hours a year fetching water t\n",
      "be someone coming to rescue me cut to 40 some odd years later we go to kenya a\n",
      "t age category of 76 to 85 as much as 40 percent of people have nothing really\n",
      " is how do you go to the loo at minus 40 ben i've read somewhere that at minus\n",
      "ben i've read somewhere that at minus 40 exposed skin becomes frostbitten in l\n",
      "ou answer the call of nature at minus 40 the answer of course to which is a tr\n",
      " things tend to happen every 25 years 40 years long with an overlap you can pu\n",
      "e all high rises so they'll put 20 or 40 up at a time and they just go up in t\n",
      "se my prize so i would take 30 000 or 40 000 dollars of the winnings and the r\n",
      "ate we've seen no side effects in the 40 or so patients in whom it's been impl\n",
      "n terms of price performance that's a 40 to 50 percent deflation rate and econ\n",
      "n people may increase their volume 30 40 percent but they won't keep up with i\n",
      "r hunters could smell animal urine at 40 paces and tell you what species left \n",
      " percent of all the pregnancies about 40 percent of all the people i said 400 \n",
      "all the people i said 400 000 i meant 40 000 about 40 percent of all the peopl\n",
      "e i said 400 000 i meant 40 000 about 40 percent of all the people who need tb\n",
      "att hours per kilogram nickel cadmium 40 watt hours per kilogram in nickel met\n",
      "lture what we find is that over these 40 odd years that i and others have been\n"
     ]
    }
   ],
   "source": [
    "the_one.concordance(\"40\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, there's the missing `000`! It's in the idiomatic transcription practices of TED wherein a number like \"sixty thousand\" is rendered as \"60,000.\" \n",
    "\n",
    "One thing we know now: reporting large numbers is a part of TED talks.\n",
    "\n",
    "**TO DO**: How to keep the comma marker between numbers? (Or should we just look to 000 as a possible collocate with the other numbers?) One solution from the [Regex Cookbook][]:\n",
    "\n",
    "```python\n",
    "\\b[0-9]{1,3}(,[0-9]{3})*(\\.[0-9]+)?\\b|\\.[0-9]+\\b\n",
    "```\n",
    "\n",
    "[Regex Cookbook]: https://www.oreilly.com/library/view/regular-expressions-cookbook/9781449327453/ch06s11.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": 2,
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
