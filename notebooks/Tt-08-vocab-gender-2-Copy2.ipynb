{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "607\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "# Let python create the column names list:\n",
    "with open('../data/talks_6d.csv') as f:\n",
    "    colnames = f.readline().strip().split(\",\")\n",
    "\n",
    "TEDtalks = pandas.read_csv('../data/talks_6d.csv', names=colnames)\n",
    "\n",
    "ftexts = TEDtalks[TEDtalks.gender == 'female'].text.tolist()\n",
    "print(len(ftexts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "my_tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize\n",
    "vectorizer = CountVectorizer(tokenizer = my_tokenizer)\n",
    "   \n",
    "X = vectorizer.fit_transform(ftexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(607, 30852)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq = np.ravel(X.sum(axis=0)) # sum each columns to get total counts for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this freq will correspond to value in dictionary vectorizer.vocabulary_\n",
    "\n",
    "import operator\n",
    "# get vocabulary keys, sorted by value\n",
    "vocab = [v[0] for v in sorted(vectorizer.vocabulary_.items(), key=operator.itemgetter(1))]\n",
    "fdist = dict(zip(vocab, freq)) # return same format as nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relafreq (list_of_texts):\n",
    "    '''Determines relative frequencies of words by first getting frequncies.'''\n",
    "    # Take the list and turn it into one long string\n",
    "    all_texts = \" \".join(list_of_texts).lower()\n",
    "    # Invoke the NLTK god\n",
    "    freqdist = nltk.FreqDist()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = tokenizer.tokenize(all_texts)\n",
    "    for word in words:\n",
    "        freqdist.update([word])\n",
    "    # Get the total number of words so we can establish relative frequencies\n",
    "    total_words = sum(freqdist.values())\n",
    "    # Convert the FreqDist container to a dictionary\n",
    "    freqdist_dict = dict(freqdist)\n",
    "    # Create a new dictionary of relative frequencies\n",
    "    relative_frequency = {k: v/total_words for k, v in freqdist_dict.items()}\n",
    "    # Convert the dictionary to a rankable list of tuples\n",
    "    # & rank it with the most frequent word first\n",
    "    ranked = sorted(relative_frequency.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    # return the ranked list of tuples\n",
    "    return(ranked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Talks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we don't need all talks, because that will include talks besides individual men and women speakers -- and the total number of those talks is small enough that they can be examined by hand at some other time. What we need are all the talks by women and all the talks by women, which, I think, will also make it easier to construct the dataframe described at the top of this notebook.\n",
    "\n",
    "Here is what I deleted:\n",
    "\n",
    "```python\n",
    "all_talks = relafreq(texts)\n",
    "all_talks[0:10]\n",
    "\n",
    "print(len(all_talks))\n",
    ">>> 53705\n",
    "```\n",
    "\n",
    "I also want to keep track of how to filter by string search:\n",
    "\n",
    "```python\n",
    "TEDtalks[TEDtalks['text'].str.contains(\"PMS\")]\n",
    "```\n",
    "\n",
    "This will show a filtered version of the dataframe. To get just the two texts involved, I used the following code:\n",
    "\n",
    "```python\n",
    "pms_talks = TEDtalks[TEDtalks['text'].str.contains(\"PMS\")].text.tolist()\n",
    "print(len(pms_talks))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gendered Talks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create two additional collections filtered by the `gender` column of the dataframe. What happens in the first line below is that we filter the dataframe, in the line that follows we pull the text column out. Originally, I had this as one line:\n",
    "\n",
    "    f_talks = TEDtalks[TEDtalks.gender == 'female'].text.tolist()\n",
    "\n",
    "But that produced a string and not a list object. I don't know why the one line would not work.\n",
    "\n",
    "**2018-03-22**: Now it's working. Did I have `texts.tolist()` -- I'm not clear what happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter by gender\n",
    "\n",
    "m_talks = TEDtalks[TEDtalks.gender == 'male'].text.tolist()\n",
    "f_talks = TEDtalks[TEDtalks.gender == 'female'].text.tolist()\n",
    "\n",
    "# A quick check of numbers:\n",
    "\n",
    "print(\"Of the {} TED talks given, {} were given by women and {} by men.\".format\n",
    "      (len(texts), len(f_talks), len(m_talks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1437 / 607"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: One thing to do here is to compare the talks to see which words are used **only** by women or **only** by men."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_relative = relafreq(f_talks)\n",
    "m_relative = relafreq(m_talks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just a way to check against rank\n",
    "import random\n",
    "random_num = random.randint(1,500)\n",
    "print(random_num, f_relative[random_num], m_relative[random_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing M/F Word Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to start by converting the list of tuples to a dictionary both because I think matching keys is going to be easier (at least based on my limited coding ability) and because, according to what I read, it appears to be faster. Since we don't really need a ranked listing for this work, it would probably be wise to rewrite the `RelaFreq` function so that it produces a dictionary. No reason to go back and forth like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_rf = dict(f_relative)\n",
    "\n",
    "m_rf = dict(m_relative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes on how to compare -- as I write this I am trying to find a way to limit my for loop through the two dictionaries only to N results just so I can see if it's working. \n",
    "\n",
    "[Python - Return first N key:value pairs from dict](https://stackoverflow.com/questions/7971618/python-return-first-n-keyvalue-pairs-from-dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a way to match words in the f/m dictionaries\n",
    "\n",
    "for key in f_rf:\n",
    "    if key in m_rf:\n",
    "        print(key, f_rf[key], m_rf[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I decided to do was run the cell and then stop it. The results from above look like this:\n",
    "\n",
    "    hour 8.613999628814925e-05 0.00012193460211598934\n",
    "    debased 7.830908753468114e-07 2.924091177841471e-07\n",
    "    deteriorate 3.1323635013872456e-06 1.7544547067048825e-06\n",
    "    perimeter 1.5661817506936228e-06 3.508909413409765e-06\n",
    "\n",
    "What we need now is to compare one list against the other for differences in usage. I am starting with twice as often to see what that turns up. >>> I need to re-read the literature here to see what comparison thresholds have been used. \n",
    "\n",
    "**2018-03-26**: I decided that the easiest way to approach this is to create a dictionary comprehension that divides the female relative frequency by the male. We can then look at numbers >1 for the words preferred by women and numbers < 1 for words preferred by men."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are just going to do math:\n",
    "\n",
    "weighted = {f_rf[key]/m_rf[key] for key in f_rf}\n",
    "\n",
    "for key in f_rf:\n",
    "    \n",
    "if f_rf[key] > m_rf[key]:\n",
    "    print(key, f_rf[key], m_rf[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dataframe from a list of dictionaries\n",
    "comp = pandas.DataFrame([f_rf, m_rf]).T\n",
    "\n",
    "# Rename the columns to something human readable\n",
    "comp.columns = ['women', 'men']\n",
    "\n",
    "# Check our results\n",
    "comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I'm doing the vision manually below instead of using the built-in functionality: \n",
    "# DataFrame.divide(other, axis='columns', level=None, fill_value=None)\n",
    "ratios = comp.assign(ratio = comp.women / comp.men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratios.index.rename('word', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ratios.plot.scatter(x='word', y='ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "occurs = ratios.assign(woccurs = comp.women * 4493178, moccurs = comp.men*4493178)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And now to sort:\n",
    "\n",
    "occurs.sort_values(by='ratio', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
