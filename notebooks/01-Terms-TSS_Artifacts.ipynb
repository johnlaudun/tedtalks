{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TED Talk Transcription Artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we explore the various features of the TED talks documents that are a product of their being transcripts of oral performances. The transcription process itself is not entirely clear, since it is the product of volunteers. In practice, this means different volunteers, or groups of volunteers, transcribe the same or similar performance features differently. The goal of this notebook is to survey possible feature artifaces and to determine what, if any, of these artifacts need to be addressed when it comes to processing the documents for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load our functions and then our documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import re \n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import tokenize, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From our 992 x 14 CSV, we have a list of 992 talks.\n"
     ]
    }
   ],
   "source": [
    "# Loading the data in a gendered partitioned fashion: \n",
    "df_male = pd.read_csv('talks_male.csv', index_col='Talk_ID')\n",
    "df_female = pd.read_csv('talks_female.csv', index_col='Talk_ID')\n",
    "df_nog = pd.read_csv('talks_nog.csv', index_col='Talk_ID')\n",
    "\n",
    "df_all = pd.concat([df_male, df_female, df_nog])\n",
    "\n",
    "texts = df_all.text.tolist()\n",
    "\n",
    "print(f\"From our {df_all.shape[0]} x {df_all.shape[1]} CSV, \\\n",
    "we have a list of {len(texts)} talks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drawing upon some of the early work in the *Terms* notebook, we run Sci-Kit Learn's `CountVectorizer` with only one parameter: for a word to be counted, it must occur in at least two documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(992, 22433)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default vectorizer = lowercase, remove punctuation, \n",
    "# tokens > 2 char, split contractions, no stopwords\n",
    "vectorizer = CountVectorizer(min_df = 2)\n",
    "X = vectorizer.fit_transform(texts)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the words in an array, we can inspect various segments of the word count. Inside this notebook, we use the `head()` method which with 20 entries, begins to suggest that there a lot of numbers to be taken into consideration. For a fuller examination, we also save the complete count to a CSV. (Here commented out so that it doesn't run every time the notebook runs.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "00          4\n",
       "000      1187\n",
       "000th       6\n",
       "01          3\n",
       "02          2\n",
       "06          5\n",
       "07          2\n",
       "10        981\n",
       "100       545\n",
       "1000        5\n",
       "100th       5\n",
       "101        13\n",
       "102         3\n",
       "103         3\n",
       "105        10\n",
       "109         3\n",
       "10th       20\n",
       "11        223\n",
       "110        10\n",
       "111         3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_words = pd.DataFrame(X.toarray(), \n",
    "                      columns = vectorizer.get_feature_names_out())\n",
    "\n",
    "wc_all = df_all_words.sum()\n",
    "wc_all.head(20)\n",
    "# wc_all.to_csv('../output/gender-part-word_counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having done that, and scrolling down to the 800th row before beginning to see letters forming something like words, we note that there are a lot of ways to spell out*ah*, which led us to ask our first question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pause Fillers and Interjections: Variations on \"ah\"\n",
    "\n",
    "The words from a search for \"ah\" were: \n",
    "\n",
    "    aaaah, aah, ah, ahh, ahhh\n",
    "    \n",
    "The words from a search for \"aa\" were: \n",
    "\n",
    "    aa, aaa, aaaa, aaaaa, aaaah, aah\n",
    "    \n",
    "Code used:\n",
    "\n",
    "```python\n",
    "for match in wc_all.index:\n",
    "    if \"aa\" in match:\n",
    "        print(match)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aa        11\n",
       "aaa        6\n",
       "aah       10\n",
       "aaaah      2\n",
       "aah       10\n",
       "ah       116\n",
       "ahh        6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ahs_list = [\"aa\", \"aaa\", \"aaaa\", \"aaaaa\", \"aah\", \n",
    "            \"aaaah\", \"aah\", \"ah\", \"ahh\", \"ahhh\" ] \n",
    "\n",
    "ahs = wc_all.filter(items = ahs_list, axis=0)\n",
    "ahs.head(len(ahs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  thank you so much, chris. and it's truly a great honor to have the opportunity to come to this sta\n"
     ]
    }
   ],
   "source": [
    "alltexts = ' '.join(texts).lower()\n",
    "t = tokenize.WhitespaceTokenizer()\n",
    "corpse = text.Text(t.tokenize(alltexts))\n",
    "print(alltexts[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no matches\n"
     ]
    }
   ],
   "source": [
    "corpse.concordance(\"ahh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "There appears to be a tokenizer mis-match between SciKit-Learn, from which the list of <b>ah</b>s above is drawn and the NLTK tokenizer which is not finding the same tokens. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Count - Sorted\n",
    "\n",
    "While we have a series with a word count, it's easy enough to sort the list to get a quick overview of the total count for the words in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the     93853\n",
       "and     67710\n",
       "to      57089\n",
       "of      52313\n",
       "that    44087\n",
       "it      35339\n",
       "in      34728\n",
       "you     34162\n",
       "we      30407\n",
       "is      28569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_sorted = wc_all.sort_values(ascending=False, inplace=False)\n",
    "wc_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Performatives and Other Parenthetical Expressions <a class=\"anchor\" id=\"performatives\"></a>\n",
    "\n",
    "Earlier explorations of the corpus revealed something we knew but had not realized could affect our work: some TED talks are not talks but musical performances. Generally, the text of such performances are rather short. Using an arbitrary length of `500` characters, we can see what these texts look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 183, 297, 388, 602, 983, 991]\n"
     ]
    }
   ],
   "source": [
    "shorts = [ texts.index(text) for text in texts if len(text) < 500 ]\n",
    "print(shorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84:\n",
      "  (Applause)    (Music)    (Applause)  \n",
      "\n",
      "183:\n",
      "  Let's just get started here.    Okay, just a moment.    (Whirring)    All right. (Laughter) Oh, sorry.    (Music) (Beatboxing)    Thank you.    (Applause)  \n"
     ]
    }
   ],
   "source": [
    "print(f\"{shorts[0]}:\\n{texts[shorts[0]]}\\n\\n{shorts[1]}:\\n{texts[shorts[1]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the two examples above reveal, some talks are not talks at all and do not actually contain any text, except for the performatives, while other talks contain non-textual materials, some of which is part of the performance and some of which is the audience's response to the performance. \n",
    "\n",
    "When it comes time to process words in a text, we think the best bet is to remove the performatives. We do think, however, that having them means we can possibly explore sentiment using `(Applause)` and `(Laughter)` as contextual valuations.\n",
    "\n",
    "For now, we will need some regex to remove the parentheses and their contents from our texts. An examination of `113` above reveals that it is only three parenthetical expressions:\n",
    "\n",
    "    (Applause)    (Music)    (Applause)\n",
    "\n",
    "We need a sample text that is a mix, and so we will use `183` from above:\n",
    "\n",
    "> Let's just get started here.    Okay, just a moment.    (Whirring)    All right. (Laughter) Oh, sorry.    (Music) (Beatboxing)    Thank you.    (Applause)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "A quick check using two regexes give us one list without the parentheses and one with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Whirring', 'Laughter', 'Music', 'Beatboxing', 'Applause']\n",
      "['(Whirring)', '(Laughter)', '(Music)', '(Beatboxing)', '(Applause)']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(r'(?<=\\().*?(?=\\))', texts[183]))\n",
    "print(re.findall(r'\\([^)]*\\)', texts[183]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `CountVectorizer` to inventory all the parenthetical expressions in the corpus to see if we are missing anything. \n",
    "\n",
    "First, we test is on a known text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mz/k5p3f5wj0czgd_5m4dw59py00000gn/T/ipykernel_52100/764417802.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX183\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m183\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m184\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf183\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX183\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m183\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m184\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(token_pattern = r'(?<=\\().*?(?=\\))')\n",
    "X183 = vec.fit_transform(texts[183:184])\n",
    "df183 = pd.DataFrame(X183.toarray(), columns=vec.get_feature_names_out())\n",
    "df.index = [ texts.index(text) for text in texts[183:184] ]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parentheticals = vec.fit_transform(texts)\n",
    "parentheticals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parens = pd.DataFrame(parentheticals.toarray(), \n",
    "                         columns=vec.get_feature_names_out())\n",
    "df_parens.index = [ texts.index(text) for text in texts ]\n",
    "df_parens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the parenthetical expressions captured, we can determine the most frequent, take a look at their numbers, and then decide what's the best path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = df_parens.sum(axis = 0)\n",
    "sums.sort_values(ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results, the top 20 parentheticals could be inserted into a stopword list and we would remove, in the case of the top 4 especially, words or clauses that might affect results.\n",
    "\n",
    "The code below can be included in `CountVectorizer` as a preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Refined Preprocessor --\n",
    "# This one removes two-word phrases/clauses\n",
    "\n",
    "parentheticals = [ \"\\(laughter\\)\", \"\\(applause\\)\", \"\\(music\\)\",  \n",
    "                  \"\\(video\\)\", \"\\(laughs\\)\", \"\\(applause ends\\)\", \n",
    "                  \"\\(audio\\)\", \"\\(singing\\)\", \"\\(music ends\\)\", \n",
    "                  \"\\(cheers\\)\", \"\\(cheering\\)\", \"\\(recording\\)\", \n",
    "                  \"\\(beatboxing\\)\", \"\\(audience\\)\", \"\\(guitar strum\\)\", \n",
    "                  \"\\(clicks metronome\\)\", \"\\(sighs\\)\", \"\\(guitar\\)\", \n",
    "                  \"\\(marimba sounds\\)\", \"\\(drum sounds\\)\" ]\n",
    "\n",
    "def remove_parentheticals(text):\n",
    "    global parentheticals\n",
    "    new_text = text\n",
    "    for rgx_match in parentheticals:\n",
    "        new_text = re.sub(rgx_match, ' ', new_text.lower(), \n",
    "                          flags=re.IGNORECASE)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick test of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"\"\"Laughter is the best medicine. (Laughter) \n",
    "Hold your applause; I'm not done yet. (Applause ends)\"\"\"\n",
    "\n",
    "print(remove_parentheticals(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_vec = CountVectorizer( preprocessor = remove_parentheticals,\n",
    "                          max_df = 0.9, min_df = 2 )\n",
    "the_X = the_vec.fit_transform(texts)\n",
    "the_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numbers\n",
    "\n",
    "One of the dimensions of the corpus that arises out of a hand inspection of the terms is the frequency with which some numbers appear. The follow table captures the top ten numbers:\n",
    "\n",
    "| TERM | FREQUENCY |\n",
    "|------|-----------|\n",
    "| 000  | 2098 |\n",
    "| 10   | 1691 |\n",
    "|  20  | 1107 |\n",
    "| 100  |  902 |\n",
    "|  30  |  827 |\n",
    "|  50  |  784 |\n",
    "|  15  |  659 | \n",
    "|  40  |  494 |\n",
    "|  12  |  460 | \n",
    "|  25  |  410 |\n",
    "\n",
    "Other frequently occurring numbers: 60, 500, 200, 11, 18, 80, 14 (241 times!). \n",
    "\n",
    "In order to examine the appearance of the numbers in context, we make a giant string out of the list of strings, `texts`: in which text a number appears is less important than its immediate context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onetext = nltk.Text('\\n'.join(texts).split())\n",
    "# And here's what an NLTK text object looks like: a list of words, really\n",
    "print(onetext[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onetext.concordance(\"000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onetext.concordance(\"10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onetext.concordance(\"40\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of things to note here:\n",
    "\n",
    "First, there is a discrepancy in the count between `sklearn` and the NLTK: the former counted 2098 occurrences of `000`, the latter none. In all the counts that follow, there is a similar mismatch:\n",
    "\n",
    "| TERM | `sklearn` | `nltk` |\n",
    "|------|-----------|--------|\n",
    "| 000  | 2098 | \"no match\" |\n",
    "|  10  | 1691 | 1216 |\n",
    "|  20  | 1107 | 879 |\n",
    "| 100  |  902 | 647 |\n",
    "|  30  |  827 | 650 |\n",
    "|  50  |  784 | 594 | \n",
    "|  15  |  659 | 512 | \n",
    "|  40  |  494 | 387 | \n",
    "| ...               | \n",
    "|  14  |  241 | 148 | \n",
    "\n",
    "I don't have a ready explanation for this.\n",
    "\n",
    "Second, the frequency of some numbers are readily explained:\n",
    "\n",
    "* Round numbers like 10, 20, 30, 50, and 100 are approximations -- though it would be interesting to explore how often they are attached to large scalars like \"thousand\" or million.\" \n",
    "* Some numbers seem to represent alternate ways of counting: 25 reagularly stands in for \"one-quarter\" -- though not as often as we might imagine -- and 18 is regularly paired with *month* as a more precise way to say \" a year and a half.\"\n",
    "* There are some numbers, like 11 and 14 which seem to have power all their own, perhaps tied to particular ages in humans. \n",
    "\n",
    "Next up is some code to explore the most common occurring words with these numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All my searches for \"collocations with specific words\" took me to the NLTK, which means, so far as I can tell, generating all the bigrams and then filtering to get the one(s) you want. This seems backwards to me: wouldn't it be faster simply to find the word and then what comes after it? I'll take a look at regex for this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bigrams\n",
    "finder = BigramCollocationFinder.from_words(onetext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here's the filter operation:\n",
    "the_number = lambda *w: '14' not in w\n",
    "# only bigrams that appear 3+ times\n",
    "finder.apply_freq_filter(3)\n",
    "# only bigrams that contain the number\n",
    "finder.apply_ngram_filter(the_number)\n",
    "# return the 10 n-grams with the highest PMI\n",
    "print(finder.nbest(bigram_measures.likelihood_ratio, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not return a count. *Oi!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_one = nltk.Text(re.sub(\"[^a-zA-Z0-9']\",\" \",'\\n'.join(texts)).lower().split())\n",
    "# And here's what an NLTK text object looks like: a list of words, really\n",
    "print(the_one[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_one.concordance(\"40\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, there's the missing `000`! It's in the idiomatic transcription practices of TED wherein a number like \"sixty thousand\" is rendered as \"60,000.\" \n",
    "\n",
    "One thing we know now: reporting large numbers is a part of TED talks.\n",
    "\n",
    "**TO DO**: How to keep the comma marker between numbers? (Or should we just look to 000 as a possible collocate with the other numbers?) One solution from the [Regex Cookbook][]:\n",
    "\n",
    "```python\n",
    "\\b[0-9]{1,3}(,[0-9]{3})*(\\.[0-9]+)?\\b|\\.[0-9]+\\b\n",
    "```\n",
    "\n",
    "[Regex Cookbook]: https://www.oreilly.com/library/view/regular-expressions-cookbook/9781449327453/ch06s11.html"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "14a02b88778d8fb8b6aeb4ad427a942bc53dfcda9d7e3737237788289e0d2d23"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": 2,
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
