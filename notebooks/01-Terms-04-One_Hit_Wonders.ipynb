{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hit Wonders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "After loading the data, we use the modified vectorizing protocol -- though it's not entirely necessary -- to create our term matrix which only allows for words that appear in one document. \n",
    "\n",
    "After converting the matrix into a dataframe, we sum the dataframe into a series, and then filter the series for those words that appear more than once in a document and then explore the context in which those terms appear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd, re, nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "df = pd.read_csv('../output/TEDall_speakers.csv')\n",
    "df.shape\n",
    "\n",
    "urls  = df.public_url.tolist()\n",
    "texts = df.text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parentheticals = [ \"\\(laughter\\)\", \"\\(applause\\)\", \"\\(music\\)\", \"\\(video\\)\", \n",
    "                  \"\\(laughs\\)\", \"\\(applause ends\\)\", \"\\(audio\\)\", \"\\(singing\\)\", \n",
    "                  \"\\(music ends\\)\", \"\\(cheers\\)\", \"\\(cheering\\)\", \"\\(recording\\)\", \n",
    "                  \"\\(beatboxing\\)\", \"\\(audience\\)\", \"\\(guitar strum\\)\", \n",
    "                  \"\\(clicks metronome\\)\", \"\\(sighs\\)\", \"\\(guitar\\)\", \"\\(marimba sounds\\)\", \n",
    "                  \"\\(drum sounds\\)\" ]\n",
    "\n",
    "\n",
    "def clean_parens(text):\n",
    "    new_text = text\n",
    "    for rgx_match in parentheticals:\n",
    "        new_text = re.sub(rgx_match, ' ', new_text.lower(), flags=re.IGNORECASE)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Very Peculiar Vector: `max_df = 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1747, 21037)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = CountVectorizer(preprocessor = clean_parens, max_df = 1)\n",
    "X = vec.fit_transform(texts)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = pd.DataFrame(X.toarray(), columns = vec.get_feature_names())\n",
    "\n",
    "# Create a series of just the terms and the number of times they occur in total\n",
    "sums = dfx.sum()\n",
    "\n",
    "# Save to CSV\n",
    "#sums.to_csv('../output/one_doc_wonders.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sums` is a pandas series. You can think of series as a one-column dataframe such that you have an index, here `sums.index` and a column with contents, here `sums.values`. You can sort by either:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bf           75\n",
       "gk           46\n",
       "telomeres    40\n",
       "abed         39\n",
       "mzuri        36\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sums = sums.sort_values(ascending = False)\n",
    "sums.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words That Appear More Than Once But Only in One Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering a series is just like filtering a dateframe, and here we create a new series with that data and save it to a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3895"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeated = sums [ sums > 1]\n",
    "len(repeated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write repeated to CSV:\n",
    "# repeated.to_csv('../output/one_doc_repeated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bf           75\n",
       "gk           46\n",
       "telomeres    40\n",
       "abed         39\n",
       "mzuri        36\n",
       "jf           36\n",
       "indus        33\n",
       "fonio        32\n",
       "teszler      30\n",
       "tkm          30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeated.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to take see these terms in context. For now, we will convert the list of texts into a single NLTK text, but after that we will want to see in which texts these words occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "onetext = nltk.Text(re.sub(\"[^a-zA-Z0-9']\",\" \",'\\n'.join(texts)).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 30 matches:\n",
      "w Laughter Siphumeze Khundayi Hi guys TKM Hello everyone TKM So you think you k\n",
      "e Khundayi Hi guys TKM Hello everyone TKM So you think you know about sex Chanc\n",
      "e going to keep things safe and spicy TKM So now the act of rubbing our naked b\n",
      "are going to live our best sexy lives TKM And we're going to tell you how to ha\n",
      "out the things that we need to change TKM And the things we need to embrace in \n",
      " From the top of my head rape culture TKM How tradition and culture limit ideas\n",
      "hen he's trying to turn up the volume TKM Like that is a personal pet peeve of \n",
      "ve of mine SK We are so scared of sex TKM And we need somebody to blame for our\n",
      " see how well that goes down Laughter TKM Does not go down well I once challeng\n",
      "at you saw on the internet by mistake TKM Mhm So now in order to cure this ailm\n",
      "ach us to help us upgrade the present TKM So now if I had a glass of Merlot whi\n",
      "t be named SK Whispering Colonization TKM Came through Within African societies\n",
      "es of old were so important for women TKM There were African sexual practices t\n",
      " in particular that's named osunality TKM Also known as the African erotic Yes \n",
      "women and creating pleasure for women TKM Mhm Shout out to the Kama Sutra but b\n",
      "elfconsciously And she goes on to say TKM There you go you got that line this t\n",
      "n about the power of this inner force TKM So within the African continent there\n",
      " are all trying to subvert each other TKM We are pounding the pussy using sex a\n",
      "ays a loser when it comes to this war TKM So now the ability to openly brandish\n",
      "e it begins to get really really good TKM So what does it mean to reconceptuali\n",
      "exual oppression and erotic injustice TKM And sex positivity is one of the real\n",
      "ica SK We do sex and sexuality online TKM We would be foolhardy not to mention \n",
      "lingus SK I like the word cunnilingus TKM I bet you do But that's not the point\n",
      " we don't end up in sticky situations TKM That's true And another space that we\n",
      " does not understand consent Laughter TKM So one fascinating subset of kink is \n"
     ]
    }
   ],
   "source": [
    "onetext.concordance(\"tkm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Observations\n",
    "\n",
    "* Unexplained (artifacts of some kind?): bf, gk, jf, tkm.\n",
    "* Yup, used: telomeres (biological), Indus, fonio (some kind of grain).\n",
    "* Name: Abed, Teszler.\n",
    "* Song lyric: **mzuri** (in a transliterated language)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": 2,
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
