{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subjective Verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook we looked at large-scale trends in the use of subjects and verbs in the two subcorpora. In this notebook, we turn to understanding possible relationships between the subjects and the verbs that follow them. That is, what kinds of actions are available to the subjects *she* and *he*. How do those actions compare between male speakers and female speakers. Finally, is there a continuity between the actions projected onto a gendered subject and the speaking subject (her or himself) as reflected in the verbs paired with *I*?\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "    <p>A note about the naming of variables below:</p>\n",
    "    <ul>\n",
    "        <li><code>m</code> and <code>w</code> represent the subcorpus, men or women speakers</li>\n",
    "        <li><code>pp</code> stands for personal pronouns, usually \"he,\" \"she,\" and \"I\" here.\n",
    "        <li><code>svo</code> signifies that the complete SVO-triplet is used</li>\n",
    "        <li><code>sv</code> signifies that just the subject-verb pairs are being used</li>\n",
    "    </ul>   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we want to explore is both the usual ways that speakers (men or women) pair the pronouns *he*, *she*, *i* with verbs and also, perhaps, the significant pairings.\n",
    "\n",
    "The usual way can be approached via **counts**, which we have visualized in a separate notebook with Sankey plots.\n",
    "\n",
    "Relative frequencies would let us compare across the two subcorpora ... or would this be approached better by some form of TF-IDF? (And would we need to determine some sort of lower threshold of the number of sentences in which a verb must occur? We're not interested in verb only used in a single sentence but verbs used often in a pairing in one subcorpus and not in the other.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO**: Get rid of the square brackets in the object column.\n",
    "\n",
    "Tried:\n",
    "```python\n",
    "w_pp_svo.str.replace('[','').replace(']','')\n",
    "\n",
    "AttributeError: 'DataFrame' object has no attribute 'str'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80460 26610\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# LOAD DATAFRAMES\n",
    "# the `lem` suffix indicates the verbs have been lemmatized\n",
    "svos_m = pd.read_csv(\"../output/svos_m_lem.csv\", index_col=0)\n",
    "svos_w = pd.read_csv(\"../output/svos_w_lem.csv\", index_col=0)\n",
    "\n",
    "# Save the SVO count for each corpus for calculating relative frequencies\n",
    "m_svo_count = svos_m.shape[0]\n",
    "w_svo_count = svos_w.shape[0]\n",
    "\n",
    "# Output something to check our efforts\n",
    "print(m_svo_count, w_svo_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the total number of SVOs established, we can use subsets in pandas to isolate the number of unique subject-verb pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19993,)\n",
      "subject  verb\n",
      "we       have    2259\n",
      "you      have    1505\n",
      "i        have    1318\n",
      "         want    1210\n",
      "         go      1076\n",
      "you      see      997\n",
      "we       do       972\n",
      "you      get      901\n",
      "we       go       743\n",
      "         need     717\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "m_svpairs = svos_m.value_counts(subset=['subject', 'verb'])\n",
    "print(m_svpairs.shape)\n",
    "print(m_svpairs.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8809,)\n",
      "subject  verb\n",
      "we       have    674\n",
      "i        have    586\n",
      "         want    424\n",
      "you      have    406\n",
      "i        go      330\n",
      "we       need    255\n",
      "you      see     255\n",
      "we       do      246\n",
      "they     have    231\n",
      "i        do      226\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "w_svpairs = svos_w.value_counts(subset=['subject', 'verb'])\n",
    "print(w_svpairs.shape)\n",
    "print(w_svpairs.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save results\n",
    "# m_svpairs.to_csv(\"../output/m_svpairs.csv\")\n",
    "# w_svpairs.to_csv(\"../output/w_svpairs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "    <p>All three parts of the SVO can be subsetted:</p>\n",
    "    <pre>m_svos = svos_m.value_counts(subset=['subject', 'verb', 'object'])\n",
    "    \n",
    " subject  verb  object\n",
    " we       do    [what]    206\n",
    "                [that]    162\n",
    " i        tell  [you]     159\n",
    " you      do    [what]    151\n",
    "          see   [what]    130</pre>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVOs with 3 Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18836, 3)\n",
      "   subject   verb                                             object\n",
      "0        i   blow                                       [conference]\n",
      "1        i   want  [to, thank, all, of, you, for, the, many, nice...\n",
      "2        i   need                                             [that]\n",
      "4        i    fly                                              [two]\n",
      "5        i   have  [to, take, off, my, shoes, or, boots, to, get,...\n",
      "6        i   tell                                            [story]\n",
      "7        i  leave                                [the, white, house]\n",
      "8        i   look                                               [me]\n",
      "18     she   take                                            [order]\n",
      "19     she     go                                     [order, voice]\n"
     ]
    }
   ],
   "source": [
    "# Filter\n",
    "m_pp_svo = svos_m.loc[(\n",
    "    svos_m['subject'] == 'he') | (\n",
    "    svos_m['subject'] == 'she') | (\n",
    "    svos_m[\"subject\"] == \"i\")\n",
    "]\n",
    "print(m_pp_svo.shape)\n",
    "print(m_pp_svo.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7585, 3)\n",
      "   subject     verb                                             object\n",
      "1      she     turn  [to, be, a, much, bigger, dog, than, i, 'd, an...\n",
      "5        i  contact                                [parks, department]\n",
      "6        i  mention                                             [that]\n",
      "7      she     pull                                               [me]\n",
      "8      she       be  [dragging, me, ,, and, lo, and, behold, ,, at,...\n",
      "9        i  mention                                             [that]\n",
      "10     she     keep  [dragging, me, ,, and, lo, and, behold, ,, at,...\n",
      "18       i       go  [to, exchange, marriage, vows, with, my, beloved]\n",
      "20      he       do                                      [which, time]\n",
      "26       i       do                                            [which]\n"
     ]
    }
   ],
   "source": [
    "# And now the women subcorpus\n",
    "w_pp_svo = svos_w.loc[(\n",
    "    svos_w['subject'] == 'he') | (\n",
    "    svos_w['subject'] == 'she') | (\n",
    "    svos_w[\"subject\"] == \"i\")\n",
    "]\n",
    "print(w_pp_svo.shape)\n",
    "print(w_pp_svo.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SV Pairs with 3 Pronouns\n",
    "\n",
    "A survey of the SVOs above reveals that there are verbs that frequently appear, those that regularly appear, and those that rarely appear with the three pronouns in which we are interested. We use `value_counts()` combined with `isin()` to get a summary of the three pronouns and verbs.\n",
    "\n",
    "The results reveal that the 18836 SVOs in the mens subcorpus use only 1723 verbs and the 7585 SVOs in the womens subcorpus use 1069 verbs. Disregarding for the moment how many verbs may only have been used once, it would appear that there is greater variety in women's discourse, but that could also represent the power law dynamic: that as the number of utterances increases, the total vocabulary growth flattens greatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1723, 4)\n",
      "  subject   verb  v_freq   v_rfreq\n",
      "0       i   have    1318  0.016381\n",
      "1       i   want    1210  0.015039\n",
      "2       i     go    1076  0.013373\n",
      "3       i     do     650  0.008079\n",
      "4       i    get     586  0.007283\n",
      "5       i   like     462  0.005742\n",
      "6       i  start     377  0.004686\n",
      "7       i   tell     326  0.004052\n",
      "8       i  think     316  0.003927\n",
      "9       i    try     302  0.003753\n"
     ]
    }
   ],
   "source": [
    "# Create a list of the pronouns we want to see\n",
    "pronouns = [\"he\", \"she\", \"i\"]\n",
    "\n",
    "# And then count the number of times \n",
    "# those pronouns are paired with particular verbs\n",
    "m_pp_sv = svos_m[svos_m[\"subject\"].isin(\n",
    "    pronouns)].value_counts(\n",
    "    subset=['subject', 'verb']).reset_index()\n",
    "\n",
    "# Re-label the new column from \"0\" to something human-readable\n",
    "m_pp_sv.rename(columns={0:'v_freq'}, inplace=True)\n",
    "\n",
    "# Add a column with relative frequency\n",
    "m_pp_sv['v_rfreq'] = m_pp_sv['v_freq'] / m_svo_count\n",
    "\n",
    "print(m_pp_sv.shape)\n",
    "print(m_pp_sv.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1069, 4)\n",
      "  subject   verb  v_freq   v_rfreq\n",
      "0       i   have     586  0.022022\n",
      "1       i   want     424  0.015934\n",
      "2       i     go     330  0.012401\n",
      "3       i     do     226  0.008493\n",
      "4       i    get     203  0.007629\n",
      "5       i   tell     169  0.006351\n",
      "6       i   like     160  0.006013\n",
      "7       i   know     154  0.005787\n",
      "8       i  start     145  0.005449\n",
      "9       i   love     137  0.005148\n"
     ]
    }
   ],
   "source": [
    "# Repeat for women's subcorpus\n",
    "w_pp_sv = svos_w[svos_w[\"subject\"].isin(\n",
    "    pronouns)].value_counts(\n",
    "    subset=['subject', 'verb']).reset_index()\n",
    "\n",
    "w_pp_sv.rename(columns={0:'v_freq'}, inplace=True)\n",
    "w_pp_sv['v_rfreq'] = w_pp_sv['v_freq'] / w_svo_count\n",
    "\n",
    "print(w_pp_sv.shape)\n",
    "print(w_pp_sv.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_pp_sv.to_csv(\"../output/m_pp_sv.csv\")\n",
    "# w_pp_sv.to_csv(\"../output/w_pp_sv.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subjects as Verb Features\n",
    "\n",
    "In the cells below, we create 6 distinct dataframes, each containing one of the gendered pronouns, *he* or *she*, or the first person (indexical-referential) pronoun *I*. \n",
    "\n",
    "We then have a function that transposes each \"subjective\" dataframe into a single row with the verbs associated with as columns and their relative frequencies as values.\n",
    "\n",
    "We then stack those rows using pandas concatenate to get a dataframe with all 6 subject positions and 1381 verbs associated with them.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "    <p>There is a lot of repetition here. No doubt there are not only better ways to do this in terms of individual lines of code but also without as many lines of repetitious code as there are here.</p>\n",
    "    </div>\n",
    "    \n",
    "**NOTE**: Possible threshold 0.002 (0.2%) frequency represents at least 38 occurrences in the men's subcorpus and 15 in the women's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " w_i looks like:\n",
      "    verb  v_freq   v_rfreq\n",
      "0   have     586  0.022022\n",
      "1   want     424  0.015934\n",
      "2     go     330  0.012401\n",
      "3     do     226  0.008493\n",
      "4    get     203  0.007629\n",
      "5   tell     169  0.006351\n",
      "6   like     160  0.006013\n",
      "7   know     154  0.005787\n",
      "8  start     145  0.005449\n",
      "9   love     137  0.005148\n"
     ]
    }
   ],
   "source": [
    "# Get the number of times pronoun appears in SVO:\n",
    "\n",
    "# Filter for pronoun and drop the un-needed columns\n",
    "m_he = m_pp_sv.loc[(m_pp_sv['subject'] == 'he')].drop(columns=[\"subject\"])\n",
    "w_he = w_pp_sv.loc[(w_pp_sv['subject'] == 'he')].drop(columns=[\"subject\"])\n",
    "\n",
    "# Repeat for \"she\"\n",
    "m_she = m_pp_sv.loc[(m_pp_sv['subject'] == 'she')].drop(columns=[\"subject\"])\n",
    "w_she = w_pp_sv.loc[(w_pp_sv['subject'] == 'she')].drop(columns=[\"subject\"])\n",
    "\n",
    "# Repeat for \"i\"\n",
    "m_i = m_pp_sv.loc[(m_pp_sv['subject'] == 'i')].drop(columns=[\"subject\"])\n",
    "w_i = w_pp_sv.loc[(w_pp_sv['subject'] == 'i')].drop(columns=[\"subject\"])\n",
    "\n",
    "print(\"\\n w_i looks like:\")\n",
    "print(w_i.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_he:  2548, w_he:  757\n",
      "m_she: 848, w_she: 643\n",
      "m_i:   15440, w_i:   6185\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "# This is the number of svos per `speaker_pronoun`\n",
    "print(f\"m_he:  {sum(m_he['v_freq'])}, w_he:  {sum(w_he['v_freq'])}\")\n",
    "print(f\"m_she: {sum(m_she['v_freq'])}, w_she: {sum(w_she['v_freq'])}\")\n",
    "print(f\"m_i:   {sum(m_i['v_freq'])}, w_i:   {sum(w_i['v_freq'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_he:  0.03166790952025851, w_he:  0.028447951897782788\n",
      "m_she: 0.010539398458861546, w_she: 0.024163848177376927\n",
      "m_i:   0.19189659458115835, w_i:   0.23243141676061632\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "# This is the proportion of svos per `speaker_pronoun`\n",
    "print(f\"m_he:  {sum(m_he['v_freq'])/m_svo_count}, w_he:  {sum(w_he['v_freq'])/w_svo_count}\")\n",
    "print(f\"m_she: {sum(m_she['v_freq'])/m_svo_count}, w_she: {sum(w_she['v_freq'])/w_svo_count}\")\n",
    "print(f\"m_i:   {sum(m_i['v_freq'])/m_svo_count}, w_i:   {sum(w_i['v_freq'])/w_svo_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_he:  514, w_he:  246\n",
      "m_she: 245, w_she: 221\n",
      "m_i:   964, w_i:   602\n",
      "\n",
      " w_i looks like:\n",
      "    verb   v_rfreq\n",
      "0   have  0.022022\n",
      "1   want  0.015934\n",
      "2     go  0.012401\n",
      "3     do  0.008493\n",
      "4    get  0.007629\n",
      "5   tell  0.006351\n",
      "6   like  0.006013\n",
      "7   know  0.005787\n",
      "8  start  0.005449\n",
      "9   love  0.005148\n"
     ]
    }
   ],
   "source": [
    "# Filter for pronoun and drop the un-needed columns\n",
    "m_he = m_pp_sv.loc[(m_pp_sv['subject'] == 'he')].drop(columns=[\"subject\",\"v_freq\"])\n",
    "w_he = w_pp_sv.loc[(w_pp_sv['subject'] == 'he')].drop(columns=[\"subject\",\"v_freq\"])\n",
    "\n",
    "# Repeat for \"she\"\n",
    "m_she = m_pp_sv.loc[(m_pp_sv['subject'] == 'she')].drop(columns=[\"subject\",\"v_freq\"])\n",
    "w_she = w_pp_sv.loc[(w_pp_sv['subject'] == 'she')].drop(columns=[\"subject\",\"v_freq\"])\n",
    "\n",
    "# Repeat for \"i\"\n",
    "m_i = m_pp_sv.loc[(m_pp_sv['subject'] == 'i')].drop(columns=[\"subject\",\"v_freq\"])\n",
    "w_i = w_pp_sv.loc[(w_pp_sv['subject'] == 'i')].drop(columns=[\"subject\",\"v_freq\"])\n",
    "\n",
    "# Print results\n",
    "# This is the number of unique verbs per `speaker_pronoun`\n",
    "print(f\"m_he:  {m_he.shape[0]}, w_he:  {w_he.shape[0]}\")\n",
    "print(f\"m_she: {m_she.shape[0]}, w_she: {w_she.shape[0]}\")\n",
    "print(f\"m_i:   {m_i.shape[0]}, w_i:   {w_i.shape[0]}\")\n",
    "print(\"\\n w_i looks like:\")\n",
    "print(w_i.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(f\"m_he:  {m_he.shape[0]/m_svo_count}, w_he:  {w_he.shape[0]/w_svo_count}\")\n",
    "print(f\"m_she: {m_she.shape[0]/m_svo_count}, w_she: {w_she.shape[0]/w_svo_count}\")\n",
    "print(f\"m_i:   {m_i.shape[0]/m_svo_count}, w_i:   {w_i.shape[0]/w_svo_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that there are two tranposes in the next series of cells, if this first one doesn't happen then the second one doesn't need to happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makestackable (df, indexname):\n",
    "    df_T = df.transpose()\n",
    "    df_T.columns = df_T.iloc[0]\n",
    "    df_T.drop(index=df_T.index[0], axis=0, inplace=True)\n",
    "    df_T.index = [indexname]\n",
    "    return df_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_it = makestackable(m_i, \"m_i\")\n",
    "w_it = makestackable(w_i, \"w_i\")\n",
    "m_het = makestackable(m_he, \"m_he\")\n",
    "w_het = makestackable(w_he, \"w_he\")\n",
    "m_shet = makestackable(m_she, \"m_she\")\n",
    "w_shet = makestackable(w_she, \"w_she\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not clear what's getting dropped in this concatenation, but we go from 1723 verbs for men and 1069 verbs for women paired with the three pronouns to 1381. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "concatenated = pd.concat([w_it, m_it, m_het, w_het, m_shet, w_shet])\n",
    "concatenated.fillna(0, inplace=True)\n",
    "concatenated.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs = concatenated.transpose()\n",
    "print(verbs.shape)\n",
    "verbs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "verbs[\"he_wm\"] = verbs[\"w_he\"] - verbs[\"m_he\"]\n",
    "verbs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "verbs[\"she_wm\"] = verbs[\"w_she\"] - verbs[\"m_she\"]\n",
    "verbs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs.plot(\n",
    "    x=\"she_wm\",\n",
    "    y=\"he_wm\",\n",
    "    kind='scatter',\n",
    "    title=\"Verb Proportions\",\n",
    "    legend=False,\n",
    "    xlabel=None,\n",
    "    ylabel=None,\n",
    "    c='cornflowerblue',\n",
    "    s=None,\n",
    "    figsize = (15,15)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO**: Do something with this dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Subject Positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"he\"\n",
    "\n",
    "In these first scatter plots for \"he\" verbs in both the men's and women's subcorpora, we see that there are 514 verbs used by men and 246 used by women. Again, we can't be sure if that number reflects anything more than a power law at work, despite the fact that there are twice as many verbs used by men but three times the talk. \n",
    "\n",
    "**TO DO**: Get a total word count for the two subcorpora.\n",
    "\n",
    "With the merge, we are left with 159 verbs in common, which does raise interesting possibilities about the verbs that are dropped from the intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn.objects as so\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(10,10), dpi=300)\n",
    "import matplotlib.lines as mlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe with the intersection of the two sets of verbs\n",
    "comp_he = m_he.merge(\n",
    "    w_he, \n",
    "    left_on = \"verb\", right_on = \"verb\", \n",
    "    suffixes=(\"_m\", \"_w\"))\n",
    "\n",
    "print(comp_he.shape)\n",
    "print(comp_he.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## KK's visualization\n",
    "sns.scatterplot(data = comp_he, x = \"v_rfreq_m\", y = \"v_rfreq_w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# JL's attempts to make things bigger\n",
    "# First plot grabs the top 15 verbs\n",
    "p = so.Plot(comp_he.iloc[0:15],\n",
    "            x='v_rfreq_m',\n",
    "            y='v_rfreq_w',\n",
    "            text='verb').add(so.Dot(marker='+')).add(so.Text(halign='left')).layout(size=(10,10))\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Second figure plots the remaining verbs\n",
    "\n",
    "plt = so.Plot(comp_he.iloc[15:],\n",
    "            x='v_rfreq_m',\n",
    "            y='v_rfreq_w',\n",
    "            text='verb').add(so.Dot(marker='+')).add(so.Text(halign='left')).layout(size=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complements\n",
    "\n",
    "Recall, that in the men's subcorpus \"he\" pairs with 514 verbs, and in the women's subcorpus 246 verbs, but there are only 159 verbs that appear in both. In this next series of cells, we explore the verbs associated with \"he\" that do not appear in both subcorpora. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create dictionaries from the two lists\n",
    "dict1 = dict(m_he.values)\n",
    "dict2 = dict(w_he.values)\n",
    "\n",
    "# Find verbs that only occur\n",
    "m_he_set = set(dict1.keys())-(set(dict2.keys()))\n",
    "\n",
    "# Filter the dataframe\n",
    "m_he_only = m_he[m_he[\"verb\"].isin(m_he_set)]\n",
    "\n",
    "print(m_he_only.shape)\n",
    "print(m_he_only.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find verbs that only occur\n",
    "w_he_set = (set(dict2.keys())) - set(dict1.keys())\n",
    "\n",
    "# Filter the dataframe\n",
    "w_he_only = w_he[w_he[\"verb\"].isin(w_he_set)]\n",
    "\n",
    "print(w_he_only.shape)\n",
    "print(w_he_only.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pointwise Mutual Information with SV Pairs\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "    <p>This may be entirely pointless.</p>\n",
    "    </div>\n",
    "\n",
    "Following Agersnap et al's use of PMI scores for every pronoun verb collocation...\n",
    "\n",
    "NLTK reference: [Sample usage for collocations](https://www.nltk.org/howto/collocations.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Our two dataframes with the relevant SVOs: m_pp_svo, w_pp_svo\n",
    "w_pp_svo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unexplained Experimentation\n",
    "\n",
    "StreamHacker has an interesting post on [chi square](https://streamhacker.com/tag/chi-square/) measures in order to determine the best features for pos / neg movie reviews.\n",
    "\n",
    "> One of the best metrics for information gain is chi square. NLTK includes this in the BigramAssocMeasures class in the metrics package. To use it, first we need to calculate a few frequencies for each word: its overall frequency and its frequency within each class. This is done with a FreqDist for overall frequency of words, and a ConditionalFreqDist where the conditions are the class labels. Once we have those numbers, we can score words with the BigramAssocMeasures.chi_sq function, then sort the words by score and take the top 10000. We then put these words into a set, and use a set membership test in our feature selection function to select only those words that appear in the set. Now each file is classified based on the presence of these high information words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# Define the feature matrix X and the target vector y for the 6 samples\n",
    "y = np.array([0, 1, 0, 1, 0, 1])\n",
    "\n",
    "# Perform feature selection using the f_regression method\n",
    "f_values, p_values = f_regression(concatenated, y)\n",
    "\n",
    "# Print the results\n",
    "for i in range(len(f_values)):\n",
    "    print(\"Feature\", i+1, \"F-value:\", f_values[i], \"p-value:\", p_values[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the feature matrix X and the target vector y for the 6 samples\n",
    "X = concatenated\n",
    "y = np.array([0, 1, 0, 1, 0, 1])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier on the training data\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pronoun-Verb Pair Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pronouns of interest\n",
    "pronouns = [\"he\", \"she\"]\n",
    "\n",
    "# Count the pronoun-verb pairs\n",
    "m_pv = svos_m[svos_m[\"subject\"].isin(\n",
    "    pronouns)].value_counts(\n",
    "    subset=['subject', 'verb']).reset_index()\n",
    "\n",
    "# Re-label the new column from \"0\" to something human-readable\n",
    "m_pv.rename(columns={0:'v_freq'}, inplace=True)\n",
    "\n",
    "m_pv.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "14a02b88778d8fb8b6aeb4ad427a942bc53dfcda9d7e3737237788289e0d2d23"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": 2,
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
