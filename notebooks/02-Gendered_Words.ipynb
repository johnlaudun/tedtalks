{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gendered Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of recent studies have attended to the variety of ways that gender can affect discourse: women speakers have been found to use *hedge* words and phrases, for example. What can TED talks add to these current explorations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd, re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "dfAll = pd.read_csv('../output/TEDall.csv')\n",
    "\n",
    "# Filter the dataframe to just the TED main talks:\n",
    "main = dfAll[dfAll['Set']=='only']\n",
    "# main.shape\n",
    "main['presented'].value_counts().sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dfAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the texts of the talks into one big pseudo-document for each gender\n",
    "all_years = main.groupby(['gender'])['text'].apply(lambda x: ','.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parentheticals = [ \"\\(laughter\\)\", \"\\(applause\\)\", \"\\(music\\)\", \"\\(video\\)\", \n",
    "                  \"\\(laughs\\)\", \"\\(applause ends\\)\", \"\\(audio\\)\", \"\\(singing\\)\", \n",
    "                  \"\\(music ends\\)\", \"\\(cheers\\)\", \"\\(cheering\\)\", \"\\(recording\\)\", \n",
    "                  \"\\(beatboxing\\)\", \"\\(audience\\)\", \"\\(guitar strum\\)\", \n",
    "                  \"\\(clicks metronome\\)\", \"\\(sighs\\)\", \"\\(guitar\\)\", \"\\(marimba sounds\\)\", \n",
    "                  \"\\(drum sounds\\)\" ]\n",
    "len(parentheticals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = dfAll.speaker_1.tolist() + dfAll.speaker_2.tolist() + dfAll.speaker_3.tolist() + dfAll.speaker_4.tolist()\n",
    "print(speakers[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_parens(text):\n",
    "    new_text = text\n",
    "    for rgx_match in parentheticals:\n",
    "        new_text = re.sub(rgx_match, ' ', new_text.lower(), flags=re.IGNORECASE)\n",
    "    return new_text\n",
    "\n",
    "def remove_speaker_names(text):\n",
    "    temp_text = text\n",
    "    for rgx_match in speakers:\n",
    "        temp_text = re.sub(rgx_match, ' ', temp_text)\n",
    "    return temp_text\n",
    "\n",
    "def clean_text(text):\n",
    "    the_text = text\n",
    "    cleaned = remove_parens(remove_speaker_names(the_text))\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our series to a dataframe to make it easier to work in place:\n",
    "dfYears = years.to_frame()\n",
    "\n",
    "# Lowercase our texts\n",
    "dfYears = dfYears.apply(lambda x: x.astype(str).str.lower())\n",
    "\n",
    "# Remove everything that isn't a word, or space\n",
    "dfYears = dfYears.replace('[^\\w\\s\\+]', '', regex = True)\n",
    "\n",
    "# Split on spaces and then count the length of the resulting list\n",
    "dfYears['word_count'] = dfYears.text.apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "# See the results\n",
    "dfYears.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countvectorizer expects a list, so we create a list\n",
    "texts = [ value for index, value in years.iteritems() ]\n",
    "\n",
    "# We are going to bring our years back to the resulting term matrix below, \n",
    "# so while we are creating lists from our series, lets grab those years\n",
    "# (And yes you can create two lists from one list comprehension, but don't.)\n",
    "year_labels = [ index for index, value in years.iteritems() ]\n",
    "\n",
    "# This just checks our results\n",
    "print(len(texts), texts[0][0:50], year_labels[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The usual incantation (minus the desired speaker removal for now):\n",
    "vec = CountVectorizer(preprocessor = remove_parens, min_df = 2)\n",
    "word_count_vector=vec.fit_transform(texts)\n",
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from the resulting array\n",
    "X = vec.fit_transform(texts)\n",
    "term_matrix = pd.DataFrame(X.todense(), columns=vec.get_feature_names())\n",
    "term_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_matrix['year'] = year_labels\n",
    "term_matrix.set_index('year', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_df = term_matrix.transpose()\n",
    "word_df.reset_index(inplace=True)\n",
    "word_df = word_df.rename(columns={'index': 'term'})\n",
    "word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save this dataframe \n",
    "# ==> Commented out so re-running notebook doesn't result in new file\n",
    "# word_df.to_csv('../output/term_year_matrix.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all of the above done, we now have a matrix with every word in a row and every year a column such that we can read a word's usage from left to right moving forward in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "df = pd.read_csv('../output/term_year_matrix.csv') # , index_col = 'term'\n",
    "\n",
    "# The 'Unnamed: 0' column is a vestigial index, let's drop it:\n",
    "# df.drop(columns = ['Unnamed: 0'], inplace=True)\n",
    "# df.set_index('term')\n",
    "\n",
    "# Check shape and list columns:\n",
    "print(df.shape, list(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# One term:\n",
    "df[word_df['term']=='nuclear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Multiple terms:\n",
    "terms = ['nuclear', 'global', 'climate']\n",
    "\n",
    "# And this is the pandas way\n",
    "df[word_df.term.isin(terms)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing by Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next series of cells, we first get the total number of words for each year, and then we get a list of our year columns so that we can then get a sum for each column and divide each term for a given year by the total number of words for that year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# a quick check of the sums involved\n",
    "df.sum(axis = 0, skipna = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of our columns minus the first one which is where our terms are located:\n",
    "years = list(df)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide each cell in a column by the total for each column\n",
    "df[years] = df[years] / df[years].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and here's are three sample terms now with normalized frequency for a year\n",
    "df[word_df.term.isin(terms)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_df.to_csv('../output/term_year_matrix_normalized.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": 2,
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
