{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy / Textacy\n",
    "\n",
    "Textacy is fussy about the size of texts being fed it, responding with `ValueError`s for `nlp.maxlength`. The workaround here is to create a `docs` object which is a list of spaCy `doc`s. The preview below demonstrates that each item in the list has the characteristics of a spaCy doc.\n",
    "\n",
    "Textacy does have a `corpus` object, but it is not straightforward to implement.\n",
    "\n",
    "```python\n",
    "corpus = textacy.Corpus(\"en_core_web_sm\", data=docs)\n",
    "```\n",
    "\n",
    "[spaCy documentation](https://spacy.io/)\n",
    "\n",
    "Spacy has built-in PoS tagging, accessing it looks like this:\n",
    "\n",
    "```python\n",
    "for token in docs[0][0:5]:\n",
    "    print (token, token.tag_, token.pos_) # spacy.explain(token.tag_)\n",
    "```\n",
    "\n",
    "[Textacy documentation]()\n",
    "\n",
    "- We are not excluding parentheticals in this notebook.\n",
    "\n",
    "**Next steps:**\n",
    "\n",
    "- Rewrite code to return appended lists for I, He, She.\n",
    "- Rewrite code to produce a pandas dataframe and then use `groupby`.\n",
    "- Work on adaptation for objective cases. \n",
    "- Work on code to compile / visualize this as a network graph (?). So count up repeated verbs, etc.\n",
    "\n",
    "- *Do we need NLTK code to compare results?*\n",
    "\n",
    "- Possibly create a document per term set and run `CountVectorizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From our 992x14 CSV, we have a list of 992 talks: 260 by women and 720 by men.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import re, spacy, textacy\n",
    "import pandas as pd\n",
    "\n",
    "# Loading the Data in a gendered partitioned fashion: \n",
    "talks_m = pd.read_csv('talks_male.csv', index_col='Talk_ID')\n",
    "talks_f = pd.read_csv('talks_female.csv', index_col='Talk_ID')\n",
    "talks_nog = pd.read_csv('talks_nog.csv', index_col='Talk_ID')\n",
    "talks_all = pd.concat([talks_m, talks_f, talks_nog])\n",
    "\n",
    "# And then grabbing on the texts of the talks:\n",
    "texts_all = talks_all.text.tolist()\n",
    "texts_women = talks_f.text.tolist()\n",
    "texts_men = talks_m.text.tolist()\n",
    "\n",
    "print(f\"From our {talks_all.shape[0]}x{talks_all.shape[1]} CSV, \\\n",
    "we have a list of {len(texts_all)} talks: {len(texts_women)} by women and \\\n",
    "{len(texts_men)} by men.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase everything before we create spaCy doc and Textacy SVO triple\n",
    "# (by lowercasing everything we reduce the number of pronouns by not quite half)\n",
    "\n",
    "texts_w = [text.lower() for text in texts_women]\n",
    "texts_m = [text.lower() for text in texts_men]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Space pipeline to be used\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# Use the pipe method to feed documents \n",
    "docs_w = list(nlp.pipe(texts_w))\n",
    "docs_m = list(nlp.pipe(texts_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Doc(2690 tokens: \"  thank you so much, chris. and it\\'s truly a gr...\")'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_m[0]._.preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working through the Textacy SVO Triple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to test the textacy SVO functionality.\n",
    "# Note we are only extracting triples from the first document:\n",
    "SVOs = list(textacy.extract.triples.subject_verb_object_triples(docs[0]))\n",
    "\n",
    "# How many triples did we get?\n",
    "print(len(SVOs))\n",
    "print(\"---\")\n",
    "\n",
    "# What do they look like?\n",
    "for item in SVOs[0:5]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to see all the nouns used \n",
    "# as subjects in the test document:\n",
    "subjects = [str(item[0]) for item in SVOs]\n",
    "subjects_set = set(subjects)\n",
    "\n",
    "print(f\"There are {len(subjects_set)} unique subjects out of {len(subjects)}.\")\n",
    "print(subjects_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get out just the first person singular triples:\n",
    "for item in SVOs:\n",
    "    if str(item[0]) == '[i]':\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the verb \"contents\" -- the verb phrase -- contains more material than we want. If all we want is the very itself, we will need to target the last item in the verb list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in SVOs:\n",
    "    if str(item[0]) == '[i]':\n",
    "        print(item[1][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gendered SVOs Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the lists of gendered pronouns\n",
    "pronouns = ['i', 'we', 'she', 'he', 'they', 'it', 'you']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our function will remain much the same, though I would like to find a way to get the brackets out of the objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function which will get the SVOs\n",
    "def actions(terms, doc, svo_list):\n",
    "    svotriples = list(textacy.extract.triples.subject_verb_object_triples(doc))\n",
    "    for term in terms:\n",
    "        for item in svotriples:\n",
    "            if str(item[0][-1]) == term:\n",
    "                svo_list.append(\n",
    "                    {\n",
    "                        'subject': str(item[0][-1]), \n",
    "                        'verb': str(item[1][-1]), \n",
    "                        'object': item[2]\n",
    "                    }\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the two lists\n",
    "svos_m, svos_w = []\n",
    "\n",
    "# Populate the lists with SVO triples\n",
    "for doc in docs_m:\n",
    "    actions(pronouns, doc, svos_m)\n",
    "\n",
    "for doc in docs_w:\n",
    "    actions(pronouns, doc, svos_w)\n",
    "\n",
    "# Convert the lists to dataframes\n",
    "df_w = pd.DataFrame(svos_w)\n",
    "df_m = pd.DataFrame(svos_m)\n",
    "\n",
    "print(df_m.shape, df_w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we want to do is simply survey the pronouns: make sure they are present and then to count the number of verbs associated with each one. The total here should match the total length of the dataframe, 18,602. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb_w</th>\n",
       "      <th>percentage_w</th>\n",
       "      <th>verb_m</th>\n",
       "      <th>percentage_m</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>739</td>\n",
       "      <td>0.039727</td>\n",
       "      <td>2529</td>\n",
       "      <td>0.044540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>6220</td>\n",
       "      <td>0.334373</td>\n",
       "      <td>15502</td>\n",
       "      <td>0.273014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>1342</td>\n",
       "      <td>0.072143</td>\n",
       "      <td>4646</td>\n",
       "      <td>0.081823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she</th>\n",
       "      <td>636</td>\n",
       "      <td>0.034190</td>\n",
       "      <td>842</td>\n",
       "      <td>0.014829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>they</th>\n",
       "      <td>1919</td>\n",
       "      <td>0.103161</td>\n",
       "      <td>5780</td>\n",
       "      <td>0.101795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we</th>\n",
       "      <td>4645</td>\n",
       "      <td>0.249704</td>\n",
       "      <td>15517</td>\n",
       "      <td>0.273278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>3101</td>\n",
       "      <td>0.166703</td>\n",
       "      <td>11965</td>\n",
       "      <td>0.210722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         verb_w  percentage_w  verb_m  percentage_m\n",
       "subject                                            \n",
       "he          739      0.039727    2529      0.044540\n",
       "i          6220      0.334373   15502      0.273014\n",
       "it         1342      0.072143    4646      0.081823\n",
       "she         636      0.034190     842      0.014829\n",
       "they       1919      0.103161    5780      0.101795\n",
       "we         4645      0.249704   15517      0.273278\n",
       "you        3101      0.166703   11965      0.210722"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pf = pronoun frequency\n",
    "\n",
    "# Count the rows with each pronoun as the subject:\n",
    "pf_m = df_m.groupby([\"subject\"]).count()\n",
    "pf_w = df_w.groupby([\"subject\"]).count()\n",
    "\n",
    "# Drop the OBJECT column\n",
    "pf_w.drop('object', axis=1, inplace=True)\n",
    "# Create PERCENTAGE column\n",
    "pf_w['percentage'] = pf_w['verb'] /  pf_w['verb'].sum()\n",
    "\n",
    "# Repeat above for men speakers\n",
    "pf_m.drop('object', axis=1, inplace=True)\n",
    "pf_m['percentage'] = pf_m['verb'] /  pf_m['verb'].sum()\n",
    "\n",
    "# Merge the two dataframes\n",
    "pf_compare = pf_w.merge(pf_m, \n",
    "                        left_on='subject', \n",
    "                        right_on='subject',\n",
    "                        suffixes=('_w', '_m'))\n",
    "\n",
    "# See the results\n",
    "pf_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> The code below works, but it gives raw counts and it probably needs to be a percentage so that one can compare the mens' and womens' subcorpora. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the top 20 verbs for each pronoun\n",
    "pv_w = df_w.groupby([\"subject\", \"verb\"]).size().groupby(level=0).nlargest(20).reset_index(level=0, drop=True).reset_index(name='Count')\n",
    "\n",
    "# Save to CSV for easier viewing\n",
    "pv_w.to_csv('../output/pv_w.csv')\n",
    "\n",
    "# Repeat for the men\n",
    "pv_m = df_m.groupby([\"subject\", \"verb\"]).size().groupby(level=0).nlargest(20).reset_index(level=0, drop=True).reset_index(name='Count')\n",
    "pv_m.to_csv('../output/pv_m.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_.groupby(\"subject\").groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_.groupby(\"subject\").get_group('he')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives you a dataframe with just the index\n",
    "# and the verb\n",
    "df2 = df_.groupby(['subject'])[['verb']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df_.groupby(\n",
    "    ['subject', 'verb']).size().groupby(level=0).nlargest(5).reset_index(level=0, drop=True).reset_index(name='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "14a02b88778d8fb8b6aeb4ad427a942bc53dfcda9d7e3737237788289e0d2d23"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": 2,
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
