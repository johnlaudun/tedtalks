{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From our 992x14 CSV, we have a list of 992 talks: 260 by women and 720 by men.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import re, spacy, textacy\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# If needed\n",
    "parentheticals = [ \"\\(laughter\\)\", \"\\(applause\\)\", \"\\(music\\)\",  \n",
    "                  \"\\(video\\)\", \"\\(laughs\\)\", \"\\(applause ends\\)\", \n",
    "                  \"\\(audio\\)\", \"\\(singing\\)\", \"\\(music ends\\)\", \n",
    "                  \"\\(cheers\\)\", \"\\(cheering\\)\", \"\\(recording\\)\", \n",
    "                  \"\\(beatboxing\\)\", \"\\(audience\\)\", \"\\(guitar strum\\)\", \n",
    "                  \"\\(clicks metronome\\)\", \"\\(sighs\\)\", \"\\(guitar\\)\", \n",
    "                  \"\\(marimba sounds\\)\", \"\\(drum sounds\\)\" ]\n",
    "\n",
    "def remove_parentheticals(text):\n",
    "    global parentheticals\n",
    "    new_text = text\n",
    "    for rgx_match in parentheticals:\n",
    "        new_text = re.sub(rgx_match, ' ', new_text.lower(), \n",
    "                          flags=re.IGNORECASE)\n",
    "    return new_text\n",
    "\n",
    "# Loading the Data in a gendered partitioned fashion: \n",
    "talks_m = pd.read_csv('talks_male.csv', index_col='Talk_ID')\n",
    "talks_f = pd.read_csv('talks_female.csv', index_col='Talk_ID')\n",
    "talks_nog = pd.read_csv('talks_nog.csv', index_col='Talk_ID')\n",
    "talks_all = pd.concat([talks_m, talks_f, talks_nog])\n",
    "\n",
    "# And then grabbing on the texts of the talks:\n",
    "texts = talks_all.text.tolist()\n",
    "texts_f = talks_f.text.tolist()\n",
    "texts_m = talks_m.text.tolist()\n",
    "\n",
    "print(f\"From our {talks_all.shape[0]}x{talks_all.shape[1]} CSV, \\\n",
    "we have a list of {len(texts)} talks: {len(texts_f)} by women and \\\n",
    "{len(texts_m)} by men.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textacy\n",
    "\n",
    "Textacy is fussy about the size of texts being fed it, responding with `ValueError`s for `nlp.maxlength`. The workaround here is to create a `docs` object which is a list of spaCy `doc`s. The preview below demonstrates that each item in the list has the characteristics of a spaCy doc.\n",
    "\n",
    "Textacy does have a `corpus` object, but it is not straightforward to implement.\n",
    "\n",
    "```python\n",
    "corpus = textacy.Corpus(\"en_core_web_sm\", data=docs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Space pipeline to be used\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# Use the pipe method to feed documents \n",
    "docs = list(nlp.pipe(texts_f))\n",
    "\n",
    "docs[0]._.preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working through a Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   _SP SPACE\n",
      "If IN SCONJ\n",
      "you PRP PRON\n",
      "'re VBP AUX\n",
      "here RB ADV\n"
     ]
    }
   ],
   "source": [
    "for token in docs[0][0:5]:\n",
    "    print (token, token.tag_, token.pos_) # spacy.explain(token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVOs = list(textacy.extract.triples.subject_verb_object_triples(docs[0]))\n",
    "len(SVOs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVOTriple(subject=[development], verb=[will, save], object=[us])\n",
      "SVOTriple(subject=[She], verb=[turned], object=[to, be, a, much, bigger, dog, than, I, 'd, anticipated])\n",
      "SVOTriple(subject=[part], verb=[handled], object=[percent])\n",
      "SVOTriple(subject=[that], verb=[bring], object=[truck, trips])\n",
      "SVOTriple(subject=[area], verb=[has], object=[one])\n",
      "SVOTriple(subject=[I], verb=[was, contacted], object=[Parks, Department])\n",
      "SVOTriple(subject=[I], verb=[mentioned], object=[that])\n",
      "SVOTriple(subject=[she], verb=[pulled], object=[me])\n",
      "SVOTriple(subject=[she], verb=[were], object=[dragging, me])\n",
      "SVOTriple(subject=[I], verb=[wo, n't, mention], object=[that])\n"
     ]
    }
   ],
   "source": [
    "for item in SVOs[0:10]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[development]\n",
      "[She]\n",
      "[part]\n",
      "[that]\n",
      "[area]\n",
      "[I]\n",
      "[I]\n",
      "[she]\n",
      "[she]\n",
      "[I]\n"
     ]
    }
   ],
   "source": [
    "for item in SVOs[0:10]:\n",
    "    print(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVOTriple(subject=[I], verb=[was, contacted], object=[Parks, Department])\n",
      "SVOTriple(subject=[I], verb=[mentioned], object=[that])\n",
      "SVOTriple(subject=[I], verb=[wo, n't, mention], object=[that])\n"
     ]
    }
   ],
   "source": [
    "for item in SVOs[0:10]:\n",
    "    if str(item[0]) == '[I]':\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVOTriple(subject=[I], verb=[was, contacted], object=[Parks, Department])\n",
      "SVOTriple(subject=[I], verb=[mentioned], object=[that])\n",
      "SVOTriple(subject=[I], verb=[wo, n't, mention], object=[that])\n",
      "SVOTriple(subject=[I], verb=['m, going], object=[to, exchange, marriage, vows, with, my, beloved])\n",
      "SVOTriple(subject=[I], verb=[do], object=[which])\n",
      "SVOTriple(subject=[I], verb=[watched], object=[half])\n",
      "SVOTriple(subject=[I], verb=[told], object=[you])\n",
      "SVOTriple(subject=[I], verb=[wrote], object=[dollar, transportation, grant])\n",
      "SVOTriple(subject=[I], verb=[like], object=[that])\n",
      "SVOTriple(subject=[I], verb=[have], object=[all])\n",
      "SVOTriple(subject=[I], verb=[do, not, expect], object=[individuals, corporations, government])\n",
      "SVOTriple(subject=[I], verb=['ll, tell], object=[you])\n",
      "SVOTriple(subject=[I], verb=[like], object=[what])\n",
      "SVOTriple(subject=[I], verb=[told], object=[you])\n",
      "SVOTriple(subject=[I], verb=['ve, embraced], object=[capitalist])\n",
      "SVOTriple(subject=[I], verb=[do, n't, have], object=[problem])\n",
      "SVOTriple(subject=[I], verb=[do, have], object=[problem])\n",
      "SVOTriple(subject=[I], verb=['m, trying], object=[to, build])\n",
      "SVOTriple(subject=[I], verb=[have], object=[time])\n",
      "SVOTriple(subject=[I], verb=[asked], object=[him])\n"
     ]
    }
   ],
   "source": [
    "for item in SVOs:\n",
    "    if str(item[0]) == '[I]':\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will be to locate the last item in the verb list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[contacted]\n",
      "[mentioned]\n",
      "[mention]\n",
      "[going]\n",
      "[do]\n",
      "[watched]\n",
      "[told]\n",
      "[wrote]\n",
      "[like]\n",
      "[have]\n",
      "[expect]\n",
      "[tell]\n",
      "[like]\n",
      "[told]\n",
      "[embraced]\n",
      "[have]\n",
      "[have]\n",
      "[trying]\n",
      "[have]\n",
      "[asked]\n"
     ]
    }
   ],
   "source": [
    "for item in SVOs:\n",
    "    if str(item[0]) == '[I]':\n",
    "        print(item[1][-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[contacted] [Parks, Department]\n",
      "[mentioned] [that]\n",
      "[mention] [that]\n",
      "[going] [to, exchange, marriage, vows, with, my, beloved]\n",
      "[do] [which]\n",
      "[watched] [half]\n",
      "[told] [you]\n",
      "[wrote] [dollar, transportation, grant]\n",
      "[like] [that]\n",
      "[have] [all]\n",
      "[expect] [individuals, corporations, government]\n",
      "[tell] [you]\n",
      "[like] [what]\n",
      "[told] [you]\n",
      "[embraced] [capitalist]\n",
      "[have] [problem]\n",
      "[have] [problem]\n",
      "[trying] [to, build]\n",
      "[have] [time]\n",
      "[asked] [him]\n"
     ]
    }
   ],
   "source": [
    "for item in SVOs:\n",
    "    if str(item[0]) == '[I]':\n",
    "        print(item[1][-1:], item[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[turned] [to, be, a, much, bigger, dog, than, I, 'd, anticipated]\n",
      "[pulled] [me]\n",
      "[were] [dragging, me]\n",
      "[kept] [dragging, me]\n"
     ]
    }
   ],
   "source": [
    "for item in SVOs:\n",
    "    if str(item[0]) == '[She]':\n",
    "        print(item[1][-1:], item[2])\n",
    "    if str(item[0]) == '[she]':\n",
    "        print(item[1][-1:], item[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actions (terms, doc):\n",
    "    svotriples = list(textacy.extract.triples.subject_verb_object_triples(doc))\n",
    "    for term in terms:\n",
    "        for item in svotriples:\n",
    "            if str(item[0]) == term:\n",
    "                print(item[1][-1:], item[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next steps:**\n",
    "\n",
    "- Rewrite code to return appended lists for I, He, She. \n",
    "- Work on adaptation for objective cases. \n",
    "- Work on code to compile / visualize this as a network graph (?). So count up repeated verbs, etc.\n",
    "\n",
    "- *Do we need NLTK code to compare results?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[contacted] [Parks, Department]\n",
      "[mentioned] [that]\n",
      "[mention] [that]\n",
      "[going] [to, exchange, marriage, vows, with, my, beloved]\n",
      "[do] [which]\n",
      "[watched] [half]\n",
      "[told] [you]\n",
      "[wrote] [dollar, transportation, grant]\n",
      "[like] [that]\n",
      "[have] [all]\n",
      "[expect] [individuals, corporations, government]\n",
      "[tell] [you]\n",
      "[like] [what]\n",
      "[told] [you]\n",
      "[embraced] [capitalist]\n",
      "[have] [problem]\n",
      "[have] [problem]\n",
      "[trying] [to, build]\n",
      "[have] [time]\n",
      "[asked] [him]\n"
     ]
    }
   ],
   "source": [
    "terms = ['[I]']\n",
    "actions(terms, docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[contacted] [Parks, Department]\n",
      "[mentioned] [that]\n",
      "[mention] [that]\n",
      "[going] [to, exchange, marriage, vows, with, my, beloved]\n",
      "[do] [which]\n",
      "[watched] [half]\n",
      "[told] [you]\n",
      "[wrote] [dollar, transportation, grant]\n",
      "[like] [that]\n",
      "[have] [all]\n",
      "[expect] [individuals, corporations, government]\n",
      "[tell] [you]\n",
      "[like] [what]\n",
      "[told] [you]\n",
      "[embraced] [capitalist]\n",
      "[have] [problem]\n",
      "[have] [problem]\n",
      "[trying] [to, build]\n",
      "[have] [time]\n",
      "[asked] [him]\n",
      "[came] [myself]\n",
      "[presented] [myself]\n",
      "[going] [to, have, a, party, and, a, cake, and, get, a, lot, of, presents]\n",
      "[heard] [phrase]\n",
      "[paid] [attention]\n",
      "[noticed] [it]\n",
      "[known] [this]\n",
      "[realized] [information]\n",
      "[left] [kitchen]\n",
      "[missed] [age]\n",
      "[help] [someone]\n",
      "[found] [Bill]\n",
      "[turned] [to, run]\n",
      "[turned] [it, seven]\n",
      "[said] [it, seven]\n",
      "[know] [it]\n",
      "[turning] [seven]\n",
      "[planned] [party]\n",
      "[need] [to, speak, to, you, privately]\n",
      "[told] [them]\n",
      "[started] [to, tell, you, your, birthday, was, September, 10th]\n",
      "[had] [to, change, the, date, of, my, slumber, party, with, all, of, my, girlfriends]\n",
      "[had] [Virgo, poster]\n",
      "[read] [horoscope]\n",
      "[took] [bus, downtown]\n",
      "[started] [filling, out, physically]\n",
      "[filling] [more]\n",
      "[got] [Libra, poster]\n",
      "[started] [to, read, my, new, Libra, horoscope]\n",
      "[astonished] [to, find, that, it, was, also, totally, me]\n",
      "[turning] [seven]\n",
      "[turned] [seven]\n",
      "[had] [month]\n",
      "[get] [ladies]\n",
      "[get] [teenagers]\n",
      "[buy] [magazine, subscriptions]\n",
      "[ignore] [doorbell]\n",
      "[answered] [doorbell]\n",
      "[said] [message]\n",
      "[raised] [them, doctrine, what]\n",
      "[worked] [them, doctrine, what]\n",
      "[dated] [them]\n",
      "[knew] [doctrine]\n",
      "[guess] [them, doctrine, what]\n",
      "[sat] [them]\n",
      "[got] [glasses]\n",
      "[got] [it]\n",
      "[got] [it]\n",
      "[got] [glasses]\n",
      "[sat] [them]\n",
      "[got] [glasses]\n",
      "[believe] [word, heart, word]\n",
      "[like] [word, heart]\n",
      "[like] [word]\n",
      "[want] [to, argue, semantics, with, these, boys]\n",
      "[Put] [family]\n",
      "[lead] [you]\n",
      "[wanted] [to, give, these, two, boys, some, advice, about, their, pitch]\n",
      "[wanted] [to, say, —]\n",
      "[said] [little]\n",
      "[thought] [this]\n",
      "[backpedaled] [little]\n",
      "[said] [Oh, ,, come, on]\n",
      "[have] [uterus]\n",
      "[had] [cancer]\n",
      "[get] [uterus]\n",
      "[said] [Book, me]\n",
      "[think] [Book, me]\n",
      "[said] [something]\n",
      "[had] [to, be, honest, with, myself]\n",
      "[hearing] [theology, dogma]\n",
      "[feel] [it]\n",
      "[feel] [love]\n",
      "[feel] [consoled, and, cared, for]\n",
      "[take] [shelter]\n",
      "[feel] [shelter]\n",
      "[felt] [what]\n"
     ]
    }
   ],
   "source": [
    "for doc in docs[0:2]:\n",
    "    actions(terms, doc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "14a02b88778d8fb8b6aeb4ad427a942bc53dfcda9d7e3737237788289e0d2d23"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": 2,
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
