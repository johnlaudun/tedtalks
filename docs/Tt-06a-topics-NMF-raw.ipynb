{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=\n",
    "# Read CSV into DataFrame and then create lists\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "import pandas\n",
    "import re\n",
    "\n",
    "# Create pandas dataframe & lists\n",
    "colnames = ['author', 'title', 'date' , 'length', 'text']\n",
    "df = pandas.read_csv('../data/talks_3.csv', names=colnames)\n",
    "talks = df.text.tolist()\n",
    "\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Create citations to identify individual texts\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "# authors = df.author.tolist()\n",
    "# dates = df.date.tolist()\n",
    "# years = [re.sub('[A-Za-z ]', '', item) for item in dates]\n",
    "# authordate = [author+\" \"+year for author, year in zip(authors, years)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=\n",
    "# Clean and Tokenize, then Drop Stopwords\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "# From the Stopwords Notebook:\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "stopwords = re.split('\\s+', open('../data/tt_stop.txt', 'r').read().lower())\n",
    "\n",
    "# Loop to tokenize, stop, and stem (if needed) texts.\n",
    "texts = []\n",
    "for talk in talks:   \n",
    "    # clean and tokenize document string\n",
    "    raw = re.sub(r\"[^\\w\\d'\\s]+\",'', talk).lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [i for i in tokens if not i in stopwords]\n",
    "    # stem tokens\n",
    "    # stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    # add tokens to list\n",
    "    texts.append(stopped_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Re-Assemble Texts as Strings from Lists of Words\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "strungs = []\n",
    "for text in texts:\n",
    "    strung = ' '.join(text)\n",
    "    strungs.append(strung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model with 40 topics for 2068 documents with 3000 features.\n"
     ]
    }
   ],
   "source": [
    "# =-=-=-=-=-=\n",
    "# Get NMF topics\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# All our variables are here to make it easier to make adjustments\n",
    "n_samples = len(strungs)\n",
    "n_features = 3000\n",
    "n_topics = 40\n",
    "n_top_words = 15\n",
    "# tt_stopwords = open('../data/stopwords_tt.txt', 'r').read().splitlines()\n",
    "\n",
    "# Get tf-idf features for NMF\n",
    "vectorizer = sk_text.TfidfVectorizer(max_df = 0.95,\n",
    "                                        min_df = 0.05,\n",
    "                                        max_features = n_features)\n",
    "tfidf = vectorizer.fit_transform(strungs)\n",
    "\n",
    "# Fit the NMF model\n",
    "nmf = NMF(n_components = n_topics,\n",
    "          random_state = 1,\n",
    "          alpha = 0.1,\n",
    "          l1_ratio = 0.5).fit(tfidf)\n",
    "print(\"Fitting the NMF model with {} topics for {} documents with {} features.\"\n",
    "      .format(n_topics, n_samples, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics in NMF model:\n",
      "\n",
      "Topic 0:\n",
      "just 0.82, really 0.73, actually 0.71, people 0.67, see 0.67, think 0.66, going 0.61, things 0.59, get 0.56, time 0.51, make 0.46, little 0.43, right 0.43, look 0.41, go 0.4, \n",
      "\n",
      "Topic 1:\n",
      "people 0.75, countries 0.53, world 0.53, percent 0.45, country 0.44, global 0.4, government 0.39, money 0.38, dollars 0.37, china 0.34, economic 0.33, economy 0.3, states 0.29, democracy 0.28, social 0.28, \n",
      "\n",
      "Topic 2:\n",
      "women 2.54, men 0.99, girls 0.45, woman 0.41, sex 0.28, female 0.27, gender 0.24, male 0.18, girl 0.15, boys 0.15, violence 0.14, equal 0.11, rights 0.1, young 0.09, husband 0.08, \n",
      "\n",
      "Topic 3:\n",
      "brain 2.68, brains 0.36, arm 0.18, activity 0.18, mental 0.17, human 0.15, body 0.15, memory 0.13, mind 0.12, behavior 0.11, pain 0.11, visual 0.1, animal 0.1, genes 0.1, control 0.09, \n",
      "\n",
      "Topic 4:\n",
      "earth 1.23, planet 1.0, life 0.47, solar 0.47, stars 0.38, sun 0.38, surface 0.36, atmosphere 0.32, star 0.26, system 0.24, moon 0.23, years 0.21, billion 0.16, miles 0.15, size 0.12, \n",
      "\n",
      "Topic 5:\n",
      "building 1.3, buildings 0.78, architecture 0.75, built 0.26, build 0.25, project 0.25, materials 0.21, air 0.2, house 0.19, material 0.16, structure 0.15, site 0.15, construction 0.15, spaces 0.14, floor 0.11, \n",
      "\n",
      "Topic 6:\n",
      "music 2.35, piece 0.21, song 0.2, playing 0.19, hear 0.14, play 0.13, played 0.12, video 0.11, listen 0.09, hearing 0.07, yeah 0.07, audience 0.06, experience 0.06, kind 0.06, dance 0.05, \n",
      "\n",
      "Topic 7:\n",
      "cancer 2.09, patients 0.49, disease 0.45, patient 0.35, drug 0.33, health 0.31, medical 0.23, treatment 0.22, blood 0.21, drugs 0.21, medicine 0.2, doctors 0.2, doctor 0.2, body 0.18, care 0.15, \n",
      "\n",
      "Topic 8:\n",
      "food 2.01, eat 0.58, feed 0.28, eating 0.28, plant 0.24, waste 0.23, organic 0.17, plants 0.17, kids 0.14, fish 0.14, healthy 0.11, production 0.11, growing 0.1, local 0.09, grow 0.08, \n",
      "\n",
      "Topic 9:\n",
      "ocean 1.37, fish 1.09, sea 0.74, animals 0.37, deep 0.21, plastic 0.17, species 0.17, boat 0.16, coast 0.15, water 0.14, animal 0.13, blue 0.13, creatures 0.11, north 0.11, feed 0.11, \n",
      "\n",
      "Topic 10:\n",
      "universe 1.85, theory 0.35, stars 0.33, physics 0.3, dark 0.29, billion 0.17, matter 0.16, sky 0.15, science 0.14, black 0.14, laws 0.14, energy 0.13, space 0.13, big 0.13, mass 0.12, \n",
      "\n",
      "Topic 11:\n",
      "kids 1.24, school 1.13, students 0.89, education 0.7, teachers 0.69, teacher 0.38, schools 0.34, learning 0.33, teaching 0.28, teach 0.28, class 0.25, student 0.23, learn 0.2, kid 0.2, math 0.18, \n",
      "\n",
      "Topic 12:\n",
      "light 1.91, see 0.46, lights 0.32, dark 0.22, stars 0.21, blue 0.2, eye 0.2, camera 0.19, sun 0.19, eyes 0.18, star 0.16, color 0.15, black 0.13, image 0.12, green 0.1, \n",
      "\n",
      "Topic 13:\n",
      "data 2.68, web 0.17, map 0.14, health 0.13, patients 0.13, information 0.12, points 0.08, text 0.07, analysis 0.06, look 0.06, numbers 0.06, hospital 0.06, google 0.06, patterns 0.05, computer 0.05, \n",
      "\n",
      "Topic 14:\n",
      "car 1.61, cars 1.08, driving 0.37, road 0.28, drive 0.24, miles 0.2, traffic 0.16, cities 0.12, sharing 0.11, going 0.1, hour 0.09, percent 0.08, cost 0.06, expensive 0.06, fuel 0.06, \n",
      "\n",
      "Topic 15:\n",
      "ca 2.0, yeah 0.25, mean 0.18, think 0.12, chris 0.12, mr 0.1, people 0.09, got 0.09, anderson 0.09, ted 0.07, ok 0.05, wow 0.04, source 0.03, thank 0.03, report 0.03, \n",
      "\n",
      "Topic 16:\n",
      "city 1.82, cities 1.19, urban 0.33, new 0.28, york 0.27, map 0.25, street 0.21, park 0.2, neighborhood 0.2, spaces 0.18, people 0.18, streets 0.18, public 0.17, community 0.15, places 0.13, \n",
      "\n",
      "Topic 17:\n",
      "africa 2.08, african 0.82, south 0.26, countries 0.23, aid 0.17, leaders 0.13, aids 0.11, sub 0.09, world 0.09, asia 0.09, country 0.08, east 0.06, percent 0.06, story 0.06, market 0.05, \n",
      "\n",
      "Topic 18:\n",
      "sound 1.74, voice 0.58, listening 0.5, sounds 0.39, hear 0.32, hearing 0.24, listen 0.23, song 0.22, visual 0.08, wave 0.08, speech 0.07, color 0.07, time 0.07, just 0.06, body 0.06, \n",
      "\n",
      "Topic 19:\n",
      "water 2.55, river 0.27, waste 0.19, dry 0.11, clean 0.11, india 0.1, rain 0.1, surface 0.1, supply 0.09, plastic 0.08, environment 0.08, material 0.08, drink 0.06, plant 0.06, green 0.06, \n",
      "\n",
      "Topic 20:\n",
      "said 0.71, people 0.56, life 0.51, story 0.4, man 0.39, father 0.39, day 0.37, love 0.35, mother 0.33, family 0.33, went 0.32, time 0.3, told 0.3, stories 0.3, years 0.29, \n",
      "\n",
      "Topic 21:\n",
      "language 1.39, english 1.07, word 0.54, words 0.53, languages 0.3, chinese 0.21, speak 0.19, sentence 0.14, books 0.14, speech 0.13, say 0.12, writing 0.11, read 0.1, learn 0.09, write 0.08, \n",
      "\n",
      "Topic 22:\n",
      "design 2.24, designers 0.65, designed 0.26, designing 0.26, products 0.13, product 0.13, new 0.1, beautiful 0.1, technology 0.1, work 0.09, object 0.09, kind 0.08, process 0.08, materials 0.07, made 0.06, \n",
      "\n",
      "Topic 23:\n",
      "oil 1.87, gas 0.35, stuff 0.18, energy 0.14, carbon 0.13, birds 0.09, price 0.09, fuel 0.08, largest 0.08, companies 0.06, natural 0.06, boat 0.05, mexico 0.05, plastic 0.04, molecules 0.04, \n",
      "\n",
      "Topic 24:\n",
      "children 2.02, child 0.89, babies 0.39, parents 0.33, india 0.26, family 0.26, families 0.25, schools 0.16, baby 0.15, mother 0.14, boy 0.12, countries 0.12, health 0.11, adults 0.08, development 0.07, \n",
      "\n",
      "Topic 25:\n",
      "cells 2.15, cell 0.71, body 0.26, disease 0.24, drug 0.24, drugs 0.19, blood 0.16, patients 0.16, lab 0.15, diseases 0.15, patient 0.15, heart 0.14, skin 0.12, actually 0.11, animal 0.11, \n",
      "\n",
      "Topic 26:\n",
      "fly 1.62, flying 0.48, flight 0.45, baby 0.15, control 0.11, air 0.1, plane 0.09, model 0.09, birds 0.07, camera 0.06, go 0.06, speed 0.06, weight 0.06, two 0.05, field 0.05, \n",
      "\n",
      "Topic 27:\n",
      "species 0.93, plants 0.83, forest 0.8, animals 0.71, plant 0.58, trees 0.56, tree 0.35, nature 0.26, animal 0.24, carbon 0.22, genes 0.2, birds 0.19, human 0.19, brazil 0.17, land 0.17, \n",
      "\n",
      "Topic 28:\n",
      "games 1.3, game 1.29, video 0.84, playing 0.24, play 0.1, real 0.09, interaction 0.08, online 0.07, physical 0.07, videos 0.06, win 0.06, world 0.05, boys 0.05, computer 0.04, camera 0.04, \n",
      "\n",
      "Topic 29:\n",
      "internet 1.36, media 0.64, online 0.57, web 0.56, page 0.33, digital 0.27, government 0.27, facebook 0.27, network 0.23, content 0.23, google 0.22, social 0.22, email 0.17, people 0.16, networks 0.15, \n",
      "\n",
      "Topic 30:\n",
      "laughter 2.32, applause 0.36, okay 0.21, oh 0.09, yeah 0.09, right 0.08, piece 0.07, color 0.06, friends 0.06, mom 0.06, hear 0.05, thank 0.05, four 0.04, just 0.03, open 0.03, \n",
      "\n",
      "Topic 31:\n",
      "dna 1.88, genes 0.39, genetic 0.31, cell 0.24, code 0.22, molecules 0.16, species 0.16, biology 0.13, science 0.1, base 0.08, program 0.07, understand 0.07, evolution 0.06, technology 0.06, long 0.06, \n",
      "\n",
      "Topic 32:\n",
      "ice 1.6, climate 0.44, feet 0.18, sea 0.17, north 0.16, atmosphere 0.15, ocean 0.13, south 0.13, co 0.12, change 0.1, cold 0.1, years 0.1, year 0.1, temperature 0.1, back 0.09, \n",
      "\n",
      "Topic 33:\n",
      "information 2.2, phone 0.43, mobile 0.29, visual 0.16, system 0.13, digital 0.1, access 0.09, police 0.07, phones 0.07, device 0.06, intelligence 0.06, technologies 0.05, report 0.05, books 0.05, devices 0.05, \n",
      "\n",
      "Topic 34:\n",
      "play 1.91, playing 0.25, serious 0.16, played 0.11, kids 0.11, note 0.11, fun 0.1, game 0.08, creativity 0.07, dance 0.06, mom 0.06, little 0.06, mistake 0.05, television 0.05, love 0.04, \n",
      "\n",
      "Topic 35:\n",
      "energy 1.61, nuclear 0.55, power 0.38, solar 0.38, electricity 0.36, climate 0.35, wind 0.27, fuel 0.26, carbon 0.25, heat 0.18, temperature 0.17, air 0.17, co 0.16, waste 0.15, gas 0.13, \n",
      "\n",
      "Topic 36:\n",
      "machine 1.76, computer 0.89, machines 0.58, computers 0.45, technology 0.19, human 0.18, intelligence 0.14, learning 0.14, built 0.11, memory 0.1, build 0.09, web 0.09, software 0.08, artificial 0.06, digital 0.06, \n",
      "\n",
      "Topic 37:\n",
      "know 1.63, said 0.96, going 0.94, got 0.56, just 0.5, say 0.47, yeah 0.46, ok 0.45, right 0.45, oh 0.44, get 0.41, think 0.38, thing 0.37, guy 0.34, really 0.34, \n",
      "\n",
      "Topic 38:\n",
      "space 2.19, spaces 0.21, body 0.15, ok 0.13, moon 0.13, physical 0.1, experience 0.08, object 0.07, public 0.07, time 0.07, moving 0.06, museum 0.06, inside 0.06, room 0.05, prize 0.05, \n",
      "\n",
      "Topic 39:\n",
      "art 1.48, artist 0.62, artists 0.59, painting 0.49, museum 0.34, images 0.3, work 0.24, project 0.23, book 0.19, image 0.18, wall 0.12, books 0.12, film 0.11, cultural 0.1, visual 0.1, \n"
     ]
    }
   ],
   "source": [
    "# =-=-=-=-=-=\n",
    "# Get NMF printing\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_id, topic in enumerate(model.components_):\n",
    "        print('\\nTopic {}:'.format(int(topic_id)))\n",
    "        print(''.join([feature_names[i] + ' ' + str(round(topic[i], 2))\n",
    "              +', ' for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "\n",
    "features = vectorizer.get_feature_names()\n",
    "# print(features)\n",
    "\n",
    "# This should work now.\n",
    "\n",
    "print(\"Topics in NMF model:\")\n",
    "print_top_words(nmf, features, n_top_words) #n_top_words can be changed on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ability', 'able', 'absolute', 'absolutely', 'accept', 'access', 'accident', 'account', 'achieve', 'act', 'acting', 'action', 'actions', 'active', 'activities', 'activity', 'actual', 'actually', 'add', 'added', 'addition', 'address', 'admit', 'adult', 'adults', 'advanced', 'advantage', 'affect', 'affected', 'afford', 'afraid', 'africa', 'african', 'afternoon', 'age', 'ages', 'ago', 'agree', 'agreed', 'ahead', 'aid', 'aids', 'air', 'al', 'alive', 'allow', 'allowed', 'allowing', 'allows', 'alternative', 'amazing', 'america', 'american', 'americans', 'amount', 'amounts', 'analysis', 'ancient', 'anderson', 'angry', 'animal', 'animals', 'answer', 'answers', 'anti', 'anybody', 'anymore', 'anyway', 'apart', 'appear', 'applause', 'apple', 'applied', 'apply', 'appreciate', 'approach', 'appropriate', 'architecture', 'area', 'areas', 'argue', 'argument', 'arm', 'arms', 'army', 'arrived', 'art', 'article', 'artificial', 'artist', 'artists', 'asia', 'ask', 'asked', 'asking', 'aspect', 'associated', 'atmosphere', 'attack', 'attention', 'audience', 'australia', 'available', 'average', 'avoid', 'aware', 'awareness', 'away', 'awful', 'babies', 'baby', 'back', 'background', 'bad', 'balance', 'ball', 'bank', 'bar', 'base', 'based', 'basic', 'basically', 'basis', 'battle', 'bear', 'beat', 'beautiful', 'beauty', 'bed', 'begin', 'beginning', 'begins', 'behavior', 'beings', 'belief', 'believe', 'believed', 'benefit', 'benefits', 'best', 'better', 'big', 'bigger', 'biggest', 'bill', 'billion', 'billions', 'biological', 'biology', 'birds', 'birth', 'bit', 'bits', 'black', 'blind', 'block', 'blocks', 'blood', 'blue', 'board', 'boat', 'bodies', 'body', 'book', 'books', 'born', 'bottom', 'bought', 'box', 'boy', 'boys', 'brain', 'brains', 'brand', 'brazil', 'break', 'breaking', 'bridge', 'bright', 'brilliant', 'bring', 'bringing', 'brings', 'british', 'broke', 'broken', 'brother', 'brothers', 'brought', 'brown', 'budget', 'build', 'building', 'buildings', 'built', 'bunch', 'burning', 'business', 'businesses', 'busy', 'buy', 'buying', 'ca', 'california', 'call', 'called', 'calling', 'calls', 'came', 'camera', 'campaign', 'cancer', 'capable', 'capacity', 'capital', 'capture', 'car', 'carbon', 'card', 'care', 'career', 'careful', 'carefully', 'carry', 'carrying', 'cars', 'case', 'cases', 'catch', 'caught', 'cause', 'caused', 'causes', 'cell', 'cells', 'center', 'centers', 'central', 'century', 'certainly', 'chain', 'challenge', 'challenges', 'challenging', 'chance', 'change', 'changed', 'changes', 'changing', 'character', 'charge', 'cheap', 'check', 'chemical', 'child', 'childhood', 'children', 'china', 'chinese', 'choice', 'choices', 'choose', 'chose', 'chris', 'circle', 'cities', 'citizens', 'city', 'civil', 'civilization', 'class', 'classic', 'clean', 'clear', 'clearly', 'climate', 'clock', 'close', 'closed', 'closely', 'closer', 'clothes', 'co', 'coast', 'code', 'coffee', 'cold', 'collaboration', 'colleague', 'colleagues', 'collect', 'collected', 'collection', 'collective', 'college', 'color', 'colors', 'combination', 'combine', 'combined', 'come', 'comes', 'comfortable', 'coming', 'commercial', 'common', 'communicate', 'communication', 'communities', 'community', 'companies', 'company', 'compare', 'compared', 'competition', 'complete', 'completely', 'complex', 'complexity', 'complicated', 'computer', 'computers', 'concept', 'concerned', 'conclusion', 'condition', 'conditions', 'conference', 'confidence', 'conflict', 'connect', 'connected', 'connection', 'connections', 'consequences', 'consider', 'considered', 'constant', 'constantly', 'construction', 'contact', 'content', 'context', 'continue', 'control', 'controlled', 'conversation', 'conversations', 'convince', 'convinced', 'cool', 'copy', 'core', 'corner', 'correct', 'cost', 'costs', 'count', 'countries', 'country', 'couple', 'course', 'cover', 'covered', 'crazy', 'create', 'created', 'creates', 'creating', 'creation', 'creative', 'creativity', 'creatures', 'credit', 'crime', 'crisis', 'critical', 'cross', 'crowd', 'cultural', 'culture', 'cultures', 'curious', 'current', 'currently', 'cut', 'cutting', 'cycle', 'dad', 'daily', 'damage', 'dance', 'dangerous', 'dark', 'data', 'date', 'daughter', 'david', 'day', 'days', 'de', 'dead', 'deal', 'dealing', 'death', 'debate', 'decade', 'decades', 'decide', 'decided', 'decision', 'decisions', 'deep', 'deeper', 'deeply', 'define', 'defined', 'definitely', 'definition', 'degree', 'degrees', 'deliver', 'demand', 'democracy', 'department', 'depends', 'depression', 'describe', 'described', 'design', 'designed', 'designers', 'designing', 'desire', 'despite', 'destruction', 'detail', 'details', 'develop', 'developed', 'developing', 'development', 'device', 'devices', 'die', 'died', 'difference', 'differences', 'different', 'differently', 'difficult', 'digital', 'dimensional', 'dinner', 'direct', 'direction', 'directly', 'disaster', 'discover', 'discovered', 'discovery', 'disease', 'diseases', 'distance', 'distribution', 'diversity', 'dna', 'doctor', 'doctors', 'dog', 'dollar', 'dollars', 'done', 'door', 'double', 'doubt', 'dr', 'dramatic', 'draw', 'drawing', 'dream', 'dreams', 'drink', 'drive', 'driven', 'drives', 'driving', 'drop', 'dropped', 'drug', 'drugs', 'dry', 'due', 'dying', 'dynamic', 'earlier', 'early', 'earth', 'easier', 'easily', 'east', 'easy', 'eat', 'eating', 'economic', 'economics', 'economy', 'edge', 'education', 'effect', 'effective', 'effectively', 'effects', 'efficient', 'effort', 'eight', 'electricity', 'elements', 'email', 'emerging', 'emotional', 'emotions', 'empty', 'encourage', 'end', 'ended', 'ends', 'energy', 'engage', 'engaged', 'engine', 'engineer', 'engineering', 'engineers', 'england', 'english', 'enjoy', 'enormous', 'enter', 'entire', 'entirely', 'environment', 'environmental', 'environments', 'equal', 'equally', 'equipment', 'equivalent', 'era', 'essential', 'essentially', 'europe', 'european', 'evening', 'event', 'events', 'eventually', 'everybody', 'everyday', 'evidence', 'evolution', 'evolved', 'exact', 'exactly', 'examples', 'exchange', 'excited', 'exciting', 'exercise', 'exist', 'existed', 'existence', 'existing', 'exists', 'expect', 'expected', 'expensive', 'experience', 'experienced', 'experiences', 'experiment', 'experiments', 'experts', 'explain', 'explained', 'explore', 'express', 'expression', 'extent', 'extra', 'extraordinary', 'extreme', 'extremely', 'eye', 'eyes', 'face', 'facebook', 'faced', 'faces', 'facing', 'fact', 'factor', 'factors', 'fail', 'failed', 'failure', 'fair', 'fairly', 'faith', 'fall', 'falling', 'familiar', 'families', 'family', 'famous', 'fantastic', 'far', 'fascinating', 'fashion', 'fast', 'faster', 'father', 'favorite', 'fear', 'feed', 'feel', 'feeling', 'feels', 'feet', 'fell', 'fellow', 'felt', 'female', 'field', 'fields', 'fifth', 'fight', 'fighting', 'figure', 'figured', 'fill', 'filled', 'film', 'final', 'financial', 'finding', 'fine', 'finish', 'finished', 'fire', 'first', 'fish', 'fit', 'five', 'fix', 'flat', 'flight', 'floor', 'flow', 'fly', 'flying', 'focus', 'focused', 'folks', 'follow', 'followed', 'food', 'foot', 'force', 'forced', 'forces', 'foreign', 'forest', 'forever', 'forget', 'form', 'formed', 'forms', 'forth', 'forward', 'found', 'foundation', 'four', 'fourth', 'france', 'free', 'freedom', 'french', 'fresh', 'friend', 'friends', 'front', 'fuel', 'full', 'fully', 'fun', 'function', 'fundamental', 'fundamentally', 'funding', 'funny', 'future', 'gain', 'game', 'games', 'gap', 'gas', 'gave', 'gender', 'general', 'generate', 'generation', 'generations', 'genes', 'genetic', 'germany', 'get', 'gets', 'getting', 'giant', 'gift', 'girl', 'girls', 'give', 'gives', 'giving', 'glass', 'global', 'go', 'goal', 'god', 'goes', 'going', 'gone', 'good', 'google', 'got', 'gotten', 'government', 'governments', 'grade', 'graduate', 'grand', 'graph', 'great', 'greater', 'greatest', 'green', 'grew', 'ground', 'group', 'groups', 'grow', 'growing', 'grown', 'growth', 'guess', 'guy', 'guys', 'hair', 'half', 'hand', 'hands', 'happen', 'happened', 'happening', 'happens', 'happiness', 'happy', 'hard', 'harder', 'harvard', 'hate', 'head', 'heads', 'health', 'healthy', 'hear', 'heard', 'hearing', 'heart', 'heat', 'heavy', 'held', 'hell', 'help', 'helped', 'helping', 'helps', 'hey', 'hidden', 'hide', 'high', 'higher', 'highest', 'highly', 'history', 'hit', 'hits', 'hold', 'holding', 'hole', 'home', 'homes', 'honest', 'honor', 'hope', 'hopefully', 'hoping', 'horrible', 'hospital', 'hot', 'hour', 'hours', 'house', 'houses', 'huge', 'human', 'humanity', 'humans', 'hundred', 'hundreds', 'hurt', 'husband', 'ice', 'idea', 'ideas', 'identify', 'identity', 'image', 'images', 'imagination', 'imagine', 'imagined', 'immediately', 'impact', 'importance', 'important', 'importantly', 'impossible', 'improve', 'income', 'increase', 'increased', 'increasing', 'increasingly', 'incredible', 'incredibly', 'independent', 'india', 'individual', 'individuals', 'industrial', 'industry', 'influence', 'information', 'infrastructure', 'inner', 'innovation', 'inside', 'inspiration', 'inspired', 'instance', 'institute', 'institutions', 'intellectual', 'intelligence', 'intelligent', 'interact', 'interaction', 'interest', 'interested', 'interesting', 'interests', 'international', 'internet', 'introduce', 'introduced', 'invented', 'invention', 'invest', 'investment', 'invisible', 'invited', 'involved', 'iraq', 'island', 'issue', 'issues', 'it', 'japan', 'japanese', 'job', 'jobs', 'john', 'join', 'joined', 'journey', 'joy', 'jump', 'just', 'justice', 'keep', 'keeping', 'keeps', 'kept', 'key', 'kid', 'kids', 'kill', 'killed', 'killing', 'kilometers', 'kind', 'kinds', 'king', 'knew', 'know', 'knowing', 'knowledge', 'known', 'knows', 'lab', 'labor', 'laboratory', 'lack', 'ladies', 'lady', 'land', 'landscape', 'language', 'languages', 'large', 'largely', 'larger', 'largest', 'last', 'late', 'laughter', 'launched', 'law', 'laws', 'lay', 'lead', 'leader', 'leaders', 'leadership', 'leading', 'leads', 'learn', 'learned', 'learning', 'leave', 'leaves', 'leaving', 'led', 'left', 'leg', 'legal', 'legs', 'length', 'lesson', 'lessons', 'let', 'letter', 'letters', 'level', 'levels', 'lie', 'lies', 'life', 'lifetime', 'light', 'lights', 'liked', 'likely', 'limited', 'line', 'lines', 'link', 'list', 'listen', 'listening', 'literally', 'little', 'live', 'lived', 'lives', 'living', 'll', 'local', 'location', 'london', 'long', 'longer', 'look', 'looked', 'looking', 'looks', 'lose', 'losing', 'loss', 'lost', 'lot', 'lots', 'love', 'loved', 'low', 'lower', 'lucky', 'machine', 'machines', 'made', 'magazine', 'magic', 'main', 'major', 'majority', 'make', 'makes', 'making', 'male', 'man', 'manage', 'managed', 'management', 'map', 'mark', 'market', 'markets', 'marriage', 'married', 'mass', 'massive', 'match', 'material', 'materials', 'math', 'matter', 'matters', 'mean', 'meaning', 'meaningful', 'means', 'meant', 'measure', 'mechanism', 'media', 'medical', 'medicine', 'meet', 'meeting', 'member', 'members', 'memory', 'men', 'mental', 'mention', 'mentioned', 'message', 'messages', 'met', 'meters', 'method', 'mexico', 'mid', 'middle', 'miles', 'military', 'million', 'millions', 'mind', 'minds', 'mine', 'minute', 'minutes', 'missing', 'mission', 'mistake', 'mit', 'mobile', 'model', 'models', 'modern', 'molecules', 'mom', 'moment', 'moments', 'money', 'month', 'months', 'moon', 'moral', 'morning', 'mother', 'motion', 'mountain', 'mountains', 'mouth', 'move', 'moved', 'movement', 'moves', 'movie', 'movies', 'moving', 'mr', 'multiple', 'museum', 'music', 'name', 'named', 'names', 'nation', 'national', 'nations', 'natural', 'naturally', 'nature', 'necessarily', 'necessary', 'need', 'needed', 'needs', 'negative', 'neighborhood', 'neighbors', 'nervous', 'net', 'network', 'networks', 'new', 'news', 'nice', 'night', 'nine', 'non', 'normal', 'normally', 'north', 'northern', 'note', 'notice', 'noticed', 'notion', 'nuclear', 'number', 'numbers', 'object', 'objects', 'obvious', 'obviously', 'occurred', 'ocean', 'offer', 'offered', 'office', 'oh', 'oil', 'ok', 'okay', 'old', 'older', 'one', 'ones', 'online', 'open', 'opened', 'opening', 'operate', 'operating', 'opinion', 'opportunities', 'opportunity', 'opposite', 'order', 'ordinary', 'organic', 'organization', 'organizations', 'organized', 'original', 'outside', 'oxygen', 'page', 'pages', 'paid', 'pain', 'painting', 'paper', 'parents', 'park', 'participate', 'particular', 'partner', 'party', 'pass', 'passed', 'passion', 'past', 'path', 'patient', 'patients', 'pattern', 'patterns', 'pay', 'paying', 'peace', 'people', 'percent', 'perfect', 'perfectly', 'perform', 'performance', 'period', 'person', 'personal', 'personally', 'perspective', 'phenomenon', 'phone', 'phones', 'photo', 'photograph', 'physical', 'physically', 'physics', 'pick', 'picked', 'picture', 'pictures', 'piece', 'pieces', 'place', 'places', 'plan', 'plane', 'planet', 'planning', 'plant', 'plants', 'plastic', 'platform', 'play', 'played', 'playing', 'please', 'plus', 'point', 'points', 'police', 'policy', 'political', 'politicians', 'politics', 'poor', 'pop', 'popular', 'population', 'position', 'positive', 'possibilities', 'possibility', 'possible', 'possibly', 'post', 'potential', 'potentially', 'pounds', 'poverty', 'power', 'powerful', 'practice', 'pre', 'predict', 'prepared', 'present', 'presented', 'president', 'press', 'pressure', 'pretty', 'prevent', 'previous', 'price', 'primary', 'principle', 'principles', 'prison', 'private', 'prize', 'problem', 'problems', 'process', 'processes', 'processing', 'produce', 'produced', 'producing', 'product', 'production', 'products', 'professional', 'professor', 'profound', 'program', 'programs', 'progress', 'project', 'projects', 'promise', 'property', 'protect', 'proud', 'prove', 'provide', 'providing', 'public', 'published', 'pull', 'pulled', 'purpose', 'push', 'put', 'puts', 'putting', 'quality', 'quarter', 'question', 'questions', 'quick', 'quickly', 'quiet', 'quite', 'quote', 'race', 'radical', 'radio', 'rain', 'raise', 'raised', 'ran', 'random', 'range', 'rapidly', 'rare', 'rate', 'rates', 're', 'reach', 'reached', 'reaction', 'read', 'reading', 'ready', 'real', 'reality', 'realize', 'realized', 'really', 'reason', 'reasons', 'received', 'recent', 'recently', 'recognize', 'record', 'records', 'red', 'reduce', 'region', 'regular', 'related', 'relationship', 'relationships', 'relative', 'relatively', 'release', 'released', 'relevant', 'religion', 'religious', 'remain', 'remains', 'remarkable', 'remember', 'remind', 'remote', 'remove', 'replace', 'report', 'represent', 'represents', 'require', 'required', 'requires', 'research', 'researchers', 'resource', 'resources', 'respect', 'respond', 'response', 'responsibility', 'responsible', 'rest', 'result', 'results', 'return', 'revolution', 'rich', 'rid', 'ride', 'right', 'rights', 'rise', 'risk', 'risks', 'river', 'road', 'rock', 'role', 'roll', 'room', 'roughly', 'round', 'rule', 'rules', 'run', 'running', 'runs', 'rural', 'sad', 'safe', 'safety', 'said', 'san', 'sat', 'save', 'saved', 'saving', 'saw', 'say', 'saying', 'says', 'scale', 'scared', 'scene', 'school', 'schools', 'science', 'scientific', 'scientist', 'scientists', 'screen', 'sea', 'search', 'second', 'seconds', 'secret', 'security', 'see', 'seeing', 'seen', 'sees', 'self', 'sell', 'selling', 'send', 'sending', 'sense', 'sensitive', 'sent', 'sentence', 'separate', 'series', 'serious', 'seriously', 'serve', 'service', 'services', 'sets', 'setting', 'seven', 'severe', 'sex', 'shape', 'shapes', 'share', 'shared', 'sharing', 'shift', 'shoes', 'short', 'shot', 'show', 'showed', 'showing', 'shown', 'shows', 'sick', 'side', 'sides', 'sign', 'signal', 'significant', 'simple', 'simply', 'single', 'sister', 'sit', 'site', 'sitting', 'situation', 'situations', 'six', 'size', 'skills', 'skin', 'sky', 'sleep', 'slide', 'slightly', 'slow', 'slowly', 'small', 'smaller', 'smart', 'social', 'societies', 'society', 'software', 'solar', 'sold', 'solution', 'solutions', 'solve', 'somebody', 'son', 'song', 'soon', 'sophisticated', 'sorry', 'sort', 'sorts', 'soul', 'sound', 'sounds', 'source', 'sources', 'south', 'southern', 'space', 'spaces', 'speak', 'speaking', 'special', 'species', 'specific', 'specifically', 'speech', 'speed', 'spend', 'spending', 'spent', 'spirit', 'spoke', 'spot', 'spread', 'spring', 'square', 'st', 'stage', 'stand', 'standard', 'standing', 'stands', 'star', 'stars', 'start', 'started', 'starting', 'starts', 'state', 'states', 'station', 'statistics', 'status', 'stay', 'stayed', 'step', 'steps', 'stick', 'stood', 'stop', 'stopped', 'store', 'stories', 'story', 'straight', 'strange', 'strategy', 'street', 'streets', 'strength', 'strong', 'struck', 'structure', 'structures', 'struggle', 'stuck', 'student', 'students', 'studied', 'studies', 'study', 'studying', 'stuff', 'stupid', 'sub', 'subject', 'success', 'successful', 'sudden', 'suddenly', 'suffering', 'suggest', 'sum', 'summer', 'sun', 'super', 'supply', 'support', 'suppose', 'supposed', 'sure', 'surface', 'surprise', 'surprised', 'surprising', 'surrounded', 'survival', 'survive', 'sustainable', 'system', 'systems', 'table', 'take', 'taken', 'takes', 'taking', 'talk', 'talked', 'talking', 'talks', 'target', 'task', 'taught', 'teach', 'teacher', 'teachers', 'teaching', 'team', 'tech', 'technical', 'techniques', 'technologies', 'technology', 'ted', 'television', 'tell', 'telling', 'tells', 'temperature', 'ten', 'tend', 'tens', 'term', 'terms', 'terrible', 'test', 'tested', 'testing', 'text', 'th', 'thank', 'thanks', 'theory', 'thing', 'things', 'think', 'thinking', 'thinks', 'third', 'thought', 'thoughts', 'thousand', 'thousands', 'threat', 'three', 'throw', 'time', 'times', 'tiny', 'today', 'told', 'tomorrow', 'tons', 'tool', 'tools', 'top', 'topic', 'total', 'totally', 'touch', 'tough', 'town', 'track', 'trade', 'traditional', 'traffic', 'train', 'trained', 'training', 'transform', 'transformed', 'travel', 'traveling', 'treat', 'treated', 'treatment', 'tree', 'trees', 'tremendous', 'trial', 'trick', 'tried', 'trip', 'trouble', 'true', 'truly', 'trust', 'truth', 'try', 'trying', 'turn', 'turned', 'turning', 'turns', 'tv', 'twice', 'two', 'type', 'types', 'typical', 'typically', 'uk', 'ultimate', 'ultimately', 'un', 'underneath', 'understand', 'understanding', 'understood', 'unfortunately', 'unique', 'unit', 'united', 'universal', 'universe', 'university', 'unusual', 'urban', 'useful', 'user', 'uses', 'valley', 'valuable', 'value', 'values', 'variety', 'vast', 've', 'version', 'versus', 'video', 'videos', 'view', 'village', 'violence', 'visible', 'vision', 'visit', 'visual', 'voice', 'vulnerable', 'wait', 'waiting', 'wake', 'walk', 'walked', 'walking', 'wall', 'walls', 'wanted', 'wants', 'war', 'warm', 'wars', 'washington', 'waste', 'watch', 'watched', 'watching', 'water', 'wave', 'ways', 'wealth', 'wear', 'wearing', 'weather', 'web', 'website', 'week', 'weeks', 'weight', 'weird', 'welcome', 'went', 'west', 'western', 'white', 'who', 'wide', 'wife', 'wild', 'willing', 'win', 'wind', 'window', 'windows', 'wisdom', 'wish', 'woman', 'women', 'won', 'wonder', 'wondered', 'wonderful', 'wondering', 'word', 'words', 'work', 'worked', 'workers', 'working', 'works', 'world', 'worldwide', 'worried', 'worry', 'worse', 'worst', 'worth', 'wow', 'write', 'writing', 'written', 'wrong', 'wrote', 'yeah', 'year', 'years', 'yellow', 'yesterday', 'york', 'young', 'zero']\n"
     ]
    }
   ],
   "source": [
    "dtm = tfidf.toarray()\n",
    "doctopic = nmf.fit_transform(dtm) # This is an array\n",
    "features = vectorizer.get_feature_names()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, array([ 0.09649451,  0.26610491,  0.01969957, ...,  0.06762911,\n",
      "        0.03002588,  0.05054642]))\n",
      "(1, array([ 0.01384376,  0.0183957 ,  0.00184777, ...,  0.        ,\n",
      "        0.0659959 ,  0.04044354]))\n",
      "(2, array([ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "        0.09000064,  0.        ]))\n",
      "(3, array([ 0.0429543 ,  0.03445525,  0.        , ...,  0.        ,\n",
      "        0.        ,  0.        ]))\n",
      "(4, array([ 0.        ,  0.02390597,  0.        , ...,  0.        ,\n",
      "        0.        ,  0.        ]))\n",
      "(5, array([ 0.        ,  0.        ,  0.        , ...,  0.01543017,\n",
      "        0.        ,  0.        ]))\n",
      "(6, array([ 0.       ,  0.       ,  0.       , ...,  0.       ,  0.0261301,  0.       ]))\n",
      "(7, array([ 0.        ,  0.00600779,  0.        , ...,  0.        ,\n",
      "        0.        ,  0.        ]))\n",
      "(8, array([ 0.,  0.,  0., ...,  0.,  0.,  0.]))\n",
      "(9, array([ 0.,  0.,  0., ...,  0.,  0.,  0.]))\n",
      "(10, array([ 0.        ,  0.00872869,  0.        , ...,  0.        ,\n",
      "        0.        ,  0.        ]))\n",
      "(11, array([ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "        0.03528347,  0.        ]))\n",
      "(12, array([ 0.,  0.,  0., ...,  0.,  0.,  0.]))\n",
      "(13, array([ 0.,  0.,  0., ...,  0.,  0.,  0.]))\n",
      "(14, array([ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "        0.        ,  0.02751185]))\n",
      "(15, array([ 0.,  0.,  0., ...,  0.,  0.,  0.]))\n",
      "(16, array([ 0.        ,  0.        ,  0.        , ...,  0.26667202,\n",
      "        0.01810485,  0.        ]))\n",
      "(17, array([ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "        0.01635792,  0.        ]))\n",
      "(18, array([ 0.,  0.,  0., ...,  0.,  0.,  0.]))\n",
      "(19, array([ 0.,  0.,  0., ...,  0.,  0.,  0.]))\n",
      "(20, array([  1.82581257e-04,   0.00000000e+00,   1.90140189e-02, ...,\n",
      "         8.66049983e-02,   2.34868662e-01,   0.00000000e+00]))\n",
      "(21, array([ 0.,  0.,  0., ...,  0.,  0.,  0.]))\n",
      "(22, array([ 0.       ,  0.       ,  0.       , ...,  0.0288309,  0.       ,  0.       ]))\n",
      "(23, array([ 0.,  0.,  0., ...,  0.,  0.,  0.]))\n",
      "(24, array([ 0.       ,  0.       ,  0.       , ...,  0.       ,  0.0338721,  0.       ]))\n",
      "(25, array([ 0.        ,  0.04833765,  0.        , ...,  0.        ,\n",
      "        0.        ,  0.        ]))\n",
      "(26, array([ 0.        ,  0.00452563,  0.        , ...,  0.        ,\n",
      "        0.        ,  0.        ]))\n",
      "(27, array([ 0.        ,  0.00604221,  0.        , ...,  0.        ,\n",
      "        0.00719332,  0.        ]))\n",
      "(28, array([ 0.,  0.,  0., ...,  0.,  0.,  0.]))\n",
      "(29, array([ 0.,  0.,  0., ...,  0.,  0.,  0.]))\n",
      "(30, array([ 0.,  0.,  0., ...,  0.,  0.,  0.]))\n",
      "(31, array([ 0.        ,  0.02880508,  0.        , ...,  0.        ,\n",
      "        0.        ,  0.        ]))\n",
      "(32, array([ 0.,  0.,  0., ...,  0.,  0.,  0.]))\n",
      "(33, array([ 0.,  0.,  0., ...,  0.,  0.,  0.]))\n",
      "(34, array([ 0.,  0.,  0., ...,  0.,  0.,  0.]))\n",
      "(35, array([ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "        0.        ,  0.03614844]))\n",
      "(36, array([ 0.,  0.,  0., ...,  0.,  0.,  0.]))\n",
      "(37, array([ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "        0.        ,  0.00068105]))\n",
      "(38, array([ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "        0.        ,  0.04426714]))\n",
      "(39, array([ 0.        ,  0.        ,  0.        , ...,  0.02342642,\n",
      "        0.        ,  0.        ]))\n"
     ]
    }
   ],
   "source": [
    "for topicidx in enumerate(nmf.components_):\n",
    "    print(topicidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=\n",
    "# Saving output to CSV\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Since DOCTOPIC is an array, you can just do:\n",
    "#      np.savetxt(\"foo.csv\", doctopic, delimiter=\",\", fmt = \"%s\")\n",
    "# http://stackoverflow.com/questions/6081008/dump-a-numpy-array-into-a-csv-file\n",
    "#\n",
    "# The above won't give you the names of the files. Instead try this:\n",
    "\n",
    "topsnum = np.array([list(range(n_topics))])\n",
    "# topsnum = np.indices((1,n_topics))[1] <-- this is more than we need,\n",
    "#                                           but it's cool to know more tricks\n",
    "#\n",
    "# Two ways to get an array that is of the form [[0,1,2,3,...]].\n",
    "# It will have the desired dimensions of (1,35) which is what we want\n",
    "\n",
    "fileheader = np.concatenate((np.array([[\"citations\"]]), topsnum),axis = 1)\n",
    "authordate = np.array([df.author])\n",
    "\n",
    "docTopics = np.concatenate((authordate.T, doctopic), axis = 1)\n",
    "docTopics = np.concatenate((fileheader, docTopics), axis = 0)\n",
    "\n",
    "np.savetxt(\"../data/nmf_topics_raw.csv\", doctopic, delimiter=\",\", fmt = \"%s\")\n",
    "#np.savetxt(\"../data/nmf_topics.csv\", docTopics, delimiter=\",\", fmt = \"%s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
