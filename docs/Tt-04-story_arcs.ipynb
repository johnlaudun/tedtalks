{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Data Load & Tokenize\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "import pandas\n",
    "import re\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "# LOAD\n",
    "colnames = ['author', 'title', 'date' , 'length', 'text']\n",
    "df = pandas.read_csv('../data/talks_3.csv', names=colnames)\n",
    "talks = df.text.tolist()\n",
    "authors = df.author.tolist()\n",
    "dates = df.date.tolist()\n",
    "years = [re.sub('[A-Za-z ]', '', item) for item in dates]\n",
    "authordate = [author+\" \"+year for author, year in zip(authors, years)]\n",
    "\n",
    "# TOKENIZE\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "texts = []\n",
    "for talk in talks:   \n",
    "    raw = re.sub(r\"[^\\w\\d'\\s]+\",'', talk).lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    texts.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Small Test Corpus\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "test = texts[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Function to collect word positions within a text (as a word list)\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "def word_positions(listname):\n",
    "    from collections import defaultdict\n",
    "    words_with_positions = defaultdict(list)\n",
    "    for position, word in enumerate(listname):\n",
    "        words_with_positions[word].append(float(position)/len(listname))\n",
    "    return(words_with_positions)\n",
    "\n",
    "# word_positions(texts[0]) # check output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Develop \"super dictionary\" of all the texts involved\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "super_dict = {}\n",
    "for text in test:\n",
    "    temp_dict = word_positions(text)\n",
    "    for k, v in temp_dict.items():\n",
    "        if super_dict.get(k) is None:\n",
    "            super_dict[k] = []\n",
    "        if v not in super_dict.get(k):\n",
    "            # Possibly problematic for larger data sets\n",
    "            super_dict[k] = super_dict[k] + v\n",
    "            \n",
    "# print(super_dict) # check output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.017037387600567912,\n",
       " 0.9966871746332229,\n",
       " 0.044716692189892805,\n",
       " 0.4214395099540582,\n",
       " 0.5565084226646249,\n",
       " 0.7650842266462481,\n",
       " 0.9191424196018376,\n",
       " 0.9978560490045941,\n",
       " 0.9994391475042064,\n",
       " 0.373067191453472,\n",
       " 0.5780151813325837,\n",
       " 0.7880236154062412,\n",
       " 0.8538093899353387,\n",
       " 0.9994377284228282,\n",
       " 0.9969465648854962]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_dict[\"thank\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*global* occurs 7 times in the corpus, with an average position of 0.6342322621960647.\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "word = \"global\"\n",
    "\n",
    "print(\"*\" + word + \"* occurs \" + str(len(super_dict[word])) + \n",
    "      \" times in the corpus, with an average position of \" + \n",
    "      str(statistics.mean(super_dict[word])) + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pandas.DataFrame()\n",
    "df['word'] = super_dict.keys()\n",
    "df['positions'] = super_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>positions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>isn't</td>\n",
       "      <td>[0.20162647223780145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meanwhile</td>\n",
       "      <td>[0.7053435114503817]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>approtec</td>\n",
       "      <td>[0.2544278886702277]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>waitress</td>\n",
       "      <td>[0.11878845243729295]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>microsystems</td>\n",
       "      <td>[0.5344924284913067]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>even</td>\n",
       "      <td>[0.636447166921899, 0.10120888389091931, 0.284...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>more</td>\n",
       "      <td>[0.3076194983435873, 0.3795551348793185, 0.391...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>typed</td>\n",
       "      <td>[0.2447166921898928]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nashville</td>\n",
       "      <td>[0.06483672503549456, 0.06956933270231898, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>shuttle</td>\n",
       "      <td>[0.5332312404287902]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word                                          positions\n",
       "0         isn't                              [0.20162647223780145]\n",
       "1     meanwhile                               [0.7053435114503817]\n",
       "2      approtec                               [0.2544278886702277]\n",
       "3      waitress                              [0.11878845243729295]\n",
       "4  microsystems                               [0.5344924284913067]\n",
       "5          even  [0.636447166921899, 0.10120888389091931, 0.284...\n",
       "6          more  [0.3076194983435873, 0.3795551348793185, 0.391...\n",
       "7         typed                               [0.2447166921898928]\n",
       "8     nashville  [0.06483672503549456, 0.06956933270231898, 0.1...\n",
       "9       shuttle                               [0.5332312404287902]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2329"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['positions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-287e817add9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'positions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/john/Library/Python/3.4/lib/python/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m         \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m         \u001b[0mscl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/john/Library/Python/3.4/lib/python/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "# I need two additional columns: \n",
    "# one for mean, one for counting the number of items in a list\n",
    "\n",
    "import numpy\n",
    "\n",
    "df.apply(numpy.average(df['positions']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
