{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\n",
    "# =-=-=-=-=-=\n",
    "# Consolidated imports for entire notebook\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "import pandas\n",
    "import re\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import *\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "\n",
    "# =-=-=-=-=-=\n",
    "# Read CSV into DataFrame and then create lists\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "# Create pandas dataframe & lists\n",
    "colnames = ['author', 'title', 'date' , 'length', 'text']\n",
    "df = pandas.read_csv('../data/talks_2.csv', names=colnames)\n",
    "talks = df.text.tolist()\n",
    "authors = df.author.tolist()\n",
    "dates = df.date.tolist()\n",
    "\n",
    "# Get years from date list and combing with author list for labels\n",
    "years = [re.sub('[A-Za-z ]', '', item) for item in dates]\n",
    "authordate = [author+\" \"+year for author, year in zip(authors, years)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=\n",
    "# Clean and Tokenize, then Drop Stopwords\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "# Load tokenizer, stopwords, and stemmer\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "stopwords = re.split('\\s+', open('../data/tt_stop.txt', 'r').read().lower())\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "# Loop to tokenize, stop, and stem (if needed) texts.\n",
    "texts = []\n",
    "for i in talks:   \n",
    "    # clean and tokenize document string\n",
    "    raw = re.sub(r\"[^\\w\\d'\\s]+\",'', i).lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [i for i in tokens if not i in stopwords]\n",
    "    # stem tokens\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    # add tokens to list\n",
    "    texts.append(stemmed_tokens)\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Re-Assemble Texts as Strings from Lists of Words\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "strungs = []\n",
    "for text in texts:\n",
    "    strung = ' '.join(text)\n",
    "    strungs.append(strung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model with 35 topics for 2092 documents with 1000 features.\n"
     ]
    }
   ],
   "source": [
    "# =-=-=-=-=-=\n",
    "# Get NMF topics\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "\n",
    "# All our variables are here to make it easier to make adjustments\n",
    "data_set = talks # or talks\n",
    "n_samples = len(data_set)\n",
    "n_features = 1000\n",
    "n_topics = 35\n",
    "n_top_words = 15\n",
    "# tt_stopwords = open('../data/stopwords_tt.txt', 'r').read().splitlines()\n",
    "\n",
    "# Get tf-idf features for NMF\n",
    "vectorizer = sk_text.TfidfVectorizer(max_df = 0.90,\n",
    "                                        min_df = 0.01,\n",
    "                                        max_features = n_features)\n",
    "tfidf = vectorizer.fit_transform(data_set)\n",
    "\n",
    "# Fit the NMF model\n",
    "nmf = NMF(n_components = n_topics,\n",
    "          random_state = 1,\n",
    "          alpha = 0.1,\n",
    "          l1_ratio = 0.5).fit(tfidf)\n",
    "print(\"Fitting the NMF model with {} topics for {} documents with {} features.\"\n",
    "      .format(n_topics, n_samples, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics in NMF model:\n",
      "\n",
      "Topic 0:\n",
      "very 0.88, actually 0.83, see 0.75, which 0.71, really 0.64, here 0.64, re 0.64, then 0.51, some 0.51, think 0.49, into 0.48, things 0.47, way 0.44, different 0.43, would 0.43, \n",
      "\n",
      "Topic 1:\n",
      "he 3.77, his 1.63, him 1.01, said 0.4, who 0.27, man 0.26, guy 0.24, father 0.18, had 0.15, story 0.14, says 0.14, know 0.12, did 0.1, face 0.09, god 0.08, \n",
      "\n",
      "Topic 2:\n",
      "women 2.69, men 1.09, woman 0.41, sex 0.27, who 0.18, violence 0.16, their 0.1, girls 0.1, rights 0.09, stories 0.09, man 0.08, were 0.08, media 0.08, country 0.08, young 0.07, \n",
      "\n",
      "Topic 3:\n",
      "she 3.25, her 2.29, said 0.23, mother 0.22, girl 0.22, woman 0.2, women 0.13, who 0.12, mom 0.11, know 0.09, old 0.08, little 0.08, don 0.08, met 0.08, baby 0.07, \n",
      "\n",
      "Topic 4:\n",
      "water 2.7, into 0.16, surface 0.12, use 0.1, ve 0.09, air 0.09, plant 0.09, environment 0.09, india 0.09, material 0.07, green 0.07, south 0.06, re 0.06, here 0.06, produce 0.06, \n",
      "\n",
      "Topic 5:\n",
      "cancer 2.24, disease 0.44, patients 0.44, drug 0.33, patient 0.31, health 0.29, treatment 0.22, blood 0.22, medical 0.21, medicine 0.2, drugs 0.19, body 0.18, doctor 0.18, heart 0.11, care 0.11, \n",
      "\n",
      "Topic 6:\n",
      "brain 2.74, brains 0.36, your 0.34, activity 0.18, body 0.14, memory 0.14, human 0.14, mind 0.12, behavior 0.12, pain 0.11, disease 0.11, control 0.1, study 0.1, visual 0.1, sleep 0.1, \n",
      "\n",
      "Topic 7:\n",
      "me 1.35, had 1.04, were 0.75, would 0.53, life 0.46, who 0.45, said 0.44, day 0.37, their 0.36, could 0.35, no 0.35, myself 0.34, went 0.34, never 0.33, years 0.33, \n",
      "\n",
      "Topic 8:\n",
      "ocean 1.41, fish 1.15, sea 0.77, animals 0.63, species 0.34, deep 0.25, animal 0.23, blue 0.14, water 0.14, re 0.14, down 0.13, land 0.11, areas 0.11, north 0.11, bottom 0.1, \n",
      "\n",
      "Topic 9:\n",
      "data 2.74, information 0.48, map 0.15, health 0.14, web 0.12, patients 0.1, numbers 0.09, see 0.08, look 0.07, hospital 0.07, percent 0.06, every 0.06, google 0.06, rate 0.05, science 0.05, \n",
      "\n",
      "Topic 10:\n",
      "ice 1.64, climate 0.66, sea 0.22, change 0.17, ocean 0.17, feet 0.16, north 0.15, carbon 0.15, global 0.14, south 0.13, years 0.11, year 0.1, planet 0.1, cold 0.09, back 0.08, \n",
      "\n",
      "Topic 11:\n",
      "music 2.31, sound 0.71, play 0.49, hear 0.32, playing 0.25, sounds 0.21, piece 0.2, listen 0.19, video 0.17, me 0.14, voice 0.13, language 0.11, experience 0.09, let 0.06, yeah 0.06, \n",
      "\n",
      "Topic 12:\n",
      "children 2.12, child 0.91, parents 0.35, india 0.31, family 0.27, families 0.24, their 0.23, schools 0.17, english 0.17, mother 0.14, boy 0.14, school 0.13, will 0.11, baby 0.1, language 0.1, \n",
      "\n",
      "Topic 13:\n",
      "chinese 1.4, china 1.25, india 0.3, democracy 0.19, english 0.18, west 0.17, political 0.17, world 0.14, language 0.13, north 0.12, east 0.11, countries 0.1, state 0.09, states 0.09, economic 0.08, \n",
      "\n",
      "Topic 14:\n",
      "universe 2.02, space 0.41, theory 0.36, dark 0.34, light 0.22, billion 0.19, matter 0.17, energy 0.17, big 0.14, science 0.13, see 0.13, mass 0.1, structure 0.1, field 0.1, sun 0.1, \n",
      "\n",
      "Topic 15:\n",
      "robot 1.83, robots 1.19, move 0.09, video 0.08, lab 0.06, its 0.06, animal 0.06, build 0.06, control 0.05, want 0.05, intelligence 0.05, see 0.04, here 0.04, play 0.04, body 0.04, \n",
      "\n",
      "Topic 16:\n",
      "re 1.25, your 1.12, going 1.0, know 0.97, don 0.78, get 0.61, want 0.61, think 0.59, ve 0.53, right 0.51, really 0.5, me 0.48, say 0.47, go 0.44, got 0.43, \n",
      "\n",
      "Topic 17:\n",
      "africa 2.16, african 0.83, countries 0.31, south 0.27, leaders 0.15, here 0.14, world 0.14, country 0.12, very 0.08, market 0.08, east 0.08, has 0.07, percent 0.06, west 0.06, story 0.06, \n",
      "\n",
      "Topic 18:\n",
      "compassion 1.78, god 0.36, love 0.09, world 0.09, has 0.07, human 0.07, zero 0.07, says 0.06, happy 0.06, being 0.06, others 0.06, yourself 0.06, person 0.05, word 0.05, non 0.05, \n",
      "\n",
      "Topic 19:\n",
      "dna 1.95, genes 0.43, species 0.29, code 0.22, cell 0.21, science 0.11, machine 0.1, human 0.07, animals 0.07, years 0.07, program 0.07, technology 0.07, understand 0.07, evolution 0.07, information 0.06, \n",
      "\n",
      "Topic 20:\n",
      "ca 2.09, yeah 0.24, mean 0.19, think 0.12, got 0.08, well 0.06, ted 0.06, yes 0.04, ok 0.03, would 0.03, been 0.03, ve 0.03, amazing 0.03, source 0.03, thank 0.03, \n",
      "\n",
      "Topic 21:\n",
      "city 1.93, cities 1.25, building 0.41, buildings 0.34, space 0.31, new 0.31, york 0.3, map 0.28, public 0.24, street 0.23, site 0.2, built 0.18, community 0.18, places 0.16, build 0.14, \n",
      "\n",
      "Topic 22:\n",
      "car 1.7, cars 1.18, road 0.32, drive 0.27, miles 0.23, cities 0.13, hour 0.1, going 0.1, per 0.1, percent 0.09, cost 0.08, dollars 0.06, stop 0.06, today 0.05, less 0.05, \n",
      "\n",
      "Topic 23:\n",
      "cells 2.21, cell 0.77, drug 0.27, disease 0.27, body 0.26, drugs 0.21, patients 0.2, patient 0.17, blood 0.17, heart 0.17, lab 0.16, skin 0.12, animal 0.12, medicine 0.11, grow 0.11, \n",
      "\n",
      "Topic 24:\n",
      "energy 1.68, oil 1.04, nuclear 0.44, power 0.36, solar 0.34, carbon 0.34, climate 0.3, per 0.2, air 0.17, use 0.17, billion 0.16, percent 0.14, technology 0.13, will 0.13, stuff 0.12, \n",
      "\n",
      "Topic 25:\n",
      "kids 1.33, school 1.06, students 0.98, teachers 0.71, education 0.69, teacher 0.38, learning 0.36, schools 0.32, teach 0.27, class 0.26, student 0.25, their 0.23, learn 0.23, kid 0.21, every 0.14, \n",
      "\n",
      "Topic 26:\n",
      "percent 0.57, world 0.52, their 0.52, countries 0.51, who 0.42, global 0.41, dollars 0.41, country 0.4, government 0.4, money 0.39, will 0.38, has 0.38, social 0.34, need 0.33, economic 0.32, \n",
      "\n",
      "Topic 27:\n",
      "design 2.37, building 0.45, designed 0.28, buildings 0.16, materials 0.16, work 0.14, art 0.14, product 0.14, project 0.12, kind 0.11, process 0.11, beautiful 0.11, new 0.11, technology 0.1, made 0.1, \n",
      "\n",
      "Topic 28:\n",
      "food 1.99, plants 0.7, plant 0.67, eat 0.54, species 0.22, grow 0.15, animals 0.14, growing 0.13, percent 0.13, kids 0.11, land 0.1, local 0.1, genes 0.09, green 0.09, produce 0.08, \n",
      "\n",
      "Topic 29:\n",
      "black 1.81, men 0.6, white 0.43, color 0.14, mass 0.13, light 0.11, young 0.09, history 0.08, african 0.07, american 0.06, guy 0.05, medicine 0.04, see 0.04, than 0.04, some 0.04, \n",
      "\n",
      "Topic 30:\n",
      "internet 1.1, information 0.85, computer 0.69, web 0.58, digital 0.56, technology 0.55, online 0.54, media 0.5, video 0.45, phone 0.39, computers 0.38, software 0.31, machine 0.29, page 0.28, google 0.27, \n",
      "\n",
      "Topic 31:\n",
      "our 2.59, us 0.97, re 0.43, human 0.39, ourselves 0.34, their 0.34, world 0.29, technology 0.26, your 0.25, lives 0.23, own 0.23, life 0.2, reality 0.2, future 0.2, self 0.19, \n",
      "\n",
      "Topic 32:\n",
      "earth 1.4, planet 1.14, solar 0.58, life 0.54, sun 0.51, surface 0.37, space 0.31, light 0.28, system 0.24, years 0.22, will 0.2, our 0.19, billion 0.17, miles 0.17, species 0.17, \n",
      "\n",
      "Topic 33:\n",
      "girls 1.87, girl 0.58, school 0.25, their 0.12, father 0.11, who 0.08, boy 0.07, wish 0.07, every 0.05, research 0.04, games 0.04, community 0.04, parents 0.04, village 0.03, young 0.03, \n",
      "\n",
      "Topic 34:\n",
      "happiness 1.66, happy 0.43, self 0.21, mind 0.21, life 0.16, positive 0.14, experience 0.12, something 0.09, moment 0.07, sex 0.06, your 0.06, less 0.05, think 0.04, present 0.04, than 0.04, \n"
     ]
    }
   ],
   "source": [
    "# =-=-=-=-=-=\n",
    "# Get NMF printing\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_id, topic in enumerate(model.components_):\n",
    "        print('\\nTopic {}:'.format(int(topic_id)))\n",
    "        print(''.join([feature_names[i] + ' ' + str(round(topic[i], 2))\n",
    "              +', ' for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "\n",
    "features = vectorizer.get_feature_names()\n",
    "#print(features)\n",
    "\n",
    "print(\"Topics in NMF model:\")\n",
    "\n",
    "# KK - I get an error here. My python does not recognize tfidf_vectorizer()\n",
    "#tfidf_feature_names = nmf.get_feature_names()\n",
    "# This works now. I added features above. Probably broken by me\n",
    "# not seeing a name change. \n",
    "print_top_words(nmf, features, n_top_words) #n_top_words can be changed on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dtm = tfidf.toarray()\n",
    "doctopic = nmf.fit_transform(dtm) # This is an array\n",
    "\n",
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for topicidx in enumerate(nmf.components_):\n",
    "    print(topicidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=\n",
    "# Saving output to CSV\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "# Since DOCTOPIC is an array, you can just do:\n",
    "#      np.savetxt(\"foo.csv\", doctopic, delimiter=\",\", fmt = \"%s\")\n",
    "# http://stackoverflow.com/questions/6081008/dump-a-numpy-array-into-a-csv-file\n",
    "#\n",
    "# The above won't give you the names of the files. Instead try this:\n",
    "\n",
    "topsnum = np.array([list(range(n_topics))])\n",
    "# topsnum = np.indices((1,n_topics))[1] <-- this is more than we need,\n",
    "#                                           but it's cool to know more tricks\n",
    "#\n",
    "# Two ways to get an array that is of the form [[0,1,2,3,...]].\n",
    "# It will have the desired dimensions of (1,35) which is what we want\n",
    "\n",
    "fileheader = np.concatenate((np.array([[\"citations\"]]), topsnum),axis = 1)\n",
    "authordate = np.array([df.author])\n",
    "\n",
    "docTopics = np.concatenate((authordate.T, doctopic), axis = 1)\n",
    "docTopics = np.concatenate((fileheader, docTopics), axis = 0)\n",
    "\n",
    "np.savetxt(\"../data/dt_KK_test.csv\", doctopic, delimiter=\",\", fmt = \"%s\")\n",
    "#np.savetxt(\"../data/nmf_topics.csv\", docTopics, delimiter=\",\", fmt = \"%s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
