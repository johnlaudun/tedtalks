{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEDtalks: Topics with LDA\n",
    "\n",
    "# =-=-=-=-=-=\n",
    "# Read CSV into DataFrame and then create lists\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "import pandas\n",
    "import re\n",
    "\n",
    "# Create pandas dataframe\n",
    "colnames = ['author', 'title', 'date' , 'length', 'text']\n",
    "df = pandas.read_csv('../data/talks_2.csv', names=colnames)\n",
    "\n",
    "# Create lists for the data\n",
    "talks = df.text.tolist()\n",
    "authors = df.author.tolist()\n",
    "dates = df.date.tolist()\n",
    "\n",
    "# Getting only the years from dates list\n",
    "years = [re.sub('[A-Za-z ]', '', item) for item in dates]\n",
    "\n",
    "# Combining year with presenter for citation\n",
    "authordate = [author+\" \"+year for author, year in zip(authors, years)]\n",
    "\n",
    "# Just to check to see if things are synced,\n",
    "# let's create a new df with the two lists.\n",
    "\n",
    "cited_texts = pandas.DataFrame(\n",
    "    {'citation': authordate,\n",
    "     'text': talks,\n",
    "    })\n",
    "\n",
    "# This just shows that the citation and the text are paired correctly.\n",
    "# cited_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=\n",
    "# Clean and Tokenize, then Drop Stopwords\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "# Documentation: https://pypi.python.org/pypi/lda\n",
    "# LDA requires a DTM as input\n",
    "\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "# From the Stopwords Notebook:\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "stopwords = re.split('\\s+', open('../data/tt_stop.txt', 'r').read().lower())\n",
    "\n",
    "# Test Strings\n",
    "doc_a = \"You can call me Al.\"\n",
    "doc_b = \"I can call you Betty.\"\n",
    "doc_c = \"Who'll be my role model?\"\n",
    "\n",
    "doc_set = [doc_a, doc_b, doc_c] # Test list of strings\n",
    "\n",
    "# List for loop\n",
    "texts = []\n",
    "\n",
    "# loop through document list\n",
    "for i in talks:\n",
    "    \n",
    "    # clean and tokenize document string\n",
    "    raw = re.sub(r\"[^\\w\\d'\\s]+\",'', i).lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [i for i in tokens if not i in stopwords]\n",
    "    \n",
    "    # stem tokens\n",
    "    # stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    \n",
    "    # add tokens to list\n",
    "    texts.append(stopped_tokens)\n",
    "\n",
    "# print(texts[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=\n",
    "# Generate LDA Model\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "\n",
    "# from gensim import corpora, models >>> Test to see if needed\n",
    "import gensim\n",
    "\n",
    "# turn our tokenized documents into a id <-> term dictionary\n",
    "dictionary = gensim.corpora.Dictionary(texts)\n",
    "    \n",
    "# convert tokenized documents into a document-term matrix\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# print(corpus[0:3]) # to see the corpus\n",
    "\n",
    "# generate LDA model\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, \n",
    "                                           num_topics=35, \n",
    "                                           id2word = dictionary, \n",
    "                                           passes=100)\n",
    "\n",
    "#save the model\n",
    "#ldamodel.save('../data/lda.model')\n",
    "\n",
    "# for later: load trained model from file\n",
    "#model =  models.LdaModel.load('lda.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=\n",
    "# Printing Options\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "\n",
    "# Prints all topics. Format T = words, Format F = ids\n",
    "print(ldamodel.show_topics(num_topics=25, num_words=10, formatted=True))\n",
    "\n",
    "# Same as above but working through list in for loop\n",
    "for i in range(0, ldamodel.num_topics):\n",
    "    print(ldamodel.print_topic(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019*like + 0.013*actually + 0.012*brain + 0.010*just + 0.010*cells + 0.010*think + 0.009*babies + 0.008*children + 0.008*see + 0.007*two\n",
      "[('like', 0.018872414487262068), ('actually', 0.012801400450384949), ('brain', 0.012249001649413069), ('just', 0.0099968190527590477), ('cells', 0.0098472656722105659), ('think', 0.0096294033856906165), ('babies', 0.0091951516720024887), ('children', 0.0082945751438348765), ('see', 0.0078378135797309845), ('two', 0.0073985921731832063)]\n"
     ]
    }
   ],
   "source": [
    "print('{}'.format(ldamodel.print_topic(3)) + '\\n' + '{}'.format(ldamodel.show_topic(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0, 0.013*people + 0.010*going + 0.007*percent + 0.007*need + 0.007*years + 0.007*food + 0.007*really + 0.007*world + 0.006*like + 0.006*get\n",
      "topic 1, 0.040*india + 0.032*china + 0.031*country + 0.025*growth + 0.024*economic + 0.016*countries + 0.012*two + 0.011*terms + 0.010*indian + 0.010*political\n",
      "topic 2, 0.032*game + 0.024*games + 0.010*re + 0.010*play + 0.009*vaccine + 0.009*video + 0.008*virus + 0.007*t + 0.007*m + 0.007*higgs\n",
      "topic 3, 0.019*like + 0.013*actually + 0.012*brain + 0.010*just + 0.010*cells + 0.010*think + 0.009*babies + 0.008*children + 0.008*see + 0.007*two\n",
      "topic 4, 0.005*envisions + 0.004*pigeon + 0.004*passenger + 0.004*adam + 0.002*mania + 0.001*sin + 0.001*tailed + 0.001*adrianne + 0.001*pigeons + 0.001*manias\n",
      "topic 5, 0.011*like + 0.011*actually + 0.009*just + 0.008*see + 0.008*really + 0.007*plant + 0.007*species + 0.007*get + 0.007*know + 0.007*looking\n",
      "topic 6, 0.012*grownup + 0.008*copyright + 0.006*iran + 0.006*nike + 0.005*awesome + 0.005*fashion + 0.005*sneakers + 0.005*protocell + 0.004*alison + 0.004*berkley\n",
      "topic 7, 0.010*world + 0.009*know + 0.009*think + 0.009*just + 0.008*weapons + 0.007*great + 0.006*america + 0.006*institutions + 0.006*west + 0.006*people\n",
      "topic 8, 0.009*bread + 0.009*stress + 0.008*black + 0.006*dolphins + 0.006*hole + 0.006*oxytocin + 0.005*dog + 0.005*pi + 0.005*dolphin + 0.004*freckles\n",
      "topic 9, 0.008*like + 0.008*going + 0.007*really + 0.007*see + 0.006*know + 0.006*data + 0.006*just + 0.006*think + 0.006*actually + 0.005*life\n",
      "topic 10, 0.012*said + 0.010*africa + 0.010*people + 0.009*world + 0.008*women + 0.008*years + 0.007*went + 0.007*like + 0.006*body + 0.006*humans\n",
      "topic 11, 0.009*people + 0.008*just + 0.006*world + 0.006*really + 0.006*know + 0.006*going + 0.006*time + 0.005*years + 0.005*like + 0.005*make\n",
      "topic 12, 0.011*like + 0.007*people + 0.007*years + 0.006*just + 0.006*really + 0.006*actually + 0.006*know + 0.006*script + 0.005*space + 0.005*make\n",
      "topic 13, 0.012*going + 0.012*just + 0.011*see + 0.011*like + 0.011*know + 0.010*go + 0.009*got + 0.009*get + 0.009*said + 0.008*time\n",
      "topic 14, 0.041*cancer + 0.013*devil + 0.012*tasmanian + 0.012*disease + 0.012*people + 0.011*cells + 0.010*body + 0.010*like + 0.009*tumor + 0.008*fact\n",
      "topic 15, 0.007*think + 0.006*said + 0.006*say + 0.006*like + 0.006*people + 0.006*problem + 0.005*understand + 0.005*wrong + 0.005*right + 0.005*trial\n",
      "topic 16, 0.011*people + 0.011*fish + 0.010*life + 0.010*know + 0.007*back + 0.007*time + 0.007*say + 0.007*story + 0.007*john + 0.006*just\n",
      "topic 17, 0.012*political + 0.011*democracy + 0.009*democratic + 0.008*societies + 0.007*peace + 0.007*age + 0.007*culture + 0.007*people + 0.007*power + 0.006*leaders\n",
      "topic 18, 0.010*just + 0.010*like + 0.008*time + 0.007*think + 0.006*see + 0.006*little + 0.006*get + 0.006*people + 0.006*music + 0.006*going\n",
      "topic 19, 0.011*ca + 0.009*organs + 0.008*rb + 0.007*flies + 0.006*dopamine + 0.006*voice + 0.005*organ + 0.005*neurons + 0.005*malaria + 0.005*liver\n",
      "topic 20, 0.016*god + 0.011*women + 0.011*people + 0.010*self + 0.007*world + 0.007*just + 0.007*know + 0.007*compassion + 0.006*men + 0.006*life\n",
      "topic 21, 0.025*octavio + 0.024*ballistics + 0.010*gay + 0.003*agenda + 0.003*lifestyle + 0.002*aquatic + 0.002*mogadishu + 0.002*bisexual + 0.002*carbs + 0.002*lesbian\n",
      "topic 22, 0.010*people + 0.010*going + 0.009*think + 0.007*really + 0.007*life + 0.007*like + 0.006*look + 0.006*just + 0.005*say + 0.005*know\n",
      "topic 23, 0.010*like + 0.010*just + 0.010*play + 0.007*actually + 0.007*going + 0.006*people + 0.006*think + 0.006*world + 0.006*internet + 0.006*see\n",
      "topic 24, 0.017*people + 0.012*new + 0.010*like + 0.008*city + 0.008*school + 0.007*work + 0.007*get + 0.007*think + 0.006*idea + 0.006*things\n"
     ]
    }
   ],
   "source": [
    "for t in range(0, ldamodel.num_topics):\n",
    "    print('topic {}, {}'.format(t, ldamodel.print_topic(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.013*people + 0.010*going + 0.007*percent + 0.007*need + 0.007*years + 0.007*food + 0.007*really + 0.007*world + 0.006*like + 0.006*get'),\n",
       " (1,\n",
       "  '0.040*india + 0.032*china + 0.031*country + 0.025*growth + 0.024*economic + 0.016*countries + 0.012*two + 0.011*terms + 0.010*indian + 0.010*political'),\n",
       " (2,\n",
       "  '0.032*game + 0.024*games + 0.010*re + 0.010*play + 0.009*vaccine + 0.009*video + 0.008*virus + 0.007*t + 0.007*m + 0.007*higgs'),\n",
       " (3,\n",
       "  '0.019*like + 0.013*actually + 0.012*brain + 0.010*just + 0.010*cells + 0.010*think + 0.009*babies + 0.008*children + 0.008*see + 0.007*two'),\n",
       " (4,\n",
       "  '0.005*envisions + 0.004*pigeon + 0.004*passenger + 0.004*adam + 0.002*mania + 0.001*sin + 0.001*tailed + 0.001*adrianne + 0.001*pigeons + 0.001*manias'),\n",
       " (5,\n",
       "  '0.011*like + 0.011*actually + 0.009*just + 0.008*see + 0.008*really + 0.007*plant + 0.007*species + 0.007*get + 0.007*know + 0.007*looking'),\n",
       " (6,\n",
       "  '0.012*grownup + 0.008*copyright + 0.006*iran + 0.006*nike + 0.005*awesome + 0.005*fashion + 0.005*sneakers + 0.005*protocell + 0.004*alison + 0.004*berkley'),\n",
       " (7,\n",
       "  '0.010*world + 0.009*know + 0.009*think + 0.009*just + 0.008*weapons + 0.007*great + 0.006*america + 0.006*institutions + 0.006*west + 0.006*people'),\n",
       " (8,\n",
       "  '0.009*bread + 0.009*stress + 0.008*black + 0.006*dolphins + 0.006*hole + 0.006*oxytocin + 0.005*dog + 0.005*pi + 0.005*dolphin + 0.004*freckles'),\n",
       " (9,\n",
       "  '0.008*like + 0.008*going + 0.007*really + 0.007*see + 0.006*know + 0.006*data + 0.006*just + 0.006*think + 0.006*actually + 0.005*life'),\n",
       " (10,\n",
       "  '0.012*said + 0.010*africa + 0.010*people + 0.009*world + 0.008*women + 0.008*years + 0.007*went + 0.007*like + 0.006*body + 0.006*humans'),\n",
       " (11,\n",
       "  '0.009*people + 0.008*just + 0.006*world + 0.006*really + 0.006*know + 0.006*going + 0.006*time + 0.005*years + 0.005*like + 0.005*make'),\n",
       " (12,\n",
       "  '0.011*like + 0.007*people + 0.007*years + 0.006*just + 0.006*really + 0.006*actually + 0.006*know + 0.006*script + 0.005*space + 0.005*make'),\n",
       " (13,\n",
       "  '0.012*going + 0.012*just + 0.011*see + 0.011*like + 0.011*know + 0.010*go + 0.009*got + 0.009*get + 0.009*said + 0.008*time'),\n",
       " (14,\n",
       "  '0.041*cancer + 0.013*devil + 0.012*tasmanian + 0.012*disease + 0.012*people + 0.011*cells + 0.010*body + 0.010*like + 0.009*tumor + 0.008*fact'),\n",
       " (15,\n",
       "  '0.007*think + 0.006*said + 0.006*say + 0.006*like + 0.006*people + 0.006*problem + 0.005*understand + 0.005*wrong + 0.005*right + 0.005*trial'),\n",
       " (16,\n",
       "  '0.011*people + 0.011*fish + 0.010*life + 0.010*know + 0.007*back + 0.007*time + 0.007*say + 0.007*story + 0.007*john + 0.006*just'),\n",
       " (17,\n",
       "  '0.012*political + 0.011*democracy + 0.009*democratic + 0.008*societies + 0.007*peace + 0.007*age + 0.007*culture + 0.007*people + 0.007*power + 0.006*leaders'),\n",
       " (18,\n",
       "  '0.010*just + 0.010*like + 0.008*time + 0.007*think + 0.006*see + 0.006*little + 0.006*get + 0.006*people + 0.006*music + 0.006*going'),\n",
       " (19,\n",
       "  '0.011*ca + 0.009*organs + 0.008*rb + 0.007*flies + 0.006*dopamine + 0.006*voice + 0.005*organ + 0.005*neurons + 0.005*malaria + 0.005*liver'),\n",
       " (20,\n",
       "  '0.016*god + 0.011*women + 0.011*people + 0.010*self + 0.007*world + 0.007*just + 0.007*know + 0.007*compassion + 0.006*men + 0.006*life'),\n",
       " (21,\n",
       "  '0.025*octavio + 0.024*ballistics + 0.010*gay + 0.003*agenda + 0.003*lifestyle + 0.002*aquatic + 0.002*mogadishu + 0.002*bisexual + 0.002*carbs + 0.002*lesbian'),\n",
       " (22,\n",
       "  '0.010*people + 0.010*going + 0.009*think + 0.007*really + 0.007*life + 0.007*like + 0.006*look + 0.006*just + 0.005*say + 0.005*know'),\n",
       " (23,\n",
       "  '0.010*like + 0.010*just + 0.010*play + 0.007*actually + 0.007*going + 0.006*people + 0.006*think + 0.006*world + 0.006*internet + 0.006*see'),\n",
       " (24,\n",
       "  '0.017*people + 0.012*new + 0.010*like + 0.008*city + 0.008*school + 0.007*work + 0.007*get + 0.007*think + 0.006*idea + 0.006*things')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.print_topics(25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
