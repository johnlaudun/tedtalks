{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the central concerns of our work from the beginning has been getting the matter of *words* right. While so-called stopwords, sometimes also imagined as an extended set of function words to include words too common to be of any use in distinguishing one text from another, have proven useful in many applications, we felt it was better to keep all the words in our initial processing of the corpus and only remove words in later experiments as they proved problematic -- read \"mostly harmless\" -- in a particular context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Talks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rowID', 'Talk_ID', 'public_url', 'speaker_name', 'headline', 'description', 'event', 'duration', 'published', 'tags', 'views', 'text']\n",
      "(2657, 12)\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV into a dataframe and then place all the texts into a list:\n",
    "\n",
    "with open('../data/tedtalks2018.csv') as f:\n",
    "    colnames = f.readline().strip().split(\",\")\n",
    "\n",
    "print(colnames)\n",
    "\n",
    "df = pandas.read_csv('tedtalks2018.csv', names=colnames)\n",
    "print(df.shape)\n",
    "\n",
    "texts = df.text.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first item in this list is the column header -- `texts[0] > 'text'` -- and so the first thing we are going to do is remove it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll sure that our first text is, in fact, a text and not something else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Thank you so much, Chris. And it's truly a great\n"
     ]
    }
   ],
   "source": [
    "print(texts[0][0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "Now we need to determine the best way forward for tokenization. In other projects, I have used the NLTK's`WhitespaceTokenizer`, so we will begin there and check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 2656 talks, the shortest is 2 words; the longest 9185; and the average 2045.\n"
     ]
    }
   ],
   "source": [
    "# List of word counts for each talk \n",
    "counts = [len(WhitespaceTokenizer().tokenize(text)) for text in texts]\n",
    "print(\"Of the {} talks, the shortest is {} words; the longest {}; and the average {}.\".format(\n",
    "    len(counts),min(counts), max(counts), int(np.mean(counts))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A two word talk? What is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Applause)    (Music)    (Applause)  \n",
      "  Let's just get started here.    Okay, just a moment.    (Whirring)    All right. (Laughter) Oh, sorry.    (Music) (Beatboxing)    Thank you.    (Applause)  \n",
      "  (Music)    (Applause)    (Music)    (Music) (Applause)    (Music) (Applause) (Applause)    Herbie Hancock: Thank you. Marcus Miller. (Applause) Harvey Mason. (Applause)    Thank you. Thank you very much. (Applause)  \n",
      "  (Music)    (Applause)    (Music)    (Applause)  \n",
      "  (Music)    (Applause)    (Music)    (Applause)    (Music)    (Applause)    (Music)    (Applause)  \n",
      "  (Mechanical noises)    (Music) (Applause)  \n",
      "  (Music)    (Applause)  \n",
      "  (Music)    (Music) (Applause)    (Applause)  \n",
      "  (Guitar music starts)    (Music ends)    (Applause)    (Distorted guitar music starts)    (Music ends)    (Applause)    (Ambient/guitar music starts)    (Music ends)    (Applause)  \n",
      "  (Guitar music starts)    (Cheers)    (Cheers)    (Music ends)  \n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    if len(WhitespaceTokenizer().tokenize(text)) < 100:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 10 words to 100 words, the results do not change that much: these are musical performances. Somewhere between 100 and 200 words, the lyrics of sung performances produce a transcript. We will need to set a threshold for the text we treat, but we will also need to consider the role of parentheticals in our analysis.\n",
    "\n",
    "Can we see a list of parentheticals as a set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mock sob',\n",
       " 'Laughter',\n",
       " 'Laughter',\n",
       " 'Laughter',\n",
       " 'Laughter',\n",
       " 'Applause',\n",
       " 'Laughter',\n",
       " 'Mock sob',\n",
       " 'Laughter',\n",
       " 'Laughter',\n",
       " 'Laughter',\n",
       " 'Laughter',\n",
       " 'Laughter',\n",
       " 'Laughter',\n",
       " 'Laughter',\n",
       " 'Laughter',\n",
       " 'Applause',\n",
       " 'Laughter',\n",
       " 'Laughter',\n",
       " 'Laughter',\n",
       " 'Laughter',\n",
       " 'Laughter',\n",
       " 'Laughter',\n",
       " 'Laughter',\n",
       " 'Laughter',\n",
       " 'Applause',\n",
       " 'Applause',\n",
       " 'Applause',\n",
       " 'Laughter',\n",
       " 'Applause']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's see a list of parentheticals in a talk:\n",
    "re.findall('\\(([^)]+)', texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Applause', 'Laughter', 'Mock sob'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting a set is not a problem:\n",
    "set(re.findall('\\(([^)]+)', texts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2656\n"
     ]
    }
   ],
   "source": [
    "# Now to get a set for all the talks:\n",
    "parentheticals = []\n",
    "for texts in texts:\n",
    "    parentheticals.append(re.findall('\\(([^)]+)', text))\n",
    "    \n",
    "print(len(parentheticals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pylab\n",
    "%matplotlib inline\n",
    "pylab.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Plot of Word Lengths\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "length_sorted = sorted(counts)\n",
    "plt.bar(range(len(length_sorted)), length_sorted)\n",
    "plt.xlabel('TEDtalks')\n",
    "plt.ylabel('Length in Words')\n",
    "plt.title('How Long is a TEDtalk?')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
