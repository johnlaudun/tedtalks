{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=\n",
    "# Read CSV into DataFrame and then create lists\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "import pandas\n",
    "import re\n",
    "\n",
    "# Create pandas dataframe & lists\n",
    "colnames = ['author', 'title', 'date' , 'length', 'text']\n",
    "df = pandas.read_csv('../data/talks_3a.csv', names=colnames)\n",
    "talks = df.text.tolist()\n",
    "\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Create citations to identify individual texts\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "# authors = df.author.tolist()\n",
    "# dates = df.date.tolist()\n",
    "# years = [re.sub('[A-Za-z ]', '', item) for item in dates]\n",
    "# authordate = [author+\" \"+year for author, year in zip(authors, years)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=\n",
    "# Clean and Tokenize, then Drop Stopwords\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "# From the Stopwords Notebook:\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "# stopwords = re.split('\\s+', open('../data/tt_stop.txt', 'r').read().lower())\n",
    "\n",
    "# Loop to tokenize, stop, and stem (if needed) texts.\n",
    "texts = []\n",
    "for talk in talks:   \n",
    "    # clean and tokenize document string\n",
    "    raw = re.sub(r\"[^\\w\\d'\\s]+\",'', talk).lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    # remove stop words from tokens\n",
    "    # stopped_tokens = [i for i in tokens if not i in stopwords]\n",
    "    # stem tokens\n",
    "    # stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    # add tokens to list\n",
    "    texts.append(tokens)\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Re-Assemble Texts as Strings from Lists of Words\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "strungs = []\n",
    "for text in texts:\n",
    "    strung = ' '.join(text)\n",
    "    strungs.append(strung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model with 40 topics for 2069 documents with 3000 features.\n"
     ]
    }
   ],
   "source": [
    "# =-=-=-=-=-=\n",
    "# Get NMF topics\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# All our variables are here to make it easier to make adjustments\n",
    "n_samples = len(strungs)\n",
    "n_features = 3000\n",
    "n_topics = 40\n",
    "n_top_words = 15\n",
    "max_percent = 0.85\n",
    "min_percent = 0.05\n",
    "tt_stopwords = open('../data/stopwords-tt-20170523.txt', 'r').read().splitlines()\n",
    "\n",
    "# Get tf-idf features for NMF\n",
    "vectorizer = sk_text.TfidfVectorizer(max_df = max_percent, \n",
    "                                     min_df = min_percent,\n",
    "                                     max_features = n_features,\n",
    "                                     stop_words = tt_stopwords)\n",
    "tfidf = vectorizer.fit_transform(strungs)\n",
    "\n",
    "# Fit the NMF model\n",
    "nmf = NMF(n_components = n_topics,\n",
    "          random_state = 1,\n",
    "          alpha = 0.1,\n",
    "          l1_ratio = 0.5).fit(tfidf)\n",
    "print(\"Fitting the NMF model with {} topics for {} documents with {} features.\"\n",
    "      .format(n_topics, n_samples, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics in NMF model:\n",
      "\n",
      "Topic 0:\n",
      "different 0.4, ll 0.39, years 0.39, let 0.38, back 0.36, idea 0.34, need 0.33, human 0.3, show 0.3, great 0.3, three 0.3, able 0.29, called 0.29, life 0.29, sort 0.29, \n",
      "\n",
      "Topic 1:\n",
      "children 2.09, child 0.95, babies 0.39, parents 0.38, family 0.32, families 0.29, mother 0.2, baby 0.16, schools 0.16, boy 0.15, countries 0.14, years 0.09, old 0.09, school 0.09, adults 0.09, \n",
      "\n",
      "Topic 2:\n",
      "war 0.7, democracy 0.68, political 0.51, government 0.51, country 0.41, power 0.34, rights 0.34, peace 0.31, states 0.3, security 0.28, civil 0.28, citizens 0.28, politics 0.28, countries 0.26, global 0.26, \n",
      "\n",
      "Topic 3:\n",
      "cells 2.23, cell 0.73, body 0.29, drug 0.2, disease 0.18, blood 0.16, lab 0.15, drugs 0.14, diseases 0.12, skin 0.12, grow 0.12, heart 0.11, animal 0.1, patient 0.1, material 0.1, \n",
      "\n",
      "Topic 4:\n",
      "women 2.61, men 1.04, woman 0.44, sex 0.3, female 0.28, gender 0.25, male 0.18, equal 0.11, girls 0.1, young 0.1, husband 0.1, rights 0.1, media 0.09, boys 0.09, stories 0.08, \n",
      "\n",
      "Topic 5:\n",
      "design 2.21, designers 0.62, building 0.39, designed 0.27, architecture 0.27, designing 0.27, materials 0.18, products 0.14, buildings 0.14, product 0.14, made 0.12, beautiful 0.11, process 0.11, object 0.11, project 0.1, \n",
      "\n",
      "Topic 6:\n",
      "brain 2.75, brains 0.38, arm 0.19, activity 0.18, mental 0.17, body 0.14, memory 0.14, human 0.14, mind 0.12, behavior 0.12, visual 0.11, pain 0.1, genes 0.1, animal 0.1, information 0.09, \n",
      "\n",
      "Topic 7:\n",
      "kids 1.39, school 1.11, students 0.89, teachers 0.72, education 0.71, teacher 0.4, schools 0.35, learning 0.34, teaching 0.3, teach 0.29, class 0.25, student 0.24, kid 0.23, learn 0.21, math 0.19, \n",
      "\n",
      "Topic 8:\n",
      "music 2.29, sound 0.65, song 0.3, hear 0.25, piece 0.22, playing 0.19, listening 0.18, listen 0.17, sounds 0.15, hearing 0.15, play 0.15, video 0.14, played 0.13, voice 0.09, birds 0.06, \n",
      "\n",
      "Topic 9:\n",
      "data 2.76, information 0.49, map 0.15, web 0.15, points 0.08, patterns 0.07, numbers 0.07, text 0.07, analysis 0.06, collect 0.05, google 0.05, computer 0.05, statistics 0.04, graph 0.04, collected 0.04, \n",
      "\n",
      "Topic 10:\n",
      "energy 1.51, oil 1.11, nuclear 0.42, gas 0.36, power 0.33, carbon 0.31, fuel 0.3, electricity 0.28, climate 0.28, solar 0.28, wind 0.24, materials 0.13, co 0.13, heat 0.13, need 0.12, \n",
      "\n",
      "Topic 11:\n",
      "universe 1.89, space 0.45, stars 0.38, theory 0.36, physics 0.31, dark 0.31, billion 0.19, matter 0.17, sky 0.17, energy 0.17, science 0.16, black 0.15, laws 0.13, big 0.13, mass 0.13, \n",
      "\n",
      "Topic 12:\n",
      "cancer 2.38, body 0.19, drug 0.17, disease 0.17, blood 0.15, genetic 0.09, molecules 0.08, treatment 0.07, lab 0.06, genes 0.06, percent 0.06, cell 0.05, research 0.05, patient 0.05, growth 0.04, \n",
      "\n",
      "Topic 13:\n",
      "water 2.61, river 0.27, waste 0.2, dry 0.12, clean 0.11, rain 0.09, material 0.09, surface 0.09, supply 0.08, plastic 0.08, environment 0.08, air 0.07, drink 0.07, plant 0.07, green 0.06, \n",
      "\n",
      "Topic 14:\n",
      "food 2.06, eat 0.61, feed 0.29, eating 0.29, plant 0.25, waste 0.23, plants 0.18, organic 0.18, kids 0.14, fish 0.14, healthy 0.12, production 0.11, local 0.11, growing 0.1, america 0.09, \n",
      "\n",
      "Topic 15:\n",
      "dna 1.9, genes 0.41, genetic 0.33, code 0.24, cell 0.24, molecules 0.16, species 0.16, biology 0.15, science 0.11, information 0.1, base 0.09, understand 0.07, program 0.07, evolution 0.07, technology 0.07, \n",
      "\n",
      "Topic 16:\n",
      "laughter 2.39, applause 0.39, okay 0.29, guy 0.07, hear 0.07, color 0.07, piece 0.07, friends 0.06, mom 0.06, bit 0.05, four 0.04, weird 0.04, somebody 0.03, street 0.03, science 0.03, \n",
      "\n",
      "Topic 17:\n",
      "chinese 1.49, china 1.2, west 0.13, north 0.12, asia 0.09, countries 0.09, state 0.08, east 0.08, states 0.07, united 0.07, political 0.07, american 0.07, economy 0.06, civilization 0.06, economic 0.06, \n",
      "\n",
      "Topic 18:\n",
      "city 1.72, cities 1.04, building 0.51, buildings 0.38, space 0.34, urban 0.32, spaces 0.28, york 0.27, architecture 0.26, public 0.24, map 0.24, neighborhood 0.22, park 0.21, community 0.21, street 0.21, \n",
      "\n",
      "Topic 19:\n",
      "africa 2.12, african 0.82, countries 0.29, south 0.28, aid 0.17, leaders 0.16, aids 0.15, country 0.13, asia 0.11, sub 0.11, east 0.09, west 0.07, poverty 0.06, generation 0.06, traditional 0.05, \n",
      "\n",
      "Topic 20:\n",
      "machine 1.79, computer 1.0, machines 0.59, computers 0.5, technology 0.19, human 0.15, learning 0.15, intelligence 0.13, built 0.13, memory 0.11, software 0.11, build 0.1, web 0.09, program 0.08, artificial 0.07, \n",
      "\n",
      "Topic 21:\n",
      "india 2.1, china 0.19, innovation 0.14, growth 0.11, country 0.1, village 0.09, rural 0.07, asia 0.05, education 0.05, japan 0.05, health 0.04, ideas 0.04, countries 0.04, west 0.03, bear 0.03, \n",
      "\n",
      "Topic 22:\n",
      "said 1.26, life 0.47, went 0.42, love 0.4, man 0.39, father 0.39, day 0.39, didn 0.38, mother 0.35, family 0.32, told 0.3, home 0.29, came 0.28, thought 0.28, back 0.28, \n",
      "\n",
      "Topic 23:\n",
      "art 1.57, artist 0.62, artists 0.6, painting 0.53, museum 0.41, project 0.28, images 0.25, space 0.24, image 0.15, wall 0.15, piece 0.1, objects 0.1, drawing 0.1, visual 0.1, called 0.09, \n",
      "\n",
      "Topic 24:\n",
      "internet 1.27, information 0.76, online 0.54, web 0.53, media 0.5, phone 0.4, digital 0.38, page 0.31, technology 0.29, google 0.28, mobile 0.28, facebook 0.27, government 0.26, network 0.26, content 0.22, \n",
      "\n",
      "Topic 25:\n",
      "fly 1.63, flying 0.52, flight 0.49, space 0.19, baby 0.14, air 0.12, control 0.12, plane 0.11, camera 0.09, model 0.08, speed 0.08, birds 0.07, jump 0.06, weight 0.06, dream 0.06, \n",
      "\n",
      "Topic 26:\n",
      "stories 1.39, film 1.18, story 1.13, movie 0.26, news 0.21, tell 0.21, man 0.11, movies 0.1, magic 0.1, woman 0.09, telling 0.09, reality 0.08, media 0.07, live 0.07, camera 0.07, \n",
      "\n",
      "Topic 27:\n",
      "earth 1.17, planet 0.98, ice 0.65, solar 0.44, atmosphere 0.4, life 0.4, surface 0.38, sun 0.35, stars 0.31, climate 0.29, years 0.25, moon 0.24, star 0.21, space 0.2, system 0.2, \n",
      "\n",
      "Topic 28:\n",
      "ocean 1.41, fish 1.12, sea 0.77, animals 0.37, deep 0.22, plastic 0.17, boat 0.17, coast 0.16, species 0.16, water 0.14, blue 0.13, animal 0.13, north 0.13, creatures 0.11, places 0.11, \n",
      "\n",
      "Topic 29:\n",
      "patients 1.05, health 0.88, patient 0.7, disease 0.64, care 0.55, medical 0.48, doctors 0.43, drugs 0.41, drug 0.36, medicine 0.36, doctor 0.34, treatment 0.34, hospital 0.34, heart 0.32, diseases 0.26, \n",
      "\n",
      "Topic 30:\n",
      "light 2.0, lights 0.34, dark 0.24, stars 0.22, blue 0.21, sun 0.2, camera 0.19, eye 0.19, star 0.17, color 0.16, eyes 0.16, green 0.12, image 0.11, black 0.11, sound 0.1, \n",
      "\n",
      "Topic 31:\n",
      "games 1.33, game 1.32, video 0.9, playing 0.25, real 0.1, play 0.09, interaction 0.09, online 0.08, videos 0.08, physical 0.07, win 0.07, camera 0.06, computer 0.05, content 0.05, dynamic 0.04, \n",
      "\n",
      "Topic 32:\n",
      "cars 1.48, cities 0.43, driving 0.41, road 0.37, traffic 0.27, drive 0.24, miles 0.19, hour 0.1, percent 0.09, stop 0.09, today 0.08, sharing 0.08, sign 0.06, cost 0.06, charge 0.05, \n",
      "\n",
      "Topic 33:\n",
      "language 1.44, english 1.07, word 0.59, words 0.58, languages 0.3, speak 0.2, sentence 0.15, speech 0.15, sound 0.12, writing 0.12, learn 0.09, write 0.09, meaning 0.08, learning 0.08, french 0.07, \n",
      "\n",
      "Topic 34:\n",
      "dollars 0.64, percent 0.64, money 0.63, business 0.46, countries 0.44, economy 0.4, companies 0.4, billion 0.4, market 0.39, economic 0.37, growth 0.37, global 0.32, income 0.3, poor 0.3, million 0.29, \n",
      "\n",
      "Topic 35:\n",
      "book 1.49, books 1.13, read 0.5, reading 0.35, page 0.31, text 0.27, sort 0.23, pages 0.16, wrote 0.13, writing 0.12, images 0.12, story 0.1, published 0.1, image 0.09, web 0.07, \n",
      "\n",
      "Topic 36:\n",
      "species 1.0, animals 0.82, plants 0.82, forest 0.81, trees 0.57, plant 0.57, tree 0.36, animal 0.29, nature 0.27, carbon 0.21, genes 0.21, birds 0.21, human 0.21, humans 0.18, brazil 0.17, \n",
      "\n",
      "Topic 37:\n",
      "girls 1.86, girl 0.7, boys 0.33, school 0.28, father 0.11, wish 0.08, boy 0.08, daughter 0.07, dance 0.07, village 0.07, sister 0.06, community 0.05, young 0.05, parents 0.05, marriage 0.04, \n",
      "\n",
      "Topic 38:\n",
      "violence 1.64, police 0.38, crime 0.14, men 0.13, young 0.12, law 0.12, community 0.12, peace 0.11, local 0.11, streets 0.11, conflict 0.11, fear 0.1, mexico 0.09, woman 0.08, drug 0.07, \n",
      "\n",
      "Topic 39:\n",
      "play 1.96, playing 0.27, serious 0.17, kids 0.13, played 0.12, note 0.12, fun 0.11, game 0.1, ll 0.08, creativity 0.07, mom 0.07, dance 0.06, television 0.05, mistake 0.05, love 0.04, \n"
     ]
    }
   ],
   "source": [
    "# =-=-=-=-=-=\n",
    "# Get NMF printing\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_id, topic in enumerate(model.components_):\n",
    "        print('\\nTopic {}:'.format(int(topic_id)))\n",
    "        print(''.join([feature_names[i] + ' ' + str(round(topic[i], 2))\n",
    "              +', ' for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "\n",
    "features = vectorizer.get_feature_names()\n",
    "# print(features)\n",
    "\n",
    "# This should work now.\n",
    "\n",
    "print(\"Topics in NMF model:\")\n",
    "print_top_words(nmf, features, n_top_words) #n_top_words can be changed on the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtm = tfidf.toarray()\n",
    "doctopic = nmf.fit_transform(dtm) # This is an array\n",
    "\n",
    "# features = vectorizer.get_feature_names() # This is already done above.\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Unused functionality\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "# print(features)\n",
    "# for topicidx in enumerate(nmf.components_):\n",
    "#     print(topicidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=\n",
    "# Saving output to CSV\n",
    "# =-=-=-=-=-=\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Since DOCTOPIC is an array, you can just do:\n",
    "#      np.savetxt(\"foo.csv\", doctopic, delimiter=\",\", fmt = \"%s\")\n",
    "# http://stackoverflow.com/questions/6081008/dump-a-numpy-array-into-a-csv-file\n",
    "#\n",
    "# The above won't give you the names of the files. Instead try this:\n",
    "\n",
    "topsnum = np.array([list(range(n_topics))])\n",
    "# topsnum = np.indices((1,n_topics))[1] <-- this is more than we need,\n",
    "#                                           but it's cool to know more tricks\n",
    "#\n",
    "# Two ways to get an array that is of the form [[0,1,2,3,...]].\n",
    "# It will have the desired dimensions of (1,35) which is what we want\n",
    "\n",
    "fileheader = np.concatenate((np.array([[\"citations\"]]), topsnum),axis = 1)\n",
    "authordate = np.array([df.author])\n",
    "\n",
    "docTopics = np.concatenate((authordate.T, doctopic), axis = 1)\n",
    "docTopics = np.concatenate((fileheader, docTopics), axis = 0)\n",
    "\n",
    "np.savetxt(\"../outputs/nmf_topics_20170523.csv\", doctopic, delimiter=\",\", fmt = \"%s\")\n",
    "#np.savetxt(\"../data/nmf_topics.csv\", docTopics, delimiter=\",\", fmt = \"%s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
