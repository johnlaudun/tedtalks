{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pandas filters\n",
    "\n",
    "def talks_for_year(year):\n",
    "    import pandas\n",
    "    import re\n",
    "    colnames = ['author', 'title', 'date' , 'length', 'text']\n",
    "    df = pandas.read_csv('../data/talks-v1b.csv', names=colnames)\n",
    "    df['date'] = df['date'].replace(to_replace='[A-Za-z ]', value='', regex=True)\n",
    "    datayear = df[df['date'] == '{:d}'.format(year)]\n",
    "    talks = datayear.text.tolist()\n",
    "    utalks = [unicode(i) for i in talks]\n",
    "    return utalks\n",
    "\n",
    "def citations_for_year(year):\n",
    "    import pandas\n",
    "    import re\n",
    "    colnames = ['author', 'title', 'date' , 'length', 'text']\n",
    "    df = pandas.read_csv('../data/talks-v1b.csv', names=colnames)\n",
    "    df['date'] = df['date'].replace(to_replace='[A-Za-z ]', value='', regex=True)\n",
    "    datayear = df[df['date'] == '{:d}'.format(year)]\n",
    "    authors = datayear.author.tolist()\n",
    "    dates = datayear.date.tolist()\n",
    "    # Combining year with presenter for citations\n",
    "    citations = [author+\" \"+date for author, date in zip(authors, dates)]\n",
    "    return citations\n",
    "\n",
    "```python\n",
    ">>> talks2007 = talks_for_year(2007)\n",
    ">>> citations2007 = citations_for_year(2007)\n",
    "```\n",
    "\n",
    "## NMF Topics\n",
    "\n",
    "```python\n",
    ">>> def nmf_model(corpus, topics, features):\n",
    "...     \"\"\"Topic Model using NMF: requires corpus, topics, and features.\"\"\"\n",
    "...     import numpy as np\n",
    "...     import sklearn.feature_extraction.text as text\n",
    "...     from sklearn.decomposition import NMF\n",
    "...     n_samples = len(corpus)\n",
    "...     n_features = features\n",
    "...     n_topics = topics\n",
    "...     # Use tf-idf features for NMF.\n",
    "...     tfidf_vectorizer = text.TfidfVectorizer(max_df=0.95,\n",
    "...                                             min_df=2,\n",
    "...                                             max_features=n_features,\n",
    "...                                             stop_words='english')\n",
    "...     tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "...     tf_vectorizer = text.CountVectorizer(max_df=0.95,\n",
    "...                                          min_df=2,\n",
    "...                                          max_features=n_features,\n",
    "...                                          stop_words='english')\n",
    "...     # Fit the NMF model\n",
    "...     print(\"Fitting the NMF model with {} topics for {} documents with {} features.\".format(n_topics, n_samples, n_features))\n",
    "...     nmf = NMF(n_components=n_topics,\n",
    "...               random_state=1,\n",
    "...               alpha=.1,\n",
    "...               l1_ratio=.5).fit(tfidf)\n",
    "...     return\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> nmf_model(talks2007, 15, 1000)\n",
    "Fitting the NMF model with 15 topics for 119 documents with 1000 features.\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> print(\"\\nTopics in NMF model:\")\n",
    ">>> tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "...\n",
    ">>> # Function for printing topic words (used later):\n",
    "... def print_top_words(model, feature_names, n_top_words):\n",
    "...     for topic_id, topic in enumerate(model.components_):\n",
    "...         print('\\nTopic {}:'.format(int(topic_id)))\n",
    "...         print(''.join([feature_names[i] + ' ' + str(round(topic[i], 2))\n",
    "...               +', ' for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "...\n",
    ">>> print_top_words(nmf, tfidf_feature_names, n_top_words) #n_top_words can be changed on the fly\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> # Now to associate NMF topics to documents...\n",
    "... dtm = tf.toarray()\n",
    ">>> doctopic = nmf.fit_transform(dtm)\n",
    ">>> print(\"Top NMF topics in...\")\n",
    ">>> for i in range(len(doctopic)):\n",
    "...     top_topics = np.argsort(doctopic[i,:])[::-1][0:3]\n",
    "...     top_topics_str = ' '.join(str(t) for t in top_topics)\n",
    "...     print(\"{}: {}\".format(citations[i], top_topics_str))\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> doctopic.shape\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> doctopic\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> # Bar Chart of One Topic\n",
    "... import matplotlib.pyplot as plt\n",
    "...\n",
    ">>> N, K = doctopic.shape\n",
    ">>> ind = np.arange(N)\n",
    ">>> width = 1\n",
    ">>> plt.bar(ind, doctopic[:,0], width=width)\n",
    ">>> plt.xticks(ind + width/2, citations) # put labels in the center\n",
    ">>> plt.title('Share of Topic #0')\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> # Stacked Bar Chart of All Topics\n",
    "... # Thanks to Alan Riddell (https://de.dariah.eu/tatom/topic_model_visualization.html)\n",
    "...\n",
    "... import numpy as np\n",
    ">>> import matplotlib.pyplot as plt\n",
    "...\n",
    ">>> plt.figure(figsize=(12,8))\n",
    ">>> #fig = matplotlib.pyplot.gcf()\n",
    "... #fig.set_size_inches(18.5, 10.5)\n",
    "...\n",
    "... N, K = doctopic.shape  # N documents, K topics\n",
    ">>> ind = np.arange(N)  # the x-axis locations for the texts\n",
    ">>> width = 1  # the width of the bars\n",
    ">>> plots = []\n",
    ">>> height_cumulative = np.zeros(N)\n",
    "...\n",
    ">>> for k in range(K):\n",
    "...     color = plt.cm.coolwarm(k/K, 1)\n",
    "...     if k == 0:\n",
    "...         p = plt.bar(ind, doctopic[:, k], width, color=color)\n",
    "...     else:\n",
    "...         p = plt.bar(ind, doctopic[:, k], width, bottom=height_cumulative, color=color)\n",
    "...     height_cumulative += doctopic[:, k]\n",
    "...     plots.append(p)\n",
    "...\n",
    ">>> plt.ylim((0, 1))  # proportions sum to 1, so the height of the stacked bars is 1\n",
    ">>> plt.ylabel('Topics')\n",
    ">>> plt.title('Topics in 2006 TEDtalks')\n",
    ">>> plt.xticks(ind+width/2, citations, rotation='vertical')\n",
    ">>> plt.yticks(np.arange(0, 1, 10))\n",
    ">>> topic_labels = ['Topic #{}'.format(k) for k in range(K)]\n",
    ">>> plt.legend([p[0] for p in plots], topic_labels)\n",
    ">>> plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    ">>> plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
