{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Data Load & Tokenize\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "import pandas\n",
    "import re\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "# LOAD\n",
    "colnames = ['author', 'title', 'date' , 'length', 'text']\n",
    "df = pandas.read_csv('../data/talks_3.csv', names=colnames)\n",
    "talks = df.text.tolist()\n",
    "authors = df.author.tolist()\n",
    "dates = df.date.tolist()\n",
    "years = [re.sub('[A-Za-z ]', '', item) for item in dates]\n",
    "authordate = [author+\" \"+year for author, year in zip(authors, years)]\n",
    "\n",
    "# TOKENIZE\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "texts = []\n",
    "for talk in talks:   \n",
    "    raw = re.sub(r\"[^\\w\\d'\\s]+\",'', talk).lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    texts.append(tokens)\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Small Test Corpus\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "#\n",
    "# test = texts[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Function to collect word positions within a text (as a word list)\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "def word_positions(listname):\n",
    "    from collections import defaultdict\n",
    "    words_with_positions = defaultdict(list)\n",
    "    for position, word in enumerate(listname):\n",
    "        words_with_positions[word].append(float(position)/len(listname))\n",
    "    return(words_with_positions)\n",
    "\n",
    "# word_positions(texts[0]) # check output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Develop \"super dictionary\" of all the texts involved\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "super_dict = {}\n",
    "for text in texts:\n",
    "    temp_dict = word_positions(text)\n",
    "    for k, v in temp_dict.items():\n",
    "        if super_dict.get(k) is None:\n",
    "            super_dict[k] = []\n",
    "        if v not in super_dict.get(k):\n",
    "            # Possibly problematic for larger data sets\n",
    "            super_dict[k] = super_dict[k] + v\n",
    "            \n",
    "# print(super_dict) # check output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'super_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cbe9ac2b25c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msuper_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cholera\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'super_dict' is not defined"
     ]
    }
   ],
   "source": [
    "super_dict[\"cholera\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =-=-=-=-=-=-=-=-=-=-=\n",
    "# Quick way to get occurrence and average position for a term in the dictionary\n",
    "# =-=-=-=-=-=-=-=-=-=-= \n",
    "\n",
    "import statistics\n",
    "\n",
    "word = \"adaptable\"\n",
    "\n",
    "# the format method would work better here\n",
    "print(\"*\" + word + \"* occurs \" + str(len(super_dict[word])) + \n",
    "      \" times in the corpus, with an average position of \" + \n",
    "      str(statistics.mean(super_dict[word])) + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_df = pandas.DataFrame()\n",
    "words_df['word'] = super_dict.keys()\n",
    "words_df['positions'] = super_dict.values()\n",
    "\n",
    "# Check -----> returns 56588\n",
    "# print(len(words_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I need two additional columns: \n",
    "# one for mean, one for counting the number of items in a list\n",
    "\n",
    "positions = words_df['positions'].tolist()\n",
    "\n",
    "average_positions = []\n",
    "for the_list in positions:\n",
    "    average_positions.append(sum(the_list)/len(the_list))\n",
    "    \n",
    "occurrences = []\n",
    "for the_list in positions:\n",
    "    occurrences.append(len(the_list))\n",
    "\n",
    "# Quick Check\n",
    "# print(average_positions[0:5])\n",
    "# print(occurrences[0:5])\n",
    "\n",
    "words_df['average'] = average_positions\n",
    "words_df['occurs'] = occurrences\n",
    "words_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_df.to_csv('../data/word_places.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "colnames = ['word', 'positions', 'average' , 'occurs']\n",
    "words = pandas.read_csv('../data/word_places.csv', names=colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>positions</th>\n",
       "      <th>average</th>\n",
       "      <th>occurs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word</td>\n",
       "      <td>positions</td>\n",
       "      <td>average</td>\n",
       "      <td>occurs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>casseroles</td>\n",
       "      <td>[0.7642857142857142]</td>\n",
       "      <td>0.7642857142857142</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>procedurally</td>\n",
       "      <td>[0.41314425961276247, 0.42568857376602126]</td>\n",
       "      <td>0.4194164166893919</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gaelic</td>\n",
       "      <td>[0.07612635939927499, 0.08130502330398758, 0.1...</td>\n",
       "      <td>0.09822199205938202</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shambles</td>\n",
       "      <td>[0.0924962852897474, 0.1502231036192365]</td>\n",
       "      <td>0.12135969445449195</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word                                          positions  \\\n",
       "0          word                                          positions   \n",
       "1    casseroles                               [0.7642857142857142]   \n",
       "2  procedurally         [0.41314425961276247, 0.42568857376602126]   \n",
       "3        gaelic  [0.07612635939927499, 0.08130502330398758, 0.1...   \n",
       "4      shambles           [0.0924962852897474, 0.1502231036192365]   \n",
       "\n",
       "               average  occurs  \n",
       "0              average  occurs  \n",
       "1   0.7642857142857142       1  \n",
       "2   0.4194164166893919       2  \n",
       "3  0.09822199205938202       3  \n",
       "4  0.12135969445449195       2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, the first thing I need to do is to make sure I understand how to access/locate a cell within a pandas dataframe. \n",
    "\n",
    "The following work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0.07612635939927499, 0.08130502330398758, 0.13723459347488348]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.iloc[3, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0.07612635939927499, 0.08130502330398758, 0.13723459347488348]'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.at[3, 'positions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you simply drop one of these into a `qcut` as in `pandas.qcut(words.iloc[3,1], 10)`, you get back: `ValueError: Bin edges must be unique`. The workaround seems to be embedding qcut into a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'rank'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-a55102db21d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpct_rank_qcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-a55102db21d0>\u001b[0m in \u001b[0;36mpct_rank_qcut\u001b[0;34m(series, n)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0medges\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpct_rank_qcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'rank'"
     ]
    }
   ],
   "source": [
    "def pct_rank_qcut(series, n):\n",
    "    import pandas as pd\n",
    "    edges = pd.Series([float(i) / n for i in range(n + 1)])\n",
    "    f = lambda x: (edges >= x).argmax()\n",
    "    return series.rank(pct=1).apply(f)\n",
    "\n",
    "q = pct_rank_qcut(words.iloc[3, 1], 10)\n",
    "print(q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
