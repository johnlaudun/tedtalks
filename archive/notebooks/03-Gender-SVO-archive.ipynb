{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*To work with the already extracted SVOs, skip to **DataFrame Ops** and load the dataframe from the CSV file.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries & Data\n",
    "\n",
    "spaCy documentation: https://spacy.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From our 992x14 CSV, we have a list of 992 talks: 260 by women and 720 by men.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import re, spacy, textacy\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# If needed\n",
    "# parentheticals = [ \"\\(laughter\\)\", \"\\(applause\\)\", \"\\(music\\)\",  \n",
    "#                   \"\\(video\\)\", \"\\(laughs\\)\", \"\\(applause ends\\)\", \n",
    "#                   \"\\(audio\\)\", \"\\(singing\\)\", \"\\(music ends\\)\", \n",
    "#                   \"\\(cheers\\)\", \"\\(cheering\\)\", \"\\(recording\\)\", \n",
    "#                   \"\\(beatboxing\\)\", \"\\(audience\\)\", \"\\(guitar strum\\)\", \n",
    "#                   \"\\(clicks metronome\\)\", \"\\(sighs\\)\", \"\\(guitar\\)\", \n",
    "#                   \"\\(marimba sounds\\)\", \"\\(drum sounds\\)\" ]\n",
    "\n",
    "# def remove_parentheticals(text):\n",
    "#     global parentheticals\n",
    "#     new_text = text\n",
    "#     for rgx_match in parentheticals:\n",
    "#         new_text = re.sub(rgx_match, ' ', new_text.lower(), \n",
    "#                           flags=re.IGNORECASE)\n",
    "#     return new_text\n",
    "\n",
    "# Loading the Data in a gendered partitioned fashion: \n",
    "talks_m = pd.read_csv('talks_male.csv', index_col='Talk_ID')\n",
    "talks_f = pd.read_csv('talks_female.csv', index_col='Talk_ID')\n",
    "talks_nog = pd.read_csv('talks_nog.csv', index_col='Talk_ID')\n",
    "talks_all = pd.concat([talks_m, talks_f, talks_nog])\n",
    "\n",
    "# And then grabbing on the texts of the talks:\n",
    "texts = talks_all.text.tolist()\n",
    "texts_f = talks_f.text.tolist()\n",
    "texts_m = talks_m.text.tolist()\n",
    "\n",
    "print(f\"From our {talks_all.shape[0]}x{talks_all.shape[1]} CSV, \\\n",
    "we have a list of {len(texts)} talks: {len(texts_f)} by women and \\\n",
    "{len(texts_m)} by men.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy / Textacy\n",
    "\n",
    "Textacy is fussy about the size of texts being fed it, responding with `ValueError`s for `nlp.maxlength`. The workaround here is to create a `docs` object which is a list of spaCy `doc`s. The preview below demonstrates that each item in the list has the characteristics of a spaCy doc.\n",
    "\n",
    "Textacy does have a `corpus` object, but it is not straightforward to implement.\n",
    "\n",
    "```python\n",
    "corpus = textacy.Corpus(\"en_core_web_sm\", data=docs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing to see if we can lowercase everything \n",
    "# before we create a spaCy doc and then a Textacy SVO triple:\n",
    "\n",
    "texts_f_l = [text.lower() for text in texts_f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Space pipeline to be used\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# Use the pipe method to feed documents \n",
    "docs = list(nlp.pipe(texts_f_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Doc(3743 tokens: \"  if you\\'re here today — and i\\'m very happy tha...\")'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]._.preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   _SP SPACE\n",
      "if IN SCONJ\n",
      "you PRP PRON\n",
      "'re VBP AUX\n",
      "here RB ADV\n"
     ]
    }
   ],
   "source": [
    "# Quick example to show spaCy's PoS tagging\n",
    "for token in docs[0][0:5]:\n",
    "    print (token, token.tag_, token.pos_) # spacy.explain(token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n",
      "---\n",
      "SVOTriple(subject=[development], verb=[will, save], object=[us])\n",
      "SVOTriple(subject=[she], verb=[turned], object=[to, be, a, much, bigger, dog, than, i, 'd, anticipated])\n",
      "SVOTriple(subject=[part], verb=[handled], object=[percent])\n",
      "SVOTriple(subject=[that], verb=[bring], object=[truck, trips])\n",
      "SVOTriple(subject=[area], verb=[has], object=[one])\n"
     ]
    }
   ],
   "source": [
    "# Now to test the textacy SVO functionality.\n",
    "# Note we are only extracting triples from the first document:\n",
    "SVOs = list(textacy.extract.triples.subject_verb_object_triples(docs[0]))\n",
    "\n",
    "# How many triples did we get?\n",
    "print(len(SVOs))\n",
    "print(\"---\")\n",
    "\n",
    "# What do they look like?\n",
    "for item in SVOs[0:5]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 59 unique subjects out of 146.\n",
      "{'[air, pollution]', '[agenda]', '[seed]', '[folks]', '[mr, ., gore]', '[robert, moses]', '[she]', '[improvements]', '[they]', \"['s]\", '[link]', '[justice]', '[things]', '[him]', '[degradation]', '[community]', '[this]', '[what]', '[use, decisions]', '[it]', '[we]', '[developers]', '[regulations]', '[development]', '[riverside, park]', '[projects]', '[dad]', '[he]', '[income, citizens]', '[parade]', '[someone]', '[sections]', '[others]', '[area]', '[part]', '[chris]', '[justice, activists]', '[nothing]', '[who]', '[roofs]', '[presentation]', '[that]', '[i]', '[abundance]', '[you]', '[which]', '[residents]', '[ruth]', '[administration]', '[example]', '[both]', '[sports, team]', '[one]', '[people]', '[lining]', '[south, bronx]', '[percent]', '[none]', '[disinvestment]'}\n"
     ]
    }
   ],
   "source": [
    "# If we want to see all the nouns used \n",
    "# as subjects in the test document:\n",
    "subjects = [str(item[0]) for item in SVOs]\n",
    "subjects_set = set(subjects)\n",
    "\n",
    "print(f\"There are {len(subjects_set)} unique subjects out of {len(subjects)}.\")\n",
    "print(subjects_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVOTriple(subject=[i], verb=[was, contacted], object=[parks])\n",
      "SVOTriple(subject=[i], verb=[mentioned], object=[that])\n",
      "SVOTriple(subject=[i], verb=[wo, n't, mention], object=[that])\n",
      "SVOTriple(subject=[i], verb=['m, going], object=[to, exchange, marriage, vows, with, my, beloved])\n",
      "SVOTriple(subject=[i], verb=[do], object=[which])\n",
      "SVOTriple(subject=[i], verb=[watched], object=[half])\n",
      "SVOTriple(subject=[i], verb=[told], object=[you])\n",
      "SVOTriple(subject=[i], verb=[wrote], object=[dollar, transportation, grant])\n",
      "SVOTriple(subject=[i], verb=[like], object=[that])\n",
      "SVOTriple(subject=[i], verb=[have], object=[all])\n",
      "SVOTriple(subject=[i], verb=[do, not, expect], object=[individuals, corporations, government])\n",
      "SVOTriple(subject=[i], verb=['ll, tell], object=[you])\n",
      "SVOTriple(subject=[i], verb=[like], object=[what])\n",
      "SVOTriple(subject=[i], verb=[told], object=[you])\n",
      "SVOTriple(subject=[i], verb=['ve, embraced], object=[capitalist])\n",
      "SVOTriple(subject=[i], verb=[do, n't, have], object=[problem])\n",
      "SVOTriple(subject=[i], verb=[do, have], object=[problem])\n",
      "SVOTriple(subject=[i], verb=['m, trying], object=[to, build])\n",
      "SVOTriple(subject=[i], verb=[have], object=[time])\n",
      "SVOTriple(subject=[i], verb=[asked], object=[him])\n"
     ]
    }
   ],
   "source": [
    "# Get out just the first person singular triples:\n",
    "for item in SVOs:\n",
    "    if str(item[0]) == '[i]':\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the verb \"contents\" -- the verb phrase -- contains more material than we want. If all we want is the very itself, we will need to target the last item in the verb list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contacted\n",
      "mentioned\n",
      "mention\n",
      "going\n",
      "do\n",
      "watched\n",
      "told\n",
      "wrote\n",
      "like\n",
      "have\n",
      "expect\n",
      "tell\n",
      "like\n",
      "told\n",
      "embraced\n",
      "have\n",
      "have\n",
      "trying\n",
      "have\n",
      "asked\n"
     ]
    }
   ],
   "source": [
    "for item in SVOs:\n",
    "    if str(item[0]) == '[i]':\n",
    "        print(item[1][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KK's Quick Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc = []\n",
    "for item in SVOs:\n",
    "    if str(item[0]) == '[I]':\n",
    "        test_doc.append(item[1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc = \"\"\n",
    "for item in SVOs:\n",
    "    if str(item[0]) == '[I]':\n",
    "        test_doc = test_doc + \" \" + str(item[1][-1])\n",
    "test_doc = test_doc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in SVOs:\n",
    "    if str(item[0]) == '[I]':\n",
    "        print(item[1][-1], item[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in SVOs:\n",
    "    if str(item[0]) == '[She]':\n",
    "        print(item[1][-1:], item[2])\n",
    "    if str(item[0]) == '[she]':\n",
    "        print(item[1][-1:], item[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next steps:**\n",
    "\n",
    "- Rewrite code to return appended lists for I, He, She.\n",
    "- Rewrite code to produce a pandas dataframe and then use `groupby`.\n",
    "- Work on adaptation for objective cases. \n",
    "- Work on code to compile / visualize this as a network graph (?). So count up repeated verbs, etc.\n",
    "\n",
    "- *Do we need NLTK code to compare results?*\n",
    "\n",
    "- Possibly create a document per term set and run `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actions(terms, doc):\n",
    "    svos = []\n",
    "    svotriples = list(textacy.extract.triples.subject_verb_object_triples(doc))\n",
    "    for term in terms:\n",
    "        for item in svotriples:\n",
    "            if str(item[0]) == term:\n",
    "                svos.append(\n",
    "                    {\n",
    "                        'subject': item[0][-1], \n",
    "                        'verb': item[1][-1], \n",
    "                        'object': item[2]\n",
    "                    }\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next Step: load these into a list and then let the code iterate through that list\n",
    "first_s = ['[I]']\n",
    "first_p = ['[We]', '[we]']\n",
    "third_f = ['[She]', '[she]']\n",
    "third_m = ['[He]', '[he]']\n",
    "\n",
    "terms = first_s + first_p + third_f + third_m\n",
    "print(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A test of the function above:\n",
    "actions(terms, docs[0])\n",
    "print(type(svos), len(svos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(svos)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are interested only in the pronouns above, we can use the function as written to create a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    actions (terms, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(svos)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('../output/talks_f_svos-pn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All SVOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svos = []\n",
    "\n",
    "def allactions(doc):\n",
    "    svotriples = list(textacy.extract.triples.subject_verb_object_triples(doc))\n",
    "    for item in svotriples:\n",
    "        svos.append(\n",
    "            {\n",
    "                'subject': item[0][-1], \n",
    "                'verb': item[1][-1], \n",
    "                'object': item[2]\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    allactions(doc)\n",
    "    \n",
    "df2 = pd.DataFrame(svos)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.to_csv('../output/talks_f_svos-all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the SVO dataframe\n",
    "df = pd.read_csv('../output/talks_f_svos-all.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "she = df.loc[df[\"subject\"] == \"she\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "she.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_subject.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_subject.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gendered SVOs Dataframe\n",
    "\n",
    "By lowercasing everything in the texts going into the spaCy doc, we have reduced the number of pronouns by not quite half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the lists of gendered pronouns\n",
    "# pronouns = ['[i]', '[we]', '[she]', '[he]', '[they]', '[it]', '[you]']\n",
    "pronouns = ['i', 'we', 'she', 'he', 'they', 'it', 'you']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our function will remain much the same, though I would like to find a way to get the brackets out of the objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function which will get the SVOs\n",
    "def actions(terms, doc, svo_list):\n",
    "    svotriples = list(textacy.extract.triples.subject_verb_object_triples(doc))\n",
    "    for term in terms:\n",
    "        for item in svotriples:\n",
    "            if str(item[0][-1]) == term:\n",
    "                svo_list.append(\n",
    "                    {\n",
    "                        'subject': str(item[0][-1]), \n",
    "                        'verb': str(item[1][-1]), \n",
    "                        'object': item[2]\n",
    "                    }\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "svos_ = []\n",
    "\n",
    "for doc in docs:\n",
    "    actions(pronouns, doc, svos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18602, 3)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = pd.DataFrame(svos_)\n",
    "df_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have replaced the individual dataframes, one for each of the pronouns available to speakers of English:\n",
    "\n",
    "First Person: I / we\n",
    "Second Person: you\n",
    "Third Person: she, he, they\n",
    "Neuter: it\n",
    "\n",
    "FTR: *you* and *it* each added 3000 SVO triples to our list for a total of 18,410."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svos_he = []\n",
    "# for doc in docs:\n",
    "#     actions(third_m, doc, svos_he)    \n",
    "# dfm = pd.DataFrame(svos_he)\n",
    "\n",
    "# svos_I = []\n",
    "# for doc in docs:\n",
    "#     actions(first_s, doc, svos_I)\n",
    "# dfi = pd.DataFrame(svos_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this to a CSV so that we can quickly come back to working on this.\n",
    "# df_.to_csv('../output/svos-pronouns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>contacted</td>\n",
       "      <td>[parks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>mentioned</td>\n",
       "      <td>[that]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i</td>\n",
       "      <td>mention</td>\n",
       "      <td>[that]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i</td>\n",
       "      <td>going</td>\n",
       "      <td>[to, exchange, marriage, vows, with, my, beloved]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i</td>\n",
       "      <td>do</td>\n",
       "      <td>[which]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18597</th>\n",
       "      <td>you</td>\n",
       "      <td>have</td>\n",
       "      <td>[spoon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18598</th>\n",
       "      <td>you</td>\n",
       "      <td>have</td>\n",
       "      <td>[pen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18599</th>\n",
       "      <td>you</td>\n",
       "      <td>have</td>\n",
       "      <td>[shoes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18600</th>\n",
       "      <td>you</td>\n",
       "      <td>have</td>\n",
       "      <td>[phone, toys]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18601</th>\n",
       "      <td>you</td>\n",
       "      <td>produce</td>\n",
       "      <td>[waste]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18602 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject       verb                                             object\n",
       "0           i  contacted                                            [parks]\n",
       "1           i  mentioned                                             [that]\n",
       "2           i    mention                                             [that]\n",
       "3           i      going  [to, exchange, marriage, vows, with, my, beloved]\n",
       "4           i         do                                            [which]\n",
       "...       ...        ...                                                ...\n",
       "18597     you       have                                            [spoon]\n",
       "18598     you       have                                              [pen]\n",
       "18599     you       have                                            [shoes]\n",
       "18600     you       have                                      [phone, toys]\n",
       "18601     you    produce                                            [waste]\n",
       "\n",
       "[18602 rows x 3 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we want to do is simply survey the pronouns: make sure they are present and then to count the number of verbs associated with each one. The total here should match the total length of the dataframe, 18,602. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>739</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>6220</td>\n",
       "      <td>6220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>1342</td>\n",
       "      <td>1342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she</th>\n",
       "      <td>636</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>they</th>\n",
       "      <td>1919</td>\n",
       "      <td>1919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we</th>\n",
       "      <td>4645</td>\n",
       "      <td>4645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>3101</td>\n",
       "      <td>3101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         verb  object\n",
       "subject              \n",
       "he        739     739\n",
       "i        6220    6220\n",
       "it       1342    1342\n",
       "she       636     636\n",
       "they     1919    1919\n",
       "we       4645    4645\n",
       "you      3101    3101"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.groupby([\"subject\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The square brackets seem to be optional. If you run df_.groupby(\"subject\").count(), you still get:\n",
    "\n",
    "| subject | verb | object |\n",
    "|---------|------|--------|\n",
    "| he      | 739  |  739   |\n",
    "| i\t      | 6220 | 6220   |\n",
    "| it      | 1342 | 1342   |\n",
    "| she     | 636  | 636    |\n",
    "| they    | 1919 | 1919   |\n",
    "| we      | 4645 | 4645   |\n",
    "| you     | 3101 | 3101   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'he': [48, 49, 141, 142, 143, 144, 145, 146, 147, 148, 305, 306, 391, 433, 493, 494, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 866, 974, 975, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1466, 1467, 1468, 1469, 1470, 1571, 1572, 1573, 1574, 1575, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1736, 1737, 1738, 1739, 1878, 1879, 1880, 1881, 1927, 2119, 2296, 2297, 2365, 2366, 2367, 2368, 2369, 2492, 2493, 2494, 2495, 2496, 2497, 2733, 2734, 2735, 2736, 2737, 2738, ...], 'i': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 191, 192, 193, ...], 'it': [53, 54, 172, 321, 322, 323, 324, 325, 326, 327, 392, 393, 434, 435, 436, 518, 519, 520, 521, 522, 523, 524, 525, 711, 712, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 1006, 1007, 1008, 1009, 1010, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1586, 1587, 1588, 1589, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, ...], 'she': [44, 45, 46, 47, 138, 139, 140, 390, 680, 681, 682, 683, 684, 685, 686, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 972, 973, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, ...], 'they': [50, 51, 52, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 976, 977, 978, ...], 'we': [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 137, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, ...], 'you': [55, 56, 57, 58, 59, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 437, 438, 439, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, ...]}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.groupby(\"subject\").groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>he</td>\n",
       "      <td>does</td>\n",
       "      <td>[which, time]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>he</td>\n",
       "      <td>married</td>\n",
       "      <td>[mom]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>he</td>\n",
       "      <td>led</td>\n",
       "      <td>[them]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>he</td>\n",
       "      <td>stopped</td>\n",
       "      <td>[nephites]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>he</td>\n",
       "      <td>visited</td>\n",
       "      <td>[nephites]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18244</th>\n",
       "      <td>he</td>\n",
       "      <td>having</td>\n",
       "      <td>[conversation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18245</th>\n",
       "      <td>he</td>\n",
       "      <td>doing</td>\n",
       "      <td>[it]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18246</th>\n",
       "      <td>he</td>\n",
       "      <td>goes</td>\n",
       "      <td>[you]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18247</th>\n",
       "      <td>he</td>\n",
       "      <td>turns</td>\n",
       "      <td>[you]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18248</th>\n",
       "      <td>he</td>\n",
       "      <td>tells</td>\n",
       "      <td>[you]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>739 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject     verb          object\n",
       "48         he     does   [which, time]\n",
       "49         he  married           [mom]\n",
       "141        he      led          [them]\n",
       "142        he  stopped      [nephites]\n",
       "143        he  visited      [nephites]\n",
       "...       ...      ...             ...\n",
       "18244      he   having  [conversation]\n",
       "18245      he    doing            [it]\n",
       "18246      he     goes           [you]\n",
       "18247      he    turns           [you]\n",
       "18248      he    tells           [you]\n",
       "\n",
       "[739 rows x 3 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.groupby(\"subject\").get_group('he')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives you a dataframe with just the index\n",
    "# and the verb\n",
    "df2 = df_.groupby(['subject'])[['verb']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df_.groupby(\n",
    "    ['subject', 'verb']).size().groupby(level=0).nlargest(5).reset_index(level=0, drop=True).reset_index(name='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>he</td>\n",
       "      <td>had</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he</td>\n",
       "      <td>said</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he</td>\n",
       "      <td>going</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>he</td>\n",
       "      <td>got</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he</td>\n",
       "      <td>has</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject   verb  Count\n",
       "0      he    had     44\n",
       "1      he   said     25\n",
       "2      he  going     24\n",
       "3      he    got     17\n",
       "4      he    has     17"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "14a02b88778d8fb8b6aeb4ad427a942bc53dfcda9d7e3737237788289e0d2d23"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": 2,
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
