# Ott 2016

"The current work makes use of the set of gender-labeled tweets collected by Burger et al. (2011) and distributed by Svitlana Volkova (http://www.cs.jhu.edu/ svitlana/), who used them as the basis of work reported in (Volkova et al., 2013)."

"the tweets were part-of-speech tagged using the tagger described in Gimpel et al. (2011) and Owoputi et al. (2012)."

Preliminary tests were performed using both a Naive Bayes classifier, as well as a MaxEnt classifier, using NLTK implementations (Bird et al., 2009).

When trained on simply the presence of individual tokens, the Naive Bayes classifier was 64.7% accurate on the test set. One could also call this category “unigrams of words.” In this case, all words that were present in all tweets were considered (for a total of 118,313 tokens), and all the characters were made lowercase first. The following features were the most informative:

Female Token  | F:M Probability
giveaway      | 24.1 : 1.0
etsy          | 17.6 : 1.0

Male Token    | M:F Probability
#news         | 20.3 : 1.0
inflation     | 14.6 : 1.0

"A classifier that was trained entirely on the presence of bigrams of tokens (i.e. without the use of unigrams) was 62.2% accurate"

"The following results are for a classifier trained on the 500 most common part-of-speech bigrams, and showed 60.7% accuracy. Neither unigrams and trigrams produced as accurate a classifier as bigrams." (13)

"The tweets were parsed using a dependency parser designed for tweets described in Kong et al. (2014). The parser, known as TweeboParser, returns CONLL style dependency trees of each tweet, given a set of tweets. The parser does not consistently provide depen- dency relation labels, but pairs of dependent words were successfully incorporated into the classifier without regard for what particular relation they were in. The most informative features for a classifier trained only on dependency pairs (with 59.7% accuracy) are listed below. In these pairs, the second word is dependent upon the first."

"In addition to the text classification analyses, KL (Kullback Leibler) divergence was used as a statistical indicator of differences between the language of men and women on Twitter."

"In this case, the KL divergence was between two distributions P and Q - one rep- resenting a distribution for women and one for men, of all the words that appeared in dependency pairs in the dataset. Probability distributions for all verbs were calculated for both women and men, after having been stemmed by NLTKs Porter Stemmer."

"While the models described here were able to classify tweets into classes of female and male authorship better than chance, they weren't performing outstandingly well. The ways in which women and men tweet differently are mostly related to what they tweet about."
